{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a3e7aaf-09a1-454e-8e86-1723a34b6dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version: 2.4.1\n",
      "ROCM HIP version: 6.1.40093-e3dc58bf0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Pytorch version: \" + torch.__version__)\n",
    "print(\"ROCM HIP version: \" + torch.version.hip)\n",
    "torch.cuda.set_device('cuda:0')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb390ac-6dcc-4e9d-8f96-eb5853597568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import harmonic as hm\n",
    "from harmonic.model import RealNVPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e80d01d-f691-4fd3-a318-930d2e2cbdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from harmonic.model import ModifiedGaussianMixtureModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed360b3-2fac-440e-857e-614c2a153c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sed_path = 'Yggdrasil/PopIII.1_fcov_1_SFR_10M_yr_Spectra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fbe619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "def load_seds_from_file(filename):\n",
    "    \"\"\"\n",
    "    Load multiple SED datasets from a text file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filename : str\n",
    "        Path to the text file containing multiple SED datasets\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of dictionaries, each containing metadata and wavelength/flux data for one SED\n",
    "    \"\"\"\n",
    "    seds = []\n",
    "    current_metadata = {}\n",
    "    current_wavelength = []\n",
    "    current_flux = []\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        in_data_section = False\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            line = line.strip()\n",
    "            \n",
    "            # Skip empty lines\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Check if this is the start of a new SED section\n",
    "            if \"Age (Myr):\" in line and in_data_section:\n",
    "                # Save the current SED data before starting a new one\n",
    "                if current_wavelength and current_flux:\n",
    "                    seds.append({\n",
    "                        \"metadata\": current_metadata.copy(),\n",
    "                        \"wavelength\": np.array(current_wavelength),\n",
    "                        \"flux\": np.array(current_flux)\n",
    "                    })\n",
    "                    \n",
    "                # Reset for the new SED\n",
    "                current_metadata = {}\n",
    "                current_wavelength = []\n",
    "                current_flux = []\n",
    "                in_data_section = False\n",
    "            \n",
    "            # Process data section\n",
    "            if in_data_section:\n",
    "                # Handle potential formatting issues in the data\n",
    "                line = line.replace(\"'\", \"\").strip()\n",
    "                parts = re.split(r'\\s+', line)\n",
    "                \n",
    "                if len(parts) >= 2:\n",
    "                    try:\n",
    "                        wl = float(parts[0])\n",
    "                        fl = float(parts[1])\n",
    "                        current_wavelength.append(wl)\n",
    "                        current_flux.append(fl)\n",
    "                    except ValueError:\n",
    "                        # Skip lines that can't be parsed as numbers\n",
    "                        pass\n",
    "            \n",
    "            # Parse metadata\n",
    "            elif \"Wavelength (AA)\" in line and \"Flux\" in line:\n",
    "                in_data_section = True\n",
    "            elif \":\" in line:\n",
    "                key, value = line.split(\":\", 1)\n",
    "                current_metadata[key.strip()] = value.strip()\n",
    "            elif \"Wavelength unit\" in line:\n",
    "                parts = line.split(\":\", 1) if \":\" in line else line.split()\n",
    "                if len(parts) > 1:\n",
    "                    current_metadata[\"Wavelength unit\"] = parts[1].strip() if \":\" in line else parts[2].strip()\n",
    "            elif \"Energy unit\" in line:\n",
    "                parts = line.split(\":\", 1) if \":\" in line else line.split()\n",
    "                if len(parts) > 1:\n",
    "                    current_metadata[\"Energy unit\"] = parts[1].strip() if \":\" in line else parts[2].strip()\n",
    "    \n",
    "    # Don't forget to add the last SED\n",
    "    if current_wavelength and current_flux:\n",
    "        seds.append({\n",
    "            \"metadata\": current_metadata,\n",
    "            \"wavelength\": np.array(current_wavelength),\n",
    "            \"flux\": np.array(current_flux)\n",
    "        })\n",
    "\n",
    "    \n",
    "    for i, sed in enumerate(seds):\n",
    "        # Convert wavelength and flux to unyt arrays with appropriate units\n",
    "        sed[\"wavelength\"] = unyt_array(sed[\"wavelength\"], units=Angstrom)\n",
    "        sed[\"flux\"] = unyt_array(sed[\"flux\"], units=erg / (s * Angstrom))\n",
    "        # convert to fnu (erg/s*Hz)\n",
    "        sed[\"flux\"] = (sed[\"flux\"] * sed[\"wavelength\"]**2/ (2.99792458e9  * m/s)).to(erg / (s * Hz))\n",
    "        sed['metadata']['Energy unit'] = 'erg/s/Hz'\n",
    "\n",
    "    \n",
    "    return seds\n",
    "\n",
    "def load_seds_from_files(filenames):\n",
    "    \"\"\"\n",
    "    Load multiple SED datasets from a list of text files.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filenames : list\n",
    "        List of paths to text files containing SED datasets\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of dictionaries, each containing metadata and wavelength/flux data for one SED\n",
    "    \"\"\"\n",
    "    seds = []\n",
    "    \n",
    "    for filename in filenames:\n",
    "        seds.extend(load_seds_from_file(filename))\n",
    "    \n",
    "    return seds\n",
    "\n",
    "def plot_sed(sed_data, ax=None, label=None):\n",
    "    \"\"\"\n",
    "    Plot a single SED dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    sed_data : dict\n",
    "        Dictionary containing wavelength and flux data\n",
    "    ax : matplotlib.axes.Axes, optional\n",
    "        Axes to plot on. If None, a new figure is created.\n",
    "    label : str, optional\n",
    "        Label for the plot legend\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib.axes.Axes\n",
    "        The axes on which the plot was drawn\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Create a label if not provided\n",
    "    if label is None and \"Age (Myr)\" in sed_data[\"metadata\"]:\n",
    "        label = f\"Age: {float(sed_data['metadata']['Age (Myr)']):.4g} Myr\"\n",
    "    \n",
    "    ax.loglog(sed_data[\"wavelength\"], sed_data[\"flux\"], label=label)\n",
    "    \n",
    "    ax.set_xlabel(f'Wavelength ({sed_data[\"metadata\"].get(\"Wavelength unit\", \"AA\")})')\n",
    "    ax.set_ylabel(f'Flux ({sed_data[\"metadata\"].get(\"Energy unit\", \"erg\")}')\n",
    "    ax.set_title('Spectral Energy Distribution')\n",
    "    ax.grid(True, which=\"both\", ls=\"--\", alpha=0.3)\n",
    "    \n",
    "    if label:\n",
    "        ax.legend()\n",
    "    \n",
    "    return ax\n",
    "\n",
    "def plot_multiple_seds(seds_data, max_seds=None):\n",
    "    \"\"\"\n",
    "    Create a plot comparing multiple SEDs.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    seds_data : list\n",
    "        List of SED data dictionaries\n",
    "    max_seds : int, optional\n",
    "        Maximum number of SEDs to plot. If None, all SEDs are plotted.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib.figure.Figure\n",
    "        The figure containing the plot\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Limit the number of SEDs to plot if specified\n",
    "    if max_seds is not None:\n",
    "        seds_to_plot = seds_data[:max_seds]\n",
    "    else:\n",
    "        seds_to_plot = seds_data\n",
    "    \n",
    "    for i, sed in enumerate(seds_to_plot):\n",
    "        age = float(sed[\"metadata\"].get(\"Age (Myr)\", f\"SED {i+1}\"))\n",
    "        label = f\"Age: {age:.4g} Myr\"\n",
    "        plot_sed(sed, ax=ax, label=label)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def print_sed_summary(sed_data, index=None):\n",
    "    \"\"\"\n",
    "    Print a summary of SED metadata and data statistics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    sed_data : dict\n",
    "        Dictionary containing SED metadata and data\n",
    "    index : int, optional\n",
    "        Index of the SED (for display purposes)\n",
    "    \"\"\"\n",
    "    if index is not None:\n",
    "        print(f\"\\nSED #{index+1}:\")\n",
    "    else:\n",
    "        print(\"\\nSED Summary:\")\n",
    "    \n",
    "    # Print metadata\n",
    "    for key, value in sed_data[\"metadata\"].items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Print data statistics\n",
    "    print(f\"\\n  Data points: {len(sed_data['wavelength'])}\")\n",
    "    print(f\"  Wavelength range: {sed_data['wavelength'].min()} - {sed_data['wavelength'].max()} {sed_data['metadata'].get('Wavelength unit', 'AA')}\")\n",
    "    print(f\"  Flux range: {sed_data['flux'].min():.3e} - {sed_data['flux'].max():.3e} {sed_data['metadata'].get('Energy unit', 'erg')}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace 'your_sed_file.txt' with the path to your file\n",
    "    seds = load_seds_from_file(sed_path)\n",
    "    \n",
    "    print(f\"Loaded {len(seds)} SED datasets from file.\")\n",
    "    \n",
    "    # Print summary of first few SEDs\n",
    "    max_display = min(3, len(seds))\n",
    "    for i in range(max_display):\n",
    "        print_sed_summary(seds[i], index=i)\n",
    "    \n",
    "    if len(seds) > max_display:\n",
    "        print(f\"\\n...and {len(seds) - max_display} more SED datasets.\")\n",
    "    \n",
    "    # Plot all SEDs on the same graph (limit to 10 for readability)\n",
    "    max_plot = min(10, len(seds))\n",
    "    if max_plot < len(seds):\n",
    "        print(f\"\\nPlotting first {max_plot} of {len(seds)} SEDs...\")\n",
    "    \n",
    "    fig = plot_multiple_seds(seds, max_seds=max_plot)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef27a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we even need to give muv? Or is shape enough?\n",
    "\n",
    "# Can simply give normalized photometry. \n",
    "# If we give muv it will be in log10(nJy) units. \n",
    "# Giving normalized photometry allows us to pass in negative photometry better\n",
    "\n",
    "\n",
    "features = filter_codes + \\\n",
    "            [\"JWST/NIRCam.F115W-JWST/NIRCam.F150W\", \"JWST/NIRCam.F150W-JWST/NIRCam.F277W\", \"JWST/NIRCam.F277W-JWST/NIRCam.F444W\"] + \\\n",
    "            ['muv', 'z']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_photometry_from_sed(sed_data, filterset, redshift, supress_lya=False, plot=False):\n",
    "    \n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6), dpi=200, facecolor='w', edgecolor='k')\n",
    "\n",
    "    norm_arr = np.full(len(sed_data), np.nan)\n",
    "    phot_data_arr = np.full((len(sed_data), len(filterset)), np.nan)\n",
    "\n",
    "    for pos, sed_i in enumerate(sed_data):\n",
    "        if supress_lya:\n",
    "            # Find pixel closest to 1216 and set to next pixel\n",
    "            index = np.argmin(np.abs(sed_i['wavelength'] - 1216 * Angstrom))\n",
    "            sed_i['flux'][index] = sed_i['flux'][index + 1]\n",
    "           \n",
    "        sed = Sed(lam = sed_i['wavelength'], lnu = sed_i['flux'])\n",
    "        sed.get_fnu(cosmo=cosmo, z = redshift, igm=Inoue14)\n",
    "        phot = sed.get_photo_fnu(filters=filterset)\n",
    "\n",
    "        muv = sed.get_lnu_at_lam(15000 * Angstrom)\n",
    "        # muv is rest-frame luminosity at 15000 Angstrom. Apply cosmological dimming\n",
    "        # to get apparent magnitude\n",
    "\n",
    "        muv = (muv * (1 + redshift)**2 / (4 * np.pi * (cosmo.luminosity_distance(redshift).to(u.m).value *m)**2)).to(nJy)\n",
    "\n",
    "        phot_data = phot.photo_fnu\n",
    "\n",
    "        norm_arr[pos] = np.log10(muv.value)\n",
    "\n",
    "        phot_data_arr[pos] = phot_data.value\n",
    "\n",
    "        if plot:\n",
    "            wav = phot.filters.pivot_lams\n",
    "            ax.plot(wav, phot_data/muv, label=f\"z={redshift:.2f}\")\n",
    "            ax.set_title(f\"SED Photometry (z={redshift:.2f})\")\n",
    "            ax.set_xlabel(\"Wavelength (Angstrom)\")\n",
    "            ax.set_ylabel(\"Photometry (normalized to 15000 Angstrom)\")\n",
    "        \n",
    "    return phot_data_arr, norm_arr\n",
    "\n",
    "\n",
    "def generate_feature_array(feature_names, seds, redshifts, filterset, supress_lya=False):\n",
    "    \n",
    "    feature_array = np.full((len(seds)*len(redshifts), len(feature_names)), np.nan)\n",
    "\n",
    "    sum_indexes = []\n",
    "    opp_types = []\n",
    "\n",
    "    for feature_name in feature_names:\n",
    "        if '-' in feature_name:\n",
    "            filters = feature_name.split('-')\n",
    "            sum_indexes.append([filter_codes.index(filters[0]), filter_codes.index(filters[1])])\n",
    "            opp_types.append(np.subtract)\n",
    "        elif '+' in feature_name:\n",
    "            filters = feature_name.split('+')\n",
    "            sum_indexes.append([filter_codes.index(filters[0]), filter_codes.index(filters[1])])\n",
    "            opp_types.append(np.add)\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "    for i, redshift in enumerate(redshifts):\n",
    "        for j, sed in enumerate(seds):\n",
    "            phot_data_arr, norm_arr = compute_photometry_from_sed([sed], filterset, redshift, supress_lya=supress_lya)\n",
    "            colors = []\n",
    "            for k, sum_index in enumerate(sum_indexes):\n",
    "                colors.append(opp_types[k](phot_data_arr[0][sum_index[0]], phot_data_arr[0][sum_index[1]]))\n",
    "                \n",
    "            feature_array[i * len(seds) + j] = np.concatenate((phot_data_arr[0], colors, [norm_arr[0], redshift]))\n",
    "\n",
    "    return feature_array\n",
    "\n",
    "redshifts = np.arange(6, 15, 0.1)\n",
    "\n",
    "feature_array = generate_feature_array(features, seds, redshifts, filterset, supress_lya=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test and build loaders\n",
    "test_split = 0.1\n",
    "n_samples = len(feature_array)\n",
    "\n",
    "# Model 1\n",
    "mask1 = np.random.rand(n_samples) > test_split\n",
    "x1_train, x1_test = feature_array[mask1], feature_array[~mask1]\n",
    "theta1_train, theta1_test = theta1[mask1], theta1[~mask1]\n",
    "\n",
    "\n",
    "# Build loaders\n",
    "loader1_train = NumpyLoader(x1_train, theta1_train)\n",
    "loader1_test = NumpyLoader(x1_test, theta1_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13450311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training scripts to train NPE/NLE with LtU-ILI\n",
    "def train_nde(loader, prior_mu, engine='NLE'):\n",
    "    # define a prior\n",
    "    prior = ili.utils.IndependentNormal(\n",
    "        loc=prior_mu,\n",
    "        scale=1*np.ones(Ndim),\n",
    "        device=device\n",
    "    )\n",
    "    # instantiate your neural networks to be used as an ensemble\n",
    "    nets = [\n",
    "        ili.utils.load_nde_sbi(\n",
    "            engine=engine, model='mdn', hidden_features=50, num_components=4),\n",
    "    ]\n",
    "    # define training arguments\n",
    "    train_args = {\n",
    "        'training_batch_size': 64,\n",
    "        'learning_rate': 5e-4\n",
    "    }\n",
    "    # initialize the trainer\n",
    "    runner = InferenceRunner.load(\n",
    "        backend='sbi',\n",
    "        engine=engine,\n",
    "        prior=prior,\n",
    "        nets=nets,\n",
    "        device=device,\n",
    "        train_args=train_args,\n",
    "    )\n",
    "    # train the model\n",
    "    posterior_ensemble, summaries = runner(loader=loader)\n",
    "    return posterior_ensemble, summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Neural Likelihood Estimation\n",
    "nle1, summ_nle1 = train_nde(loader1_train, mu1, 'NLE')\n",
    "nle2, summ_nle2 = train_nde(loader2_train, mu2, 'NLE')\n",
    "\n",
    "# Train Neural Posterior Estimation\n",
    "npe1, summ_npe1 = train_nde(loader1_train, mu1, 'NPE')\n",
    "npe2, summ_npe2 = train_nde(loader2_train, mu2, 'NPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5de9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "def lognorm_equations(p, consts):\n",
    "    \"\"\" Equations for finding the tau and T0 for a lognormal SFH given\n",
    "    some tmax and FWHM. Needed to transform variables. \"\"\"\n",
    "\n",
    "    tau_solve, T0_solve = p\n",
    "\n",
    "    xmax, h = consts\n",
    "\n",
    "    tau = np.exp(T0_solve - tau_solve**2) - xmax\n",
    "    t0 = xmax*(np.exp(0.5*np.sqrt(8*np.log(2)*tau_solve**2))\n",
    "               - np.exp(-0.5*np.sqrt(8*np.log(2)*tau_solve**2))) - h\n",
    "\n",
    "    return (tau, t0)\n",
    "\n",
    "\n",
    "tmaxes = np.linspace(10, 2500, 5) * Myr \n",
    "tmaxes = tmaxes.to(yr).to_value()\n",
    "\n",
    "FWHMs = np.linspace(10, 1000, 5) * Myr\n",
    "FWHMs = FWHMs.to(yr).to_value()\n",
    "\n",
    "print(tmaxes, FWHMs)\n",
    "\n",
    "\n",
    "# Create a grid of tmax and FWHM values\n",
    "\n",
    "tmax_grid, FWHM_grid = np.meshgrid(tmaxes, FWHMs)\n",
    "# Flatten the grid for easier processing\n",
    "tmax_flat = tmax_grid.flatten()\n",
    "FWHM_flat = FWHM_grid.flatten() \n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "# Loop through the grid and calculate tau and T0 for each combination\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=200, facecolor='w', edgecolor='k')\n",
    "\n",
    "\n",
    "for tmax, fwhm in zip(tmax_flat, FWHM_flat):\n",
    "    # Define the constants for the equations\n",
    "    consts = (tmax, fwhm)\n",
    "    \n",
    "    # Use fsolve to find the roots of the equations\n",
    "    \n",
    "    tau_guess = fwhm/(2*tmax*np.sqrt(2*np.log(2)))\n",
    "    t0_guess = np.log(tmax) + fwhm**2/(8*np.log(2)*tmax**2)\n",
    "\n",
    "    tau, t0 = fsolve(lognorm_equations, (tau_guess, t0_guess),\n",
    "                        args=([tmax, fwhm]))\n",
    "    \n",
    "    t0 = t0 * yr\n",
    "\n",
    "\n",
    "    sfh = SFH.LogNormal(tau=tau, peak_age=t0, max_age=max_age, min_age=-1000 * Myr)\n",
    "    age, sfr = sfh.calculate_sfh(t_range=(0, 1.3*max_age.to(yr)), dt=1e6*yr)                                       \n",
    "    sfr = sfr / sfr.max()\n",
    "    ax.plot(age, sfr, label=f\"tau={tau:.2f}, peak_age={peak_age:.2f}\")\n",
    "    \n",
    "\n",
    "    # add secondary axis showing redshift\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
