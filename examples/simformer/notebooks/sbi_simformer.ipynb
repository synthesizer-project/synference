{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f6eea8",
   "metadata": {},
   "source": [
    "### Testing SBI's Implementation of the Simformer for Model Comparison\n",
    "\n",
    "You will need to run the following commands to pull the simformer branch to your cloned 'sbi' repository.\n",
    "\n",
    "```bash\n",
    "\n",
    "git fetch origin pull/1621/head:simformer\n",
    "git checkout simformer\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0704f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from synference import SBI_Fitter, load_unc_model_from_hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9a427d",
   "metadata": {},
   "source": [
    "### Load SBI Fitter, create noise models and feature arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef73924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpass_path = \"/home/tharvey/work/synference/libraries/grid_BPASS_Chab_DenseBasis_SFH_0.01_z_14_logN_5.0_Calzetti_v3_multinode.hdf5\"  # noqa: E501\n",
    "\n",
    "fitter_bpass = SBI_Fitter.init_from_hdf5(\n",
    "    \"BPASS_Chab_DenseBasis_SFH_0.01_z_14_logN_5.0_Calzetti_v3_multinode\", bpass_path\n",
    ")\n",
    "\n",
    "noise_model_path = \"/home/tharvey/work/synference/priv/data/JOF_psfmatched_asinh_noise_model.h5\"\n",
    "noise_models = load_unc_model_from_hdf5(noise_model_path)\n",
    "\n",
    "hst_filters = [\"F435W\", \"F606W\", \"F775W\", \"F814W\", \"F850LP\"]\n",
    "\n",
    "nm = {f\"JWST/NIRCam.{i}\": j for i, j in noise_models.items() if i not in hst_filters}\n",
    "\n",
    "fa_input = dict(\n",
    "    extra_features=[\"redshift\"],\n",
    "    empirical_noise_models=nm,\n",
    "    include_errors_in_feature_array=False,\n",
    "    scatter_fluxes=False,\n",
    "    # normed_flux_units=\"asinh\",\n",
    "    photometry_to_remove=[\n",
    "        \"CTIO/DECam.u\",\n",
    "        \"CTIO/DECam.g\",\n",
    "        \"CTIO/DECam.r\",\n",
    "        \"CTIO/DECam.i\",\n",
    "        \"CTIO/DECam.z\",\n",
    "        \"CTIO/DECam.Y\",\n",
    "        \"LSST/LSST.u\",\n",
    "        \"LSST/LSST.g\",\n",
    "        \"LSST/LSST.r\",\n",
    "        \"LSST/LSST.i\",\n",
    "        \"LSST/LSST.z\",\n",
    "        \"LSST/LSST.Y\",\n",
    "        \"PAN-STARRS/PS1.g\",\n",
    "        \"PAN-STARRS/PS1.r\",\n",
    "        \"PAN-STARRS/PS1.i\",\n",
    "        \"PAN-STARRS/PS1.w\",\n",
    "        \"PAN-STARRS/PS1.z\",\n",
    "        \"PAN-STARRS/PS1.y\",\n",
    "        \"Paranal/VISTA.Z\",\n",
    "        \"Paranal/VISTA.Y\",\n",
    "        \"Paranal/VISTA.J\",\n",
    "        \"Paranal/VISTA.H\",\n",
    "        \"Paranal/VISTA.Ks\",\n",
    "        \"Subaru/HSC.g\",\n",
    "        \"Subaru/HSC.r\",\n",
    "        \"Subaru/HSC.i\",\n",
    "        \"Subaru/HSC.z\",\n",
    "        \"Subaru/HSC.Y\",\n",
    "        \"CFHT/MegaCam.u\",\n",
    "        \"CFHT/MegaCam.g\",\n",
    "        \"CFHT/MegaCam.r\",\n",
    "        \"CFHT/MegaCam.i\",\n",
    "        \"CFHT/MegaCam.z\",\n",
    "        \"Euclid/VIS.vis\",\n",
    "        \"Euclid/NISP.Y\",\n",
    "        \"Euclid/NISP.J\",\n",
    "        \"Euclid/NISP.H\",\n",
    "        \"HST/ACS_WFC.F475W\",\n",
    "        \"HST/WFC3_IR.F105W\",\n",
    "        \"JWST/NIRCam.F070W\",\n",
    "        \"HST/WFC3_IR.F110W\",\n",
    "        \"HST/WFC3_IR.F125W\",\n",
    "        \"JWST/NIRCam.F140M\",\n",
    "        \"HST/WFC3_IR.F140W\",\n",
    "        \"HST/WFC3_IR.F160W\",\n",
    "        \"JWST/NIRCam.F360M\",\n",
    "        \"JWST/NIRCam.F430M\",\n",
    "        \"JWST/NIRCam.F460M\",\n",
    "        \"JWST/NIRCam.F480M\",\n",
    "        \"JWST/MIRI.F560W\",\n",
    "        \"JWST/MIRI.F770W\",\n",
    "        \"JWST/MIRI.F1000W\",\n",
    "        \"JWST/MIRI.F1130W\",\n",
    "        \"JWST/MIRI.F1280W\",\n",
    "        \"JWST/MIRI.F1500W\",\n",
    "        \"JWST/MIRI.F1800W\",\n",
    "        \"JWST/MIRI.F2100W\",\n",
    "        \"JWST/MIRI.F2550W\",\n",
    "        \"Spitzer/IRAC.I1\",\n",
    "        \"Spitzer/IRAC.I2\",\n",
    "        \"Spitzer/IRAC.I3\",\n",
    "        \"Spitzer/IRAC.I4\",\n",
    "        \"HST/ACS_WFC.F435W\",\n",
    "        \"HST/ACS_WFC.F606W\",\n",
    "        \"HST/ACS_WFC.F775W\",\n",
    "        \"HST/ACS_WFC.F814W\",\n",
    "        \"HST/ACS_WFC.F850LP\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "fitter_bpass.create_feature_array_from_raw_photometry(\n",
    "    **fa_input, parameter_transformations={\"Av\": np.log10}\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66ee64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synference.utils import make_serializable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = fitter_bpass.run_single_simformer(verbose=True, sde_type=\"vp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15f160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = fitter_bpass.feature_array[fitter_bpass._test_indices]\n",
    "y_test = fitter_bpass._y_test\n",
    "random_sample_idx = np.random.choice(X_test.shape[0])\n",
    "random_sample = X_test[random_sample_idx]\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_serializable(fitter_bpass.simformer._posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dbae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter_bpass.simformer._posterior.vector_field_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d16f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import torch\n",
    "\n",
    "# Save with dill\n",
    "dill.detect.trace(True)\n",
    "\n",
    "with open(\"bpass_simformer_posterior_vp.pt\", \"wb\") as f:\n",
    "    dill.dump(fitter_bpass.simformer, f)\n",
    "\n",
    "# Unpickle using dill\n",
    "with open(\"bpass_simformer_posterior_vp.pt\", \"rb\") as f:\n",
    "    posterior = dill.load(f)\n",
    "    print(posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle using dill\n",
    "from synference.utils import CPU_Unpickler\n",
    "\n",
    "with open(\"bpass_simformer_posterior_vp.pt\", \"rb\") as f:\n",
    "    posterior = CPU_Unpickler(f).load()\n",
    "    print(posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec83b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "?fitter_bpass.posteriors.sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42aef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = fitter_bpass.posteriors.sample(x=random_sample, sample_shape=(1000,), steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f31671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a corner plot\n",
    "import corner\n",
    "\n",
    "corner.corner(\n",
    "    samples.cpu().numpy(),\n",
    "    labels=fitter_bpass.fitted_parameter_names,\n",
    "    show_titles=True,\n",
    "    truths=fitter_bpass._y_test[random_sample_idx],\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0df1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = fitter_bpass.simformer._summary[\"validation_loss\"]\n",
    "train_loss = fitter_bpass.simformer._summary[\"training_loss\"]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss, label=\"Train Loss\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a88e3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference.posteriors.direct_posterior import DirectPosterior\n",
    "\n",
    "posterior = DirectPosterior(posterior_estimator=posterior, prior=fitter_bpass.prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f5becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make edge mask\n",
    "# parameters attend to themselves and redshift\n",
    "\n",
    "\n",
    "fitter_bpass.simformer.build_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fef0fa",
   "metadata": {},
   "source": [
    "# Stolen Evidence Networks from LtU-ILI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e18903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# def smooth_sign(x, k=100.):\n",
    "#     return 2. * torch.sigmoid(k * x) - 1\n",
    "\n",
    "\n",
    "def parity_odd_power(x, alpha=2):\n",
    "    \"\"\"Parity odd power activation function.\"\"\"\n",
    "    return x * (torch.abs(x) ** (alpha - 1))\n",
    "\n",
    "\n",
    "def leaky_parity_odd_power(x, alpha=2):\n",
    "    \"\"\"Leaky version of the parity odd power activation function.\"\"\"\n",
    "    return x + parity_odd_power(x, alpha)\n",
    "\n",
    "\n",
    "class POPExpLoss(nn.Module):\n",
    "    \"\"\"Exponential loss function for evidence network training.\"\"\"\n",
    "\n",
    "    def forward(self, model_pred, model_label):\n",
    "        \"\"\"Exponential loss function for evidence network training.\"\"\"\n",
    "        model_pred = leaky_parity_odd_power(model_pred, alpha=1)\n",
    "        model_pred = torch.clamp(model_pred, -50, 50)\n",
    "        loss_val = torch.exp((0.5 - model_label) * model_pred)\n",
    "        return torch.mean(loss_val)\n",
    "\n",
    "\n",
    "class ExpLoss(nn.Module):\n",
    "    \"\"\"Exponential loss function for evidence network training.\"\"\"\n",
    "\n",
    "    def forward(self, model_pred, model_label):\n",
    "        \"\"\"Exponential loss function for evidence network training.\"\"\"\n",
    "        loss_val = (0.5 - model_label) * model_pred\n",
    "        out = torch.logsumexp(loss_val, dim=0)\n",
    "        return out\n",
    "\n",
    "\n",
    "class EvidenceNetwork(nn.Module):\n",
    "    \"\"\"A deep neural network designed to approximate the log-Bayes factor.\n",
    "\n",
    "    The architecture consists of an optional embedding network, followed by an\n",
    "    initial fully-connected layer, a series of residual blocks, and a final\n",
    "    output layer. This structure allows the network to learn complex features from\n",
    "    the input data.\n",
    "\n",
    "    Args:\n",
    "        input_size (int): The dimension of the input features that are fed into the\n",
    "            first fully-connected layer. This should match the output dimension\n",
    "            of the `embedding_net`.\n",
    "        embedding_net (nn.Module, optional): A PyTorch module to preprocess or\n",
    "            embed the raw input data before it enters the main network. Defaults\n",
    "            to nn.Identity().\n",
    "        layer_width (int, optional): The number of neurons in the hidden layers.\n",
    "            Defaults to 16.\n",
    "        added_layers (int, optional): The number of residual blocks to include in\n",
    "            the network. Defaults to 3.\n",
    "        batch_norm_flag (int, optional): A flag to enable (1) or disable (0)\n",
    "            batch normalization. Defaults to 1.\n",
    "        alpha (int, optional): The exponent for the `leaky_parity_odd_power`\n",
    "            activation function applied to the output. Defaults to 2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        embedding_net=nn.Identity(),\n",
    "        layer_width=16,\n",
    "        added_layers=3,\n",
    "        batch_norm_flag=1,\n",
    "        alpha=2,\n",
    "    ):\n",
    "        \"\"\"Initializes the EvidenceNetwork with specified architecture.\"\"\"\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_net = embedding_net\n",
    "        self.layer_width = layer_width\n",
    "        self.added_layers = added_layers\n",
    "        self.bn = batch_norm_flag\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.initial_layer = self.simple_layer(self.input_size, self.layer_width, 1)\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList(\n",
    "            [self.simple_layer(self.layer_width, self.layer_width, 1) for _ in range(1)]\n",
    "        )\n",
    "\n",
    "        self.residual_layers = nn.ModuleList(\n",
    "            [\n",
    "                self.residual_layer(self.layer_width, self.layer_width, self.bn)\n",
    "                for _ in range(self.added_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.post_residual = self.simple_layer(\n",
    "            self.layer_width, self.layer_width, batch_norm_flag=0\n",
    "        )\n",
    "        self.output_layer = nn.Linear(self.layer_width, 1)\n",
    "\n",
    "    def simple_layer(self, in_features, out_features, batch_norm_flag=1):\n",
    "        \"\"\"Creates a simple fully-connected layer with LeakyReLU activation.\"\"\"\n",
    "        layers = [nn.Linear(in_features, out_features), nn.LeakyReLU(0.1)]\n",
    "        if batch_norm_flag == 1:\n",
    "            layers.append(nn.BatchNorm1d(self.layer_width))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def residual_layer(self, in_features, out_features, batch_norm_flag=1):\n",
    "        \"\"\"Creates a residual block with two fully-connected layers.\"\"\"\n",
    "        layers = [\n",
    "            self.simple_layer(in_features, out_features, batch_norm_flag),\n",
    "            self.simple_layer(out_features, out_features, batch_norm_flag),\n",
    "        ]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the EvidenceNetwork.\"\"\"\n",
    "        # Embedding Network\n",
    "        x = self.embedding_net(x)\n",
    "\n",
    "        # Initial layer (resizing input to layer width)\n",
    "        x = self.initial_layer(x)\n",
    "\n",
    "        # Hidden layers\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # Residual layers\n",
    "        for layer in self.residual_layers:\n",
    "            x = x + layer(x)\n",
    "\n",
    "        # Output layer\n",
    "        x = self.post_residual(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = 0.1 * x + 0.001\n",
    "        x = leaky_parity_odd_power(x, alpha=self.alpha)\n",
    "        return x\n",
    "\n",
    "\n",
    "class K_EvidenceNetwork:\n",
    "    \"\"\"A runner class to train an EvidenceNetwork for approximating the Bayes Factor (K).\n",
    "\n",
    "    This class handles data preparation, training loops, validation, early stopping,\n",
    "    and model saving. It can optionally use a custom embedding network to process\n",
    "    complex data modalities before the main fully-connected layers.\n",
    "\n",
    "    Args:\n",
    "        embedding_net (nn.Module, optional): A PyTorch module to preprocess input\n",
    "            data. If None, an identity mapping is used. Defaults to None.\n",
    "        layer_width (int, optional): The number of neurons in the hidden layers of\n",
    "            the EvidenceNetwork. Defaults to 16.\n",
    "        added_layers (int, optional): The number of residual blocks in the\n",
    "            EvidenceNetwork. Defaults to 3.\n",
    "        batch_norm_flag (int, optional): A flag to enable (1) or disable (0)\n",
    "            batch normalization. Defaults to 1.\n",
    "        alpha (int, optional): The exponent for the leaky_parity_odd_power\n",
    "            activation function. Defaults to 2.\n",
    "        train_args (dict, optional): A dictionary of training hyperparameters to\n",
    "            override the defaults. Defaults to {}.\n",
    "        device (str, optional): The device to run training on (e.g., 'cpu' or\n",
    "            'cuda'). Defaults to 'cpu'.\n",
    "\n",
    "    Attributes:\n",
    "        model (EvidenceNetwork): The trained PyTorch model. This is None until\n",
    "            the `train` method is successfully called.\n",
    "        best_val (float): The best validation loss achieved during training.\n",
    "        loss_fn (nn.Module): The loss function instance used for training.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_net=None,\n",
    "        layer_width=16,\n",
    "        added_layers=3,\n",
    "        batch_norm_flag=1,\n",
    "        alpha=2,\n",
    "        train_args={},\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        \"\"\"Initializes the K_EvidenceNetwork with specified architecture and training parameters.\"\"\"\n",
    "        self.embedding_net = embedding_net or nn.Identity()\n",
    "        self.layer_width = layer_width\n",
    "        self.added_layers = added_layers\n",
    "        self.batch_norm_flag = batch_norm_flag\n",
    "        self.alpha = alpha\n",
    "        self.train_args = dict(\n",
    "            training_batch_size=32,\n",
    "            learning_rate=1e-5,\n",
    "            stop_after_epochs=30,\n",
    "            clip_max_norm=5,\n",
    "            max_epochs=int(1e4),\n",
    "            validation_fraction=0.1,\n",
    "        )\n",
    "        self.train_args.update(train_args)\n",
    "        self.device = device\n",
    "\n",
    "        self.embedding_net.to(self.device)\n",
    "\n",
    "        self.loss_fn = ExpLoss()\n",
    "        self.best_val = float(\"inf\")\n",
    "        self.model = None\n",
    "\n",
    "    def _loss(self, model, theta, x):\n",
    "        \"\"\"Compute the loss function for a given model.\"\"\"\n",
    "        logK = model(x)\n",
    "        return self.loss_fn(logK, theta.view(-1, 1))\n",
    "\n",
    "    def _train_epoch(self, model, train_loader, val_loader, optimizer):\n",
    "        \"\"\"Train a single epoch of a neural network model.\"\"\"\n",
    "        model.train()\n",
    "        loss_train, count_train = [], 0\n",
    "        for x, theta in train_loader:\n",
    "            x, theta = x.to(self.device), theta.to(self.device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = self._loss(model, theta, x)\n",
    "            loss.backward()\n",
    "\n",
    "            norm = nn.utils.clip_grad_norm_(model.parameters(), self.train_args[\"clip_max_norm\"])\n",
    "\n",
    "            if torch.isfinite(norm):\n",
    "                optimizer.step()\n",
    "            # Record\n",
    "            loss_train.append(loss.item() * len(theta))\n",
    "            count_train += len(theta)\n",
    "        loss_train = sum(loss_train) / count_train\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss_val, count_val = [], 0\n",
    "            for x, theta in val_loader:\n",
    "                x, theta = x.to(self.device), theta.to(self.device)\n",
    "                loss_val.append(self._loss(model, theta, x).item() * len(theta))\n",
    "                count_val += len(theta)\n",
    "        loss_val = sum(loss_val) / count_val\n",
    "        return loss_train, loss_val\n",
    "\n",
    "    def train(self, loader1, loader2, show_progress_bars=True):\n",
    "        \"\"\"Trains the evidence network.\n",
    "\n",
    "        Args:\n",
    "            loader1: A data loader object for the first model. Must have a\n",
    "                     `get_all_data()` method.\n",
    "            loader2: A data loader object for the second model.\n",
    "            show_progress_bars (bool): Whether to display tqdm progress bars.\n",
    "        \"\"\"\n",
    "        # Aggregate data from different models, and label them\n",
    "        # Assumes loaders have a 'get_all_data' method returning numpy arrays\n",
    "        x1 = loader1.get_all_data().astype(np.float32)\n",
    "        x2 = loader2.get_all_data().astype(np.float32)\n",
    "        x = np.concatenate([x1, x2], axis=0)\n",
    "        labels = np.concatenate([np.zeros(len(x1)), np.ones(len(x2))], axis=0)\n",
    "\n",
    "        # Train/Validation split\n",
    "        indices = np.random.permutation(len(x))\n",
    "        val_size = int(len(x) * self.train_args[\"validation_fraction\"])\n",
    "        val_indices, train_indices = indices[:val_size], indices[val_size:]\n",
    "        x_train, labels_train = x[train_indices], labels[train_indices]\n",
    "        x_val, labels_val = x[val_indices], labels[val_indices]\n",
    "\n",
    "        # Create data loaders\n",
    "        train_data = TensorDataset(torch.tensor(x_train), torch.tensor(labels_train))\n",
    "        val_data = TensorDataset(torch.tensor(x_val), torch.tensor(labels_val))\n",
    "        train_loader = DataLoader(\n",
    "            train_data,\n",
    "            batch_size=self.train_args[\"training_batch_size\"],\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_data,\n",
    "            batch_size=self.train_args[\"training_batch_size\"],\n",
    "            shuffle=False,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "        # Determine the input dimension for the dense network\n",
    "        if not isinstance(self.embedding_net, nn.Identity):\n",
    "            with torch.no_grad():\n",
    "                # Use a single-item batch to find the output dimension\n",
    "                sample_input = next(iter(train_loader))[0].to(self.device)\n",
    "                embedded_output = self.embedding_net(sample_input)\n",
    "                ndim = embedded_output.shape[-1]\n",
    "        else:\n",
    "            # If no embedding net, the input dim is from the data itself\n",
    "            ndim = x_train.shape[-1]\n",
    "\n",
    "        # Create model, passing the embedding net\n",
    "        model = EvidenceNetwork(\n",
    "            input_size=ndim,\n",
    "            embedding_net=self.embedding_net,\n",
    "            layer_width=self.layer_width,\n",
    "            added_layers=self.added_layers,\n",
    "            batch_norm_flag=self.batch_norm_flag,\n",
    "            alpha=self.alpha,\n",
    "        )\n",
    "        model.to(self.device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=self.train_args[\"learning_rate\"])\n",
    "\n",
    "        # Train model\n",
    "        wait = 0\n",
    "        summary = {\"training_loss\": [], \"validation_loss\": []}\n",
    "        best_model_state = deepcopy(model.state_dict())\n",
    "\n",
    "        with tqdm(\n",
    "            iter(range(self.train_args[\"max_epochs\"])),\n",
    "            unit=\" epochs\",\n",
    "            disable=not show_progress_bars,\n",
    "        ) as tq:\n",
    "            for epoch in tq:\n",
    "                loss_train, loss_val = self._train_epoch(\n",
    "                    model=model,\n",
    "                    train_loader=train_loader,\n",
    "                    val_loader=val_loader,\n",
    "                    optimizer=optimizer,\n",
    "                )\n",
    "                if show_progress_bars:\n",
    "                    tq.set_postfix(loss_train=f\"{loss_train:.4f}\", loss_val=f\"{loss_val:.4f}\")\n",
    "\n",
    "                summary[\"training_loss\"].append(loss_train)\n",
    "                summary[\"validation_loss\"].append(loss_val)\n",
    "\n",
    "                if loss_val < self.best_val:\n",
    "                    self.best_val = loss_val\n",
    "                    best_model_state = deepcopy(model.state_dict())\n",
    "                    wait = 0\n",
    "                elif wait >= self.train_args[\"stop_after_epochs\"]:\n",
    "                    logging.info(f\"Stopping early after {epoch} epochs.\")\n",
    "                    break\n",
    "                else:\n",
    "                    wait += 1\n",
    "            else:\n",
    "                logging.warning(\n",
    "                    f\"Training did not converge in {self.train_args['max_epochs']} epochs.\"\n",
    "                )\n",
    "\n",
    "        summary[\"best_validation_loss\"] = self.best_val\n",
    "        summary[\"epochs_trained\"] = epoch + 1\n",
    "        self.model = model\n",
    "        self.model.load_state_dict(best_model_state)\n",
    "        return summary\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Predict the log-Bayes Ratio for a given input.\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model has not been trained yet. Please call .train() first.\")\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x_tensor = torch.from_numpy(np.atleast_2d(x).astype(np.float32)).to(self.device)\n",
    "            return self.model(x_tensor).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009f477d",
   "metadata": {},
   "source": [
    "Setup Evidence Networks approach between BPASS and LTU-ILI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0adb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = K_EvidenceNetwork()\n",
    "\n",
    "# Create data loaders for two models\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "bpass_dataset = TensorDataset(\n",
    "    torch.tensor(fitter_bpass._X_test), torch.tensor(fitter_bpass._y_test)\n",
    ")\n",
    "bpass_loader = DataLoader(bpass_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# ltu_dataset = TensorDataset(torch.tensor(fitter_p._X_test), torch.tensor(fitter_ltu._y_test))\n",
    "# ltu_loader = DataLoader(ltu_dataset, batch_size=64, shuffle=False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
