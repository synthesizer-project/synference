{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import corner\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import torch\n",
    "from omegaconf import OmegaConf  # To create DictConfig-like objects if needed\n",
    "from scoresbibm.evaluation.eval_task import (\n",
    "    eval_coverage,\n",
    "    eval_inference_task,\n",
    ")\n",
    "from scoresbibm.methods.score_transformer import train_transformer_model\n",
    "from scoresbibm.utils.data_utils import (\n",
    "    load_model,\n",
    "    save_model,\n",
    ")\n",
    "from simformer import GalaxyPhotometryTask, GalaxySimulator\n",
    "from synthesizer.emission_models import (\n",
    "    TotalEmission,\n",
    ")\n",
    "from synthesizer.emission_models.attenuation import Calzetti2000\n",
    "from synthesizer.grid import Grid\n",
    "from synthesizer.instruments import FilterCollection, Instrument\n",
    "from synthesizer.parametric import (\n",
    "    SFH,\n",
    "    ZDist,\n",
    ")  # Need concrete SFH, ZDist classes\n",
    "from unyt import Myr\n",
    "\n",
    "# Example: Define global 'device' if not already defined\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dir = \"/home/tharvey/work/synthesizer_grids/\"\n",
    "grid_name = \"bpass-2.2.1-bin_chabrier03-0.1,300.0_cloudy-c23.01-sps.hdf5\"\n",
    "\n",
    "grid = Grid(grid_name, grid_dir=grid_dir)\n",
    "filter_codes = [\n",
    "    \"JWST/NIRCam.F090W\",\n",
    "    \"JWST/NIRCam.F115W\",\n",
    "    \"JWST/NIRCam.F150W\",\n",
    "    \"JWST/NIRCam.F162M\",\n",
    "    \"JWST/NIRCam.F182M\",\n",
    "    \"JWST/NIRCam.F200W\",\n",
    "    \"JWST/NIRCam.F210M\",\n",
    "    \"JWST/NIRCam.F250M\",\n",
    "    \"JWST/NIRCam.F277W\",\n",
    "    \"JWST/NIRCam.F300M\",\n",
    "    \"JWST/NIRCam.F335M\",\n",
    "    \"JWST/NIRCam.F356W\",\n",
    "    \"JWST/NIRCam.F410M\",\n",
    "    \"JWST/NIRCam.F444W\",\n",
    "]\n",
    "filterset = FilterCollection(filter_codes)\n",
    "instrument = Instrument(\"JWST\", filters=filterset)\n",
    "\n",
    "\n",
    "emission_model_instance = TotalEmission(\n",
    "    grid=grid,\n",
    "    fesc=0.0,\n",
    "    fesc_ly_alpha=0.1,\n",
    "    dust_curve=Calzetti2000(),\n",
    "    dust_emission_model=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup simulator for photometry and prior ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfh_model_class = SFH.LogNormal\n",
    "zdist_model_class = ZDist.DeltaConstant\n",
    "\n",
    "emitter_params_dict = {\"stellar\": [\"tau_v\"]}\n",
    "\n",
    "galaxy_simulator_instance = GalaxySimulator(\n",
    "    sfh_model=sfh_model_class,\n",
    "    zdist_model=zdist_model_class,\n",
    "    grid=grid,\n",
    "    instrument=instrument,\n",
    "    emission_model=emission_model_instance,\n",
    "    emission_model_key=\"total\",\n",
    "    emitter_params=emitter_params_dict,\n",
    "    param_units={\"peak_age\": Myr, \"max_age\": Myr},\n",
    "    normalize_method=None,\n",
    "    output_type=\"photo_fnu\",\n",
    "    out_flux_unit=\"ABmag\",\n",
    ")\n",
    "\n",
    "inputs_list = [\n",
    "    \"redshift\",\n",
    "    \"log_mass\",\n",
    "    \"log10metallicity\",\n",
    "    \"tau_v\",\n",
    "    \"peak_age\",\n",
    "    \"max_age\",\n",
    "    \"tau\",\n",
    "]\n",
    "\n",
    "priors_ranges_dict = {\n",
    "    \"redshift\": (5.0, 12.0),\n",
    "    \"log_mass\": (7.0, 11.0),\n",
    "    \"log10metallicity\": (-3.0, -1.3),\n",
    "    \"tau_v\": (0.0, 2),\n",
    "    \"peak_age\": (0.0, 500.0),\n",
    "    \"max_age\": (500.0, 1000.0),\n",
    "    \"tau\": (0.3, 1.5),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup simulator wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulator_glob(params, return_type=\"tensor\"):\n",
    "    \"\"\"Run the galaxy simulator with given parameters.\"\"\"\n",
    "    if isinstance(params, torch.Tensor):\n",
    "        params = params.cpu().numpy()\n",
    "    if isinstance(params, dict):\n",
    "        pass  # assumes params are correctly keyed\n",
    "    elif isinstance(params, (list, tuple, np.ndarray)):\n",
    "        params = np.squeeze(params)\n",
    "        params = {inputs_list[i]: params[i] for i in range(len(inputs_list))}\n",
    "\n",
    "    phot = galaxy_simulator_instance(\n",
    "        params\n",
    "    )  # This line requires galaxy_simulator_instance\n",
    "\n",
    "    if return_type == \"tensor\":\n",
    "        return torch.tensor(phot[np.newaxis, :], dtype=torch.float32).to(device)\n",
    "    else:\n",
    "        return phot\n",
    "\n",
    "\n",
    "galaxy_task = GalaxyPhotometryTask(\n",
    "    prior_dict=priors_ranges_dict,\n",
    "    param_names_ordered=inputs_list,\n",
    "    run_simulator_fn=run_simulator_glob,  # Pass your actual function\n",
    "    num_filters=len(filter_codes),\n",
    ")\n",
    "\n",
    "# Test data generation\n",
    "print(f\"Theta dim: {galaxy_task.get_theta_dim()}\")\n",
    "print(f\"X dim: {galaxy_task.get_x_dim()}\")\n",
    "data_batch = galaxy_task.get_data(num_samples=3)\n",
    "print(\"Sampled theta (JAX):\", data_batch[\"theta\"])\n",
    "print(\"Shape of theta:\", data_batch[\"theta\"].shape)\n",
    "print(\"Sampled x (JAX):\", data_batch[\"x\"])\n",
    "print(\"Shape of x:\", data_batch[\"x\"].shape)\n",
    "\n",
    "# Test prior sampling directly\n",
    "prior_for_test = galaxy_task.get_prior()\n",
    "theta_samples_torch = prior_for_test.sample((2,))\n",
    "print(\"Direct prior samples (Torch):\", theta_samples_torch)\n",
    "print(\"Log prob of prior samples:\", prior_for_test.log_prob(theta_samples_torch))\n",
    "\n",
    "# Test base mask function\n",
    "mask_fn = galaxy_task.get_base_mask_fn()\n",
    "node_ids_example = jnp.arange(galaxy_task.get_theta_dim() + galaxy_task.get_x_dim())\n",
    "# jax.random.shuffle(jax.random.PRNGKey(0), node_ids_example) # Example of permuted IDs\n",
    "applied_mask = mask_fn(node_ids=node_ids_example, node_meta_data=None)\n",
    "print(\"Base mask applied to node_ids:\", applied_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure model hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration (from config/method/model/score_transformer.yaml)\n",
    "#\n",
    "model_config_dict = {\n",
    "    \"name\": \"ScoreTransformer\",\n",
    "    \"d_model\": 128,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_layers\": 4,\n",
    "    \"d_feedforward\": 256,\n",
    "    \"dropout\": 0.1,\n",
    "    \"max_len\": 5000,  # Adjust based on theta_dim + x_dim\n",
    "    \"tokenizer\": {\"name\": \"LinearTokenizer\", \"encoding_dim\": 64},\n",
    "    \"use_output_scale_fn\": True,\n",
    "    # Add other model-specific parameters as per the YAML\n",
    "}\n",
    "\n",
    "# SDE Configuration (e.g., from config/method/sde/vpsde.yaml)\n",
    "#\n",
    "sde_config_dict = {\n",
    "    \"name\": \"VPSDE\",  # or \"VESDE\"\n",
    "    \"beta_min\": 0.1,\n",
    "    \"beta_max\": 20.0,\n",
    "    \"num_steps\": 1000,\n",
    "    \"T_min\": 1e-05,\n",
    "    \"T_max\": 1.0,\n",
    "}\n",
    "\n",
    "# Training Configuration (from config/method/train/train_score_transformer.yaml)\n",
    "train_config_dict = {\n",
    "    \"learning_rate\": 1e-4,  # Initial learning rate for training # used\n",
    "    \"min_learning_rate\": 1e-6,  # Minimum learning rate for training # used\n",
    "    \"z_score_data\": True,  # Whether to z-score (normalize) the data # used\n",
    "    \"total_number_steps_scaling\": 5,  # Scaling factor for total number of steps # used\n",
    "    \"max_number_steps\": 1e8,  # Maximum number of steps for training # used\n",
    "    \"min_number_steps\": 1e4,  # Minimum number of steps for training # used\n",
    "    \"training_batch_size\": 64,  # Batch size for training # used\n",
    "    \"val_every\": 50,  # Validate every 100 steps # used\n",
    "    \"clip_max_norm\": 10.0,  # Gradient clipping max norm # used\n",
    "    \"condition_mask_fn\": {\n",
    "        \"name\": \"structured_random\"\n",
    "    },  # Use the base mask function defined in the task\n",
    "    \"edge_mask_fn\": {\"name\": \"faithfull\"},\n",
    "    \"validation_fraction\": 0.1,  # Fraction of data to use for validation # used\n",
    "    \"val_repeat\": 5,  # Number of times to repeat validation # used\n",
    "    \"stop_early_count\": 5,  # Number of steps to wait before stopping early # used\n",
    "    \"rebalance_loss\": True,  # Whether to rebalance the loss # used\n",
    "}\n",
    "\n",
    "\n",
    "method_config_dict = {\n",
    "    \"device\": str(device),  # Ensure this matches your device setup\n",
    "    \"sde\": sde_config_dict,\n",
    "    \"model\": model_config_dict,\n",
    "    \"train\": train_config_dict,\n",
    "}\n",
    "\n",
    "# Convert the main method_cfg to OmegaConf DictConfig\n",
    "method_cfg = OmegaConf.create(method_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_task.get_data(num_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup task and generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Instantiating GalaxyPhotometryTask...\")\n",
    "galaxy_task = GalaxyPhotometryTask(\n",
    "    prior_dict=priors_ranges_dict,\n",
    "    param_names_ordered=inputs_list,\n",
    "    run_simulator_fn=run_simulator_glob,\n",
    "    num_filters=len(filter_codes),\n",
    "    backend=\"jax\",  # Or \"torch\"\n",
    ")\n",
    "print(\"Task instantiated.\")\n",
    "\n",
    "# --- 2. Generate Data ---\n",
    "num_training_simulations = 5000\n",
    "print(f\"Generating {num_training_simulations} training simulations...\")\n",
    "# .get_data() returns a dict with JAX arrays if backend is \"jax\"\n",
    "training_data = galaxy_task.get_data(num_samples=num_training_simulations)\n",
    "theta_train = training_data[\"theta\"]\n",
    "x_train = training_data[\"x\"]\n",
    "print(f\"Data generated: theta shape {theta_train.shape}, x shape {x_train.shape}\")\n",
    "\n",
    "# (Optional) Generate validation data if your train_config.val_split is 0\n",
    "num_validation_simulations = 20\n",
    "validation_data = galaxy_task.get_data(num_samples=num_validation_simulations)\n",
    "theta_val = validation_data[\"theta\"]\n",
    "x_val = validation_data[\"x\"]\n",
    "\n",
    "# --- 3. Set RNG Seed for JAX ---\n",
    "rng_seed_for_training = 0\n",
    "master_rng_key = jax.random.PRNGKey(rng_seed_for_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Train the Model ---\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trained_score_model = train_transformer_model(\n",
    "    task=galaxy_task,\n",
    "    data=training_data,  # Expects dict {\"theta\": ..., \"x\": ...} with JAX arrays\n",
    "    method_cfg=method_cfg,  # The OmegaConf object created above\n",
    "    rng=master_rng_key,\n",
    ")\n",
    "print(\n",
    "    \"Training finished. Model returned by train_transformer_model:\",\n",
    "    type(trained_score_model),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corner = True\n",
    "import corner\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Take test observation\n",
    "theta_dim = galaxy_task.get_theta_dim()\n",
    "x_dim = galaxy_task.get_x_dim()\n",
    "# Mask for posterior: theta is unknown (0), x is known (1)\n",
    "posterior_condition_mask = jnp.array([0] * theta_dim + [1] * x_dim, dtype=jnp.bool_)\n",
    "for i, xobs in enumerate(x_val):\n",
    "    x_o = jnp.array([xobs], dtype=jnp.float32)\n",
    "    samples = trained_score_model.sample_batched(\n",
    "        num_samples=1000,\n",
    "        x_o=x_o,\n",
    "        rng=master_rng_key,\n",
    "        condition_mask=posterior_condition_mask,\n",
    "    )\n",
    "    samples = np.array(samples, dtype=np.float32)\n",
    "    theta = np.array(theta_val[i], dtype=np.float32)\n",
    "\n",
    "    if plot_corner:\n",
    "        truth = np.array(theta_val[i], dtype=np.float32)\n",
    "\n",
    "        corner.corner(\n",
    "            samples,\n",
    "            labels=galaxy_task.param_names_ordered,\n",
    "            show_titles=True,\n",
    "            truths=truth,\n",
    "            quantiles=[0.16, 0.5, 0.84],\n",
    "            title_kwargs={\"fontsize\": 12},\n",
    "        )\n",
    "        plt.savefig(\n",
    "            f\"/home/tharvey/work/ltu-ili_testing/models/simformer/plots/corner_plot_{i}.png\"\n",
    "        )\n",
    "\"\"\"\n",
    "import pickle\n",
    "with open(\"trained_galaxy_score_model_params.pkl\", \"wb\") as f:\n",
    "    pickle.dump(trained_score_model.score_model_params, f)\n",
    "print(\"Model parameters saved (example).\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute C2ST metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoresbibm.evaluation.eval_metrics import c2st\n",
    "from scoresbibm.evaluation.eval_task import eval_inference_task\n",
    "\n",
    "eval_inference_task(\n",
    "    task=galaxy_task,\n",
    "    model=trained_score_model,\n",
    "    metric_fn=c2st,  # Use the c2st metric function\n",
    "    metric_params={\"condition_mask_fn\": \"posterior\"},\n",
    "    rng=master_rng_key,\n",
    "    num_samples=1000,\n",
    "    num_evaluations=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_condition_mask_fn(str):\n",
    "    \"\"\"Get the condition mask function based on the provided string.\"\"\"\n",
    "    return (\n",
    "        galaxy_task.get_base_mask_fn()\n",
    "        if str == \"base\"\n",
    "        else galaxy_task.get_joint_mask_fn()\n",
    "    )\n",
    "\n",
    "\n",
    "metric_values, eval_time = eval_coverage(\n",
    "    task=galaxy_task,\n",
    "    model=trained_score_model,\n",
    "    metric_params={\n",
    "        \"num_samples\": 1000,  # Number of samples to draw for coverage evaluation\n",
    "        \"num_evaluations\": 50,\n",
    "        \"condition_mask_fn\": \"posterior\",  # posterior, joint, likelihood,\n",
    "        # random or structured random\n",
    "        \"num_bins\": 20,  # Number of bins for histogram\n",
    "        \"sample_kwargs\": {},\n",
    "        \"log_prob_kwargs\": {},\n",
    "        \"batch_size\": 64,  # Batch size for sampling\n",
    "    },\n",
    "    rng=master_rng_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metric_values[0], metric_values[1], marker=\"o\", label=\"Coverage\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Ideal Coverage\")\n",
    "plt.xlabel(\"Predicted Percentile\")\n",
    "plt.ylabel(\"Empirical Percentile\")\n",
    "plt.legend()\n",
    "plt.savefig(\"/home/tharvey/work/ltu-ili_testing/models/simformer/plots/coverage_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(\n",
    "    model=trained_score_model,\n",
    "    dir_path=\"/home/tharvey/work/ltu-ili_testing/models/simformer/\",\n",
    "    model_id=\"simformer_galaxy_score_model_test_v1\",\n",
    ")\n",
    "\n",
    "# also need to pickle - num_filters, prior_dict, run_simulator_fn, param_names_ordered,\n",
    "# backend\n",
    "\n",
    "save_dict = {\n",
    "    \"_x_dim\": galaxy_task.get_x_dim(),\n",
    "    \"_theta_dim\": galaxy_task.get_theta_dim(),\n",
    "    \"prior_dict\": priors_ranges_dict,\n",
    "    \"param_names_ordered\": galaxy_task.param_names_ordered,\n",
    "    \"backend\": galaxy_task.backend,\n",
    "    \"method_config_dict\": method_config_dict,\n",
    "}\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "dump(\n",
    "    save_dict,\n",
    "    \"/home/tharvey/work/ltu-ili_testing/models/simformer/models/data_simformer_galaxy_score_model_test_v1.joblib\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model = load_model(\n",
    "    dir_path=\"/home/tharvey/work/ltu-ili_testing/models/simformer/\",\n",
    "    model_id=\"simformer_galaxy_score_model_test_v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corner = True\n",
    "import corner\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Take test observation\n",
    "theta_dim = galaxy_task.get_theta_dim()\n",
    "x_dim = galaxy_task.get_x_dim()\n",
    "# Mask for posterior: theta is unknown (0), x is known (1)\n",
    "posterior_condition_mask = jnp.array([0] * theta_dim + [1] * x_dim, dtype=jnp.bool_)\n",
    "for i, xobs in enumerate(x_val):\n",
    "    x_o = jnp.array([xobs], dtype=jnp.float32)\n",
    "    samples = trained_score_model.sample_batched(\n",
    "        num_samples=1000,\n",
    "        x_o=x_o,\n",
    "        rng=master_rng_key,\n",
    "        condition_mask=posterior_condition_mask,\n",
    "    )\n",
    "    samples = np.array(samples, dtype=np.float32)\n",
    "    theta = np.array(theta_val[i], dtype=np.float32)\n",
    "\n",
    "    if plot_corner:\n",
    "        truth = np.array(theta_val[i], dtype=np.float32)\n",
    "\n",
    "        corner.corner(\n",
    "            samples,\n",
    "            labels=galaxy_task.param_names_ordered,\n",
    "            show_titles=True,\n",
    "            truths=truth,\n",
    "            quantiles=[0.16, 0.5, 0.84],\n",
    "            title_kwargs={\"fontsize\": 12},\n",
    "        )\n",
    "        plt.savefig(\n",
    "            f\"/home/tharvey/work/ltu-ili_testing/models/simformer/plots/corner_plot_{i}.png\"\n",
    "        )\n",
    "\"\"\"\n",
    "import pickle\n",
    "with open(\"trained_galaxy_score_model_params.pkl\", \"wb\") as f:\n",
    "    pickle.dump(trained_score_model.score_model_params, f)\n",
    "print(\"Model parameters saved (example).\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_score_model.z_score_params"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
