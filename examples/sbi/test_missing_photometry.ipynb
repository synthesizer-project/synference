{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sbifitter import MissingPhotometryHandler, SBI_Fitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_path = \"/home/tharvey/work/output/BPASS_Chab_LogNorm_5_z_12_phot_grid2.hdf5\"\n",
    "\n",
    "fitter = SBI_Fitter.init_from_hdf5(\n",
    "    \"BPASS_Chab_LogNorm_5_z_12_phot_grid2\", grid_path, return_output=False\n",
    ")\n",
    "\n",
    "fitter.load_model_from_pkl(\n",
    "    \"/home/tharvey/work/ltu-ili_testing/models/BPASS_Chab_LogNorm_5_z_12_phot_grid2\",\n",
    "    set_self=True,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a random index from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.choice(fitter._test_indices)\n",
    "\n",
    "phot = fitter.feature_array[index]\n",
    "true_params = fitter.fitted_parameter_array[index]\n",
    "\n",
    "for i in range(len(phot)):\n",
    "    print(fitter.feature_names[i], phot[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(phot, dtype=bool)\n",
    "# Let's pretend we don't have F460M\n",
    "mask[-4] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of the MissingPhotomeryHandler class from our sbi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phot_sampler = MissingPhotometryHandler.init_from_sbifitter(fitter, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will take our training data, pretend we don't have one filter, and see how well we can recover the missing flux in that filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "recovered = []\n",
    "\n",
    "iters = np.random.choice(fitter._test_indices, size=200, replace=False)\n",
    "\n",
    "for idx in tqdm(iters):\n",
    "    phot = fitter.feature_array[idx]\n",
    "\n",
    "    obs = {\n",
    "        \"mags_sbi\": phot,\n",
    "        \"mags_unc_sbi\": np.ones_like(phot) * 0.1,  # Say we have a 0.1 mag error\n",
    "        \"missing_mask\": mask,\n",
    "    }\n",
    "\n",
    "    out = phot_sampler.process_observation(obs, noise_generator=None)\n",
    "    true.append(phot[mask])\n",
    "    recovered.append(np.mean(out[\"missing_photometry_dist\"], axis=1))\n",
    "\n",
    "true = np.array(true)\n",
    "recovered = np.array(recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.array(true)[:, 0], np.array(true)[:, 0] - recovered, alpha=1)\n",
    "plt.ylabel(r\"$\\Delta$ Recovered Mag - True Mag\")\n",
    "plt.xlabel(\"True Mag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(out[\"missing_photometry_dist\"], bins=10)\n",
    "plt.vlines(out[\"missing_photometry_dist\"].mean(), 0, 20, color=\"r\", label=\"Mean\")\n",
    "plt.vlines(phot[-4], 0, 20, color=\"g\", label=\"True Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a more extreme example, where we remove many filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "recovered = []\n",
    "\n",
    "iters = np.random.choice(fitter._test_indices, size=200, replace=False)\n",
    "\n",
    "for idx in tqdm(iters):\n",
    "    phot = fitter.feature_array[idx]\n",
    "\n",
    "    obs = {\n",
    "        \"mags_sbi\": phot,\n",
    "        \"mags_unc_sbi\": np.ones_like(phot) * 0.1,  # Say we have a 0.1 mag error\n",
    "        \"missing_mask\": mask,\n",
    "    }\n",
    "\n",
    "    out = phot_sampler.process_observation(obs, noise_generator=None)\n",
    "    true.append(phot[mask])\n",
    "    recovered.append(np.mean(out[\"missing_photometry_dist\"], axis=1))\n",
    "\n",
    "true = np.array(true)\n",
    "recovered = np.array(recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pretend we only have the JADES filters\n",
    "\n",
    "mask = [1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1]\n",
    "mask = np.array(mask, dtype=bool)\n",
    "\n",
    "# Ok, pretending we only had the JADES filters ran into\n",
    "# issues with the KDE's and low dimenionality.\n",
    "# Probably can't stretch the model that far.\n",
    "\n",
    "# Let's just hide three filters.\n",
    "\n",
    "mask = np.zeros_like(phot, dtype=bool)\n",
    "mask[-3] = True\n",
    "mask[-5] = True\n",
    "mask[4] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "recovered = []\n",
    "\n",
    "iters = np.random.choice(fitter._test_indices, size=30, replace=False)\n",
    "\n",
    "for idx in tqdm(iters):\n",
    "    phot = fitter.feature_array[idx]\n",
    "\n",
    "    obs = {\n",
    "        \"mags_sbi\": phot,\n",
    "        \"mags_unc_sbi\": np.ones_like(phot) * 0.1,  # Say we have a 0.1 mag error\n",
    "        \"missing_mask\": mask,\n",
    "    }\n",
    "\n",
    "    out = phot_sampler.process_observation(obs, noise_generator=None)\n",
    "    true.append(phot[mask])\n",
    "    recovered.append(np.mean(out[\"missing_photometry_dist\"], axis=0))\n",
    "\n",
    "true = np.array(true)\n",
    "recovered = np.array(recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot for each missing filter the discrepancy between the median recovered flux and the true flux. The closer to zero, the better the recovery. For this naive case, we can recover the flux within around 0.01 magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, np.sum(mask), figsize=(20, 5))\n",
    "\n",
    "for i in range(np.sum(mask)):\n",
    "    ax[i].scatter(np.array(true)[:, i], np.array(true)[:, i] - recovered[:, i], alpha=1)\n",
    "    ax[i].set_ylabel(r\"$\\Delta$ Recovered Mag - True Mag\")\n",
    "    ax[i].set_xlabel(\"True Mag\")\n",
    "    missing_filter_idx = np.where(mask)[0][i]\n",
    "    missing_filter_name = fitter.feature_names[missing_filter_idx]\n",
    "    ax[i].set_title(missing_filter_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_path = \"\"\"/home/tharvey/work/output/\n",
    "            grid_Pop_II_LogNormal_SFH_5_z_12_logN_5.0_BPASS_Chab_v1.hdf5\"\"\"\n",
    "\n",
    "fitter = SBI_Fitter.init_from_hdf5(\"test\", grid_path, return_output=False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
