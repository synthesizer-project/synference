{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table\n",
    "\n",
    "from sbifitter import SBI_Fitter\n",
    "\n",
    "file_path = os.path.dirname(os.path.realpath(os.path.abspath(\"\")))\n",
    "grid_folder = os.path.join(os.path.dirname(file_path), \"grids\")\n",
    "output_folder = os.path.join(os.path.dirname(file_path), \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_path = f\"{grid_folder}/grid_BPASS_Chab_DenseBasis_SFH_0.0_z_12_logN_4.0_CF00_v1.hdf5\"  # noqa\n",
    "\n",
    "fitter = SBI_Fitter.init_from_hdf5(\n",
    "    \"BPASS_Chab_DenseBasis_0.0_z_12_test\",\n",
    "    grid_path,\n",
    "    return_output=False,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "model_name = \"BPASS_Chab_DelayedExpSFH_0.01_z_12_CF00_v1sbipp_settings_posterior\"\n",
    "model_name = \"BPASS_Chab_DelayedExpSFH_0.01_z_12_CF00_v1sbipp_settings_nsf_zfix_posterior\"\n",
    "model_name = \"BPASS_Chab_DenseBasis_SFH_0.0_z_12_logN_4.0_CF00_v1_sbi\"\n",
    "append = \"_sbi\"\n",
    "\n",
    "fitter.load_model_from_pkl(f\"{output_folder}/{model_name}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "f = \"/cosma7/data/dp276/dc-harv3/work/sbifitter/models/BPASS_Chab_DenseBasis_SFH_0.0_z_12_logN_4.0_CF00_v1_sbi/BPASS_Chab_DenseBasis_SFH_0.0_z_12_logN_4.0_CF00_v1_sbi_20250701_125114_posterior.pkl\"  # noqa E501\n",
    "# with open(f, \"rb\") as f:\n",
    "# Use CPU_Unpickler to load the content\n",
    "# This is necessary if the original pickler used torch's _load_from_bytes\n",
    "# which is not compatible with CPU Unpickling\n",
    "# contents = CPU_Unpickler(f).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the cheeky thing of setting the flags explicity\n",
    "\n",
    "fitter.feature_array_flags = dict(\n",
    "    normalize_method=None,\n",
    "    extra_features=[],\n",
    "    normed_flux_units=\"AB\",\n",
    "    normalization_unit=\"AB\",\n",
    "    scatter_fluxes=True,\n",
    "    empirical_noise_models=True,\n",
    "    depths=None,\n",
    "    include_errors_in_feature_array=True,\n",
    "    min_flux_pc_error=0.9,\n",
    "    simulate_missing_fluxes=False,\n",
    "    missing_flux_value=99.0,\n",
    "    missing_flux_fraction=0.9,\n",
    "    missing_flux_options=None,\n",
    "    include_flags_in_feature_array=False,\n",
    "    override_phot_grid=None,\n",
    "    override_phot_grid_units=None,\n",
    "    norm_mag_limit=40,\n",
    "    remove_nan_inf=None,\n",
    "    parameters_to_remove=[],\n",
    "    photometry_to_remove=None,\n",
    "    drop_dropouts=False,\n",
    "    drop_dropout_fraction=1.0,\n",
    "    raw_photometry_names=fitter.feature_names[:9],\n",
    "    error_names=fitter.feature_names[9:],\n",
    "    flag_names=[],\n",
    "    norm_name=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on real galaxies\n",
    "\n",
    "Firstly load our real catalogue, and setup a mapping between feature names and column names using a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"\"\"/home/tharvey/Downloads/JADES-Deep-GS_MASTER_Sel-f277W+f356W+f444W\n",
    "            _v9_loc_depth_masked_10pc_EAZY_matched_selection_ext_src_UV.fits\"\"\"\n",
    "table = Table.read(file)\n",
    "\n",
    "new_table = Table()\n",
    "\n",
    "\n",
    "def mag_cols_syntax(band):\n",
    "    \"\"\"Returns the syntax for the magnitude columns in the table.\"\"\"\n",
    "    return f\"MAG_APER_{band}_aper_corr\"\n",
    "\n",
    "\n",
    "def magerr_cols_syntax(band):\n",
    "    \"\"\"Returns the syntax for the magnitude error columns in the table.\"\"\"\n",
    "    return f\"MAGERR_APER_{band}_u1_loc_depth\"\n",
    "\n",
    "\n",
    "table = table[\n",
    "    (table[\"selected_gal_all_criteria_delta_chi2_4_fsps_larson_no_bd\"])\n",
    "    & (table[\"sigma_f444W\"][:, 0] > 10)\n",
    "    & (table[\"sigma_f277W\"][:, 0] > 10)\n",
    "    & (table[\"sigma_f356W\"][:, 0] > 10)\n",
    "]\n",
    "bands = [i.split(\"_\")[-1] for i in table.colnames if i.startswith(\"loc_depth\")]\n",
    "new_band_names = [\"HST/ACS_WFC.F606W\"] + [f\"JWST/NIRCam.{band.upper()}\" for band in bands[1:]]\n",
    "\n",
    "for band in bands:\n",
    "    new_table[mag_cols_syntax(band)] = table[mag_cols_syntax(band)][:, 0]\n",
    "    new_table[magerr_cols_syntax(band)] = table[magerr_cols_syntax(band)][:, 0]\n",
    "\n",
    "new_table[\"z_eazy\"] = table[\"zbest_fsps_larson\"]\n",
    "\n",
    "conversion_dict = {mag_cols_syntax(band): new_band for band, new_band in zip(bands, new_band_names)}\n",
    "conversion_dict.update(\n",
    "    {magerr_cols_syntax(band): f\"unc_{new_band}\" for band, new_band in zip(bands, new_band_names)}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Features is catalogue converted to match features. Mask is a 1D boolean array showing rows which were removed\n",
    "due to missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_features, obs_mask = fitter.create_features_from_observations(\n",
    "    new_table, columns_to_feature_names=conversion_dict, flux_units=\"AB\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if any observations are out of distribution given our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbifitter import test_out_of_distribution\n",
    "\n",
    "a, b = test_out_of_distribution(fitter.feature_array, obs_features, sigma_threshold=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can let the code do this internally and it will add the columns to the table for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = fitter.fit_catalogue(\n",
    "    new_table,\n",
    "    columns_to_feature_names=conversion_dict,\n",
    "    flux_units=\"AB\",\n",
    "    sample_method=\"direct\",\n",
    "    timeout_seconds_per_row=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_masked = output[output[\"redshift_50\"] != 0.0]\n",
    "plt.scatter(output_masked[\"z_eazy\"], output_masked[\"redshift_50\"])\n",
    "plt.xlabel(\"z_eazy\")\n",
    "\n",
    "plt.plot(plt.xlim(), plt.xlim(), ls=\"--\", color=\"k\")\n",
    "plt.ylabel(\"z_sbi\")\n",
    "plt.xlabel(\"z_eazy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(obs_features, dtype=torch.float32, device=fitter.device)\n",
    "fitter.posteriors.sample_batched(x=x, sample_shape=(1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter._prior.dist.low, fitter._prior.dist.high\n",
    "\n",
    "for i in range(len(fitter.simple_fitted_parameter_names)):\n",
    "    print(\n",
    "        fitter.simple_fitted_parameter_names[i],\n",
    "        fitter._prior.dist.low[i].item(),\n",
    "        fitter._prior.dist.high[i].item(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# max\n",
    "(\n",
    "    7.1637e00,\n",
    "    8.4432e00,\n",
    "    3.2980e-02,\n",
    "    6.2265e-02,\n",
    "    1.6504e03,\n",
    ")\n",
    "5.2127e03, -1.4724e00\n",
    "\n",
    "# min\n",
    "(\n",
    "    9.8384e-01,\n",
    "    7.4450e00,\n",
    "    -5.1909e-01,\n",
    "    -3.3764e-01,\n",
    "    1.9143e02,\n",
    ")\n",
    "5.1072e02, -3.3405e00\n",
    "\n",
    "# mean\n",
    "a = [\n",
    "    6.1481e00,\n",
    "    8.1235e00,\n",
    "    -7.4607e-02,\n",
    "    -5.8678e-02,\n",
    "    9.8795e02,\n",
    "    7.5202e02,\n",
    "    -2.5445e00,\n",
    "]\n",
    "a = torch.tensor(a, dtype=torch.float32, device=fitter.device)\n",
    "\n",
    "help(fitter._prior.support.check)  # (a)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
