{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from unyt import um\n",
    "\n",
    "from synference import SBI_Fitter\n",
    "from synference.utils import transform_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class LogCoshLoss(nn.Module):\n",
    "    \"\"\"Log-Cosh Loss Function.\n",
    "\n",
    "    This loss is smoother than L2 loss and less sensitive to outliers.\n",
    "    It is twice differentiable everywhere, unlike Huber loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the LogCoshLoss.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"Compute the Log-Cosh loss between predictions and true values.\"\"\"\n",
    "        # The `torch.log(torch.cosh(x))` is numerically stable enough for typical network outputs.\n",
    "        diff = y_pred - y_true\n",
    "        return torch.log(torch.cosh(diff)).sum()\n",
    "\n",
    "\n",
    "class SpenderLikeVAE(nn.Module):\n",
    "    \"\"\"A VAE with encoder architecture matching SPENDER.\n",
    "\n",
    "    The encoder consists of:\n",
    "    1. A 3-layer 1D CNN with increasing kernel sizes, instance normalization,\n",
    "       PReLU activation, dropout, and max pooling.\n",
    "    2. A dot-product attention mechanism over the wavelength dimension.\n",
    "    3. A 3-layer MLP to produce the parameters of the latent distribution.\n",
    "\n",
    "    The decoder is a simple 3-layer MLP that reconstructs the spectrum from a\n",
    "    latent sample.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim=1001, latent_dim=16, dropout=0.1):\n",
    "        \"\"\"Initialize the Spender-like VAE.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # --- ENCODER (SPENDER-style) ---\n",
    "        # 1. Convolutional Frontend with normalization and dropout\n",
    "        filters = [128, 256, 512]\n",
    "        sizes = [5, 11, 21]\n",
    "\n",
    "        # Build conv blocks matching SPENDER\n",
    "        self.conv_blocks = nn.ModuleList()\n",
    "        for i in range(len(filters)):\n",
    "            f_in = 1 if i == 0 else filters[i - 1]\n",
    "            f_out = filters[i]\n",
    "            kernel_size = sizes[i]\n",
    "            padding = kernel_size // 2\n",
    "\n",
    "            conv_block = nn.Sequential(\n",
    "                nn.Conv1d(\n",
    "                    in_channels=f_in, out_channels=f_out, kernel_size=kernel_size, padding=padding\n",
    "                ),\n",
    "                nn.InstanceNorm1d(f_out),\n",
    "                nn.PReLU(f_out),\n",
    "                nn.Dropout(p=dropout),\n",
    "            )\n",
    "            self.conv_blocks.append(conv_block)\n",
    "\n",
    "        # Pooling layers (match SPENDER)\n",
    "        self.pool1 = nn.MaxPool1d(sizes[0], padding=sizes[0] // 2)\n",
    "        self.pool2 = nn.MaxPool1d(sizes[1], padding=sizes[1] // 2)\n",
    "\n",
    "        # Calculate the length after pooling\n",
    "        conv_output_len = input_dim\n",
    "        # After pool1\n",
    "        conv_output_len = (conv_output_len + 2 * (sizes[0] // 2)) // sizes[0]\n",
    "        # After pool2\n",
    "        conv_output_len = (conv_output_len + 2 * (sizes[1] // 2)) // sizes[1]\n",
    "\n",
    "        # 2. Attention Module\n",
    "        # Split channels into h and k for attention\n",
    "        self.n_feature = filters[-1] // 2\n",
    "\n",
    "        # 3. MLP for latent space parameters (match SPENDER structure)\n",
    "        n_hidden = [128, 64, 32]\n",
    "\n",
    "        self.enc_fc1 = nn.Linear(self.n_feature, n_hidden[0])\n",
    "        self.enc_act1 = nn.PReLU(n_hidden[0])\n",
    "        self.enc_drop1 = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.enc_fc2 = nn.Linear(n_hidden[0], n_hidden[1])\n",
    "        self.enc_act2 = nn.PReLU(n_hidden[1])\n",
    "        self.enc_drop2 = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.enc_fc3 = nn.Linear(n_hidden[1], n_hidden[2])\n",
    "        self.enc_act3 = nn.PReLU(n_hidden[2])\n",
    "        self.enc_drop3 = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Output layers for mu and log_var\n",
    "        self.enc_fc_mu = nn.Linear(n_hidden[2], latent_dim)\n",
    "        self.enc_fc_log_var = nn.Linear(n_hidden[2], latent_dim)\n",
    "\n",
    "        # --- DECODER ---\n",
    "        # A simple 3-layer MLP as described in the spender paper\n",
    "        self.dec_fc1 = nn.Linear(latent_dim, 128)\n",
    "        self.dec_fc2 = nn.Linear(128, 256)\n",
    "        self.dec_fc3 = nn.Linear(256, input_dim)\n",
    "\n",
    "        # Decoder activation\n",
    "        self.act_fn = nn.SiLU()\n",
    "\n",
    "    def attention(self, x):\n",
    "        \"\"\"Attention mechanism.\n",
    "\n",
    "        Dot-product attention mechanism as described in the SPENDER paper.\n",
    "        Splits channels into two halves (h and k), computes softmax attention\n",
    "        weights from k, and applies them to h.\n",
    "        \"\"\"\n",
    "        # x shape: (batch, channels, length)\n",
    "        # Split channels into two halves\n",
    "        h = x[:, : self.n_feature, :]\n",
    "        k = x[:, self.n_feature :, :]\n",
    "\n",
    "        # Softmax operates on the wavelength dimension (last dimension)\n",
    "        softmax_k = F.softmax(k, dim=-1)\n",
    "\n",
    "        # Element-wise product\n",
    "        e = h * softmax_k\n",
    "\n",
    "        # Sum across wavelength dimension (like SPENDER)\n",
    "        e = torch.sum(e, dim=2)\n",
    "\n",
    "        return e\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode input spectrum to latent distribution parameters.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor, shape (batch, input_dim)\n",
    "            Input spectra\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        mu : torch.Tensor, shape (batch, latent_dim)\n",
    "            Mean of latent distribution\n",
    "        log_var : torch.Tensor, shape (batch, latent_dim)\n",
    "            Log variance of latent distribution\n",
    "        \"\"\"\n",
    "        # Reshape input for Conv1d: (batch, channels, length)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # CNN frontend with pooling (SPENDER-style)\n",
    "        x = self.pool1(self.conv_blocks[0](x))\n",
    "        x = self.pool2(self.conv_blocks[1](x))\n",
    "        x = self.conv_blocks[2](x)\n",
    "\n",
    "        # Attention (reduces wavelength dimension)\n",
    "        x = self.attention(x)\n",
    "\n",
    "        # MLP with PReLU activations and dropout\n",
    "        x = self.enc_drop1(self.enc_act1(self.enc_fc1(x)))\n",
    "        x = self.enc_drop2(self.enc_act2(self.enc_fc2(x)))\n",
    "        x = self.enc_drop3(self.enc_act3(self.enc_fc3(x)))\n",
    "\n",
    "        # Output mu and log_var\n",
    "        mu = self.enc_fc_mu(x)\n",
    "        log_var = self.enc_fc_log_var(x)\n",
    "\n",
    "        return mu, log_var\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"Reparameterization trick for VAE.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mu : torch.Tensor\n",
    "            Mean of latent distribution\n",
    "        log_var : torch.Tensor\n",
    "            Log variance of latent distribution\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        z : torch.Tensor\n",
    "            Sampled latent vector\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode latent vector to reconstructed spectrum.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : torch.Tensor, shape (batch, latent_dim)\n",
    "            Latent vectors\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        reconstructed_x : torch.Tensor, shape (batch, input_dim)\n",
    "            Reconstructed spectra\n",
    "        \"\"\"\n",
    "        x = self.act_fn(self.dec_fc1(z))\n",
    "        x = self.act_fn(self.dec_fc2(x))\n",
    "        # No final activation to allow for arbitrary flux values\n",
    "        reconstructed_x = self.dec_fc3(x)\n",
    "        return reconstructed_x\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the VAE.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor, shape (batch, input_dim)\n",
    "            Input spectra\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        reconstructed_x : torch.Tensor, shape (batch, input_dim)\n",
    "            Reconstructed spectra\n",
    "        mu : torch.Tensor, shape (batch, latent_dim)\n",
    "            Mean of latent distribution\n",
    "        log_var : torch.Tensor, shape (batch, latent_dim)\n",
    "            Log variance of latent distribution\n",
    "        \"\"\"\n",
    "        mu, log_var = self.encode(x)\n",
    "        return mu\n",
    "\n",
    "    def forward_vae(self, x):\n",
    "        \"\"\"Full VAE forward pass for training (regardless of embedding_mode).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor, shape (batch, input_dim)\n",
    "            Input spectra\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        reconstructed_x : torch.Tensor, shape (batch, input_dim)\n",
    "            Reconstructed spectra\n",
    "        mu : torch.Tensor, shape (batch, latent_dim)\n",
    "            Mean of latent distribution\n",
    "        log_var : torch.Tensor, shape (batch, latent_dim)\n",
    "            Log variance of latent distribution\n",
    "        \"\"\"\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return self.decode(z), mu, log_var\n",
    "\n",
    "    @property\n",
    "    def n_parameters(self):\n",
    "        \"\"\"Number of trainable parameters in this model.\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def vae_loss(recons_x, x, mu, log_var):\n",
    "    \"\"\"Calculates the VAE loss using the specified LogCoshLoss for reconstruction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    recons_x : torch.Tensor\n",
    "        Reconstructed spectra\n",
    "    x : torch.Tensor\n",
    "        Original spectra\n",
    "    mu : torch.Tensor\n",
    "        Mean of latent distribution\n",
    "    log_var : torch.Tensor\n",
    "        Log variance of latent distribution\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    loss : torch.Tensor\n",
    "        Total VAE loss (reconstruction + KL divergence)\n",
    "    \"\"\"\n",
    "    log_cosh_loss = LogCoshLoss()\n",
    "    recon_loss = log_cosh_loss(recons_x, x)\n",
    "\n",
    "    # KL Divergence\n",
    "    kld_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "    return recon_loss + kld_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = SBI_Fitter.init_from_hdf5(\n",
    "    \"Spectra_BPASS_Chab_Continuity_SFH_0.01_z_14_logN_4.4_Calzetti_v4_multinode\",\n",
    "    \"/cosma7/data/dp276/dc-harv3/work/sbi_grids/grid_spectra_BPASS_Chab_Continuity_SFH_0.01_z_14_logN_4.4_Calzetti_v4_multinode.hdf5\",  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = fits.getdata(\"/cosma/apps/dp276/dc-harv3/synference/priv/jwst_nirspec_prism_disp.fits\")\n",
    "wavs = tab[\"WAVELENGTH\"] * um\n",
    "R = tab[\"R\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.create_feature_array(\n",
    "    flux_units=\"log10 nJy\",\n",
    "    crop_wavelength_range=(0.6, 5.0),\n",
    "    resample_wavelengths=wavs,\n",
    "    inst_resolution_wavelengths=wavs,\n",
    "    inst_resolution_r=R,\n",
    "    theory_r=np.inf,\n",
    "    min_flux_value=-10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model = SBI_Fitter.load_saved_model(\n",
    "    \"/cosma/apps/dp276/dc-harv3/synference/models/Spectra_BPASS_Chab_Continuity_SFH_0.01_z_14_logN_4.4_Calzetti_v4_multinode\"  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 52\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "redshift = run_model.fitted_parameter_array[idx][0]\n",
    "mass = run_model.fitted_parameter_array[idx][1]\n",
    "plt.plot(\n",
    "    wavs,\n",
    "    -2.5 * np.log10((1 + redshift) * 10 ** run_model.feature_array[idx]) + 31.4,\n",
    "    label=\"Observed [NIRSpec PRISM]\",\n",
    ")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "print(f\"Redshift: {redshift:.2f}, log10(M/Msun): {mass:.2f}\")\n",
    "plt.text(\n",
    "    3.7,\n",
    "    32.5,\n",
    "    f\"$z$={redshift:.2f}\\n$log_{{10}}(M/M_\\\\odot)={mass:.2f}$\",\n",
    "    fontsize=12,\n",
    "    color=\"black\",\n",
    "    bbox=dict(facecolor=\"lightgrey\", alpha=0.8, edgecolor=\"none\"),\n",
    ")\n",
    "# Show Lyman break\n",
    "\"\"\"plt.axvline(0.1216 * (1 + redshift), color='k', linestyle='--', label='Lyman break')\n",
    "plt.axvline(0.0912 * (1 + redshift), color='k', linestyle=':', label='Lyman limit')\n",
    "# Show Hb, Ha\n",
    "plt.axvline(0.4861 * (1 + redshift), color='r', linestyle='--', label='Hβ')\n",
    "plt.axvline(0.6563 * (1 + redshift), color='r', linestyle=':', label='Hα')\n",
    "# Show OIII, OII\n",
    "plt.axvline(0.5007 * (1 + redshift), color='g', linestyle='--', label='[OIII]')\n",
    "plt.axvline(0.3727 * (1 + redshift), color='g', linestyle=':', label='[OII]')\"\"\"\n",
    "\n",
    "# normal_spec\n",
    "ax = plt.gca()\n",
    "ax.set_ylim(ax.get_ylim())\n",
    "ax.set_xlim(ax.get_xlim())\n",
    "orig = -2.5 * np.log10(run_model.raw_observation_grid[:, idx] * (1 + redshift)) + 31.4\n",
    "plt.plot(\n",
    "    run_model.raw_observation_names * (1 + redshift),\n",
    "    orig,\n",
    "    color=\"gray\",\n",
    "    alpha=0.5,\n",
    "    linewidth=0.5,\n",
    "    label=\"Intrinsic\",\n",
    ")\n",
    "plt.xlabel(\"Wavelength [micron]\")\n",
    "plt.ylabel(\"Mag [ABmag]\")\n",
    "plt.legend()\n",
    "plt.ylim(35, None)\n",
    "plt.xlim(0.6, 10)\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model.recreate_simulator_from_grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup required parameter transforms for this simulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.cosmology import Planck18\n",
    "from unyt import Myr, unyt_array\n",
    "\n",
    "\n",
    "def continuity_agebins(\n",
    "    redshift,\n",
    "    cosmo=Planck18,\n",
    "    Nbins=6,\n",
    "    first_bin=3 * Myr,\n",
    "    second_bin=10 * Myr,\n",
    "    last_bin=\"15%\",\n",
    "    max_redshift=20,\n",
    "):\n",
    "    \"\"\"Generate age bins for the Continuity SFH.\n",
    "\n",
    "    The first two bins are fixed, the last bin is a percentage of the maximum age at that redshift,\n",
    "    and the middle bins are logarithmically spaced.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    redshift : float\n",
    "        The redshift at which to calculate the age bins.\n",
    "    cosmo : astropy.cosmology.Cosmology, optional\n",
    "        The cosmology to use for age calculations, by default Planck18.\n",
    "    Nbins : int, optional\n",
    "        The total number of bins, by default 6.\n",
    "    first_bin : unyt_quantity, optional\n",
    "        The ending lookback time for the first bin, by default 3 Myr.\n",
    "    second_bin : unyt_quantity, optional\n",
    "        The ending lookback time for the second bin, by default 10 Myr.\n",
    "    last_bin : str or unyt_quantity, optional\n",
    "        The ending lookback time for the last bin, which can be a percentage of the max_age\n",
    "        at that redshift or a fixed value, by default '15%'.\n",
    "    max_redshift : float, optional\n",
    "        The maximum redshift to consider for the age bins, by default 20.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    list of unyt_quantity\n",
    "        The age bins in lookback time.\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(redshift, dict):\n",
    "        redshift = redshift[\"redshift\"]\n",
    "\n",
    "    # Calculate the maximum age at the given redshift\n",
    "    max_age = cosmo.age(redshift).to_value(\"Myr\")\n",
    "    age_at_max = cosmo.age(max_redshift).to_value(\"Myr\")\n",
    "    available_age = max_age - age_at_max\n",
    "\n",
    "    bins = [0.0, first_bin.to_value(\"Myr\")]\n",
    "    if isinstance(last_bin, str) and last_bin.endswith(\"%\"):\n",
    "        # If last_bin is a percentage, calculate it based on the remaining age\n",
    "        last_bin_value = available_age * float(last_bin[:-1]) / 100.0\n",
    "    else:\n",
    "        # Otherwise, treat last_bin as a fixed value\n",
    "        last_bin_value = last_bin.to_value(\"Myr\")\n",
    "\n",
    "    age_at_last_bin = available_age - last_bin_value\n",
    "    # Generate the middle bins logarithmically spaced\n",
    "    middle_bins = np.logspace(\n",
    "        np.log10(second_bin),\n",
    "        np.log10(age_at_last_bin),\n",
    "        Nbins - 2,\n",
    "    )\n",
    "    # Combine all bins and convert to unyt_quantity\n",
    "    all_bins = np.concatenate((bins, middle_bins, [available_age]))\n",
    "\n",
    "    # reshape to (N, 2) and readd relevant bins to mathc shape.\n",
    "    # e.g. (0, 1e7), (1e7, 1e8), (1e8, 1.5e8), (1.5e8, 2.0e8), (2.0e8, 3.0e8), (3.0e8, 4.0e8)\n",
    "    all_bins = np.array([(all_bins[i], all_bins[i + 1]) for i in range(len(all_bins) - 1)])\n",
    "    all_bins = unyt_array(all_bins, \"Myr\")\n",
    "\n",
    "    return all_bins\n",
    "\n",
    "\n",
    "k = tuple([f\"logsfr_ratio_{j}\" for j in range(5)])\n",
    "\n",
    "\n",
    "def create_cont(**kwargs):\n",
    "    \"\"\"Create logsfr_ratios array from individual logsfr_ratio_j parameters.\"\"\"\n",
    "    return np.array([kwargs[f\"logsfr_ratio_{j}\"] for j in range(len(kwargs))])\n",
    "\n",
    "\n",
    "run_model.simulator.param_transforms[\"agebins\"] = continuity_agebins\n",
    "run_model.simulator.param_transforms[k] = (\"logsfr_ratios\", create_cont)\n",
    "\n",
    "\n",
    "run_model.simulator.param_transforms[\"Av\"] = (\"tau_v\", lambda Av: Av / 1.086)\n",
    "run_model.simulator.output_type = [\"fnu\", \"photo_fnu\"]\n",
    "run_model.simulator.out_flux_unit = \"nJy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = run_model.sample_posterior(\n",
    "    X_test=run_model.feature_array[idx],\n",
    "    num_samples=100,\n",
    ")\n",
    "\n",
    "\n",
    "recovered_sed = []\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "for i in trange(samples.shape[0]):\n",
    "    input = {\n",
    "        run_model.fitted_parameter_names[j]: samples[i, j]\n",
    "        for j in range(len(run_model.fitted_parameter_names))\n",
    "    }\n",
    "    out = run_model.simulator(input)\n",
    "    fnu = out[\"fnu\"]\n",
    "    sample_wav = out[\"fnu_wav\"]\n",
    "    recovered_sed.append(fnu)\n",
    "\n",
    "recovered_sed = np.array(recovered_sed)\n",
    "\n",
    "recovered_16, recovered_50, recovered_84 = np.percentile(recovered_sed, [16, 50, 84], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "redshift = run_model.fitted_parameter_array[idx][0]\n",
    "mass = run_model.fitted_parameter_array[idx][1]\n",
    "\"\"\"\n",
    "_, transformed_16 = transform_spectrum(\n",
    "    theory_wave=sample_wav.to('um').value  / (1 + redshift),\n",
    "    theory_flux=recovered_16 * (1 + redshift),\n",
    "    z=redshift,\n",
    "    observed_wave=wavs.to('um').value,\n",
    "    resolution_curve_wave=wavs.to('um').value,\n",
    "    resolution_curve_r=R)\n",
    "\"\"\"\n",
    "_, transformed_50 = transform_spectrum(\n",
    "    theory_wave=sample_wav.to(\"um\").value / (1 + redshift),\n",
    "    theory_flux=recovered_50,\n",
    "    z=redshift,\n",
    "    observed_wave=wavs.to(\"um\").value,\n",
    "    resolution_curve_wave=wavs.to(\"um\").value,\n",
    "    resolution_curve_r=R,\n",
    ")\n",
    "\"\"\"\n",
    "_, transformed_84 = transform_spectrum(\n",
    "    theory_wave=sample_wav.to('um').value / (1 + redshift),\n",
    "    theory_flux=recovered_84 * (1 + redshift),\n",
    "    z=redshift,\n",
    "    observed_wave=wavs.to('um').value,\n",
    "    resolution_curve_wave=wavs.to('um').value,\n",
    "    resolution_curve_r=R)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "# Add GRIDSPEC - top axis is combined, bottom is 5 seperate axes\n",
    "\n",
    "gs = fig.add_gridspec(2, 4, height_ratios=[3, 1], hspace=0.3)\n",
    "main_ax = fig.add_subplot(gs[0, :])\n",
    "\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "print(f\"Redshift: {redshift:.2f}, log10(M/Msun): {mass:.2f}\")\n",
    "plt.text(\n",
    "    0.99,\n",
    "    0.02,\n",
    "    f\"$z$ = {redshift:.2f}\\n$log_{{10}}(M/M_\\\\odot) = {mass:.2f}$\",\n",
    "    transform=main_ax.transAxes,\n",
    "    fontsize=12,\n",
    "    color=\"black\",\n",
    "    horizontalalignment=\"right\",\n",
    "    verticalalignment=\"bottom\",\n",
    "    bbox=dict(facecolor=\"lightgrey\", alpha=0.8, edgecolor=\"none\"),\n",
    ")\n",
    "# Show Lyman break\n",
    "plt.axvline(\n",
    "    0.1216 * (1 + redshift),\n",
    "    color=\"k\",\n",
    "    linestyle=\"--\",\n",
    ")  # label='Lyman break')\n",
    "plt.text(\n",
    "    0.122 * (1 + redshift),\n",
    "    0.80,\n",
    "    \"Lyman break\",\n",
    "    rotation=90,\n",
    "    verticalalignment=\"bottom\",\n",
    "    transform=main_ax.get_xaxis_transform(),\n",
    "    horizontalalignment=\"center\",\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.8, edgecolor=\"none\"),\n",
    ")\n",
    "plt.axvline(0.0912 * (1 + redshift), color=\"k\", linestyle=\":\")\n",
    "plt.text(\n",
    "    0.092 * (1 + redshift),\n",
    "    0.80,\n",
    "    \"Lyman limit\",\n",
    "    rotation=90,\n",
    "    verticalalignment=\"bottom\",\n",
    "    transform=main_ax.get_xaxis_transform(),\n",
    "    horizontalalignment=\"center\",\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.8, edgecolor=\"none\"),\n",
    ")\n",
    "# Show Hb, Ha\n",
    "plt.axvline(0.4861 * (1 + redshift), color=\"k\", linestyle=\":\")\n",
    "plt.text(\n",
    "    0.487 * (1 + redshift),\n",
    "    0.80,\n",
    "    r\"H$\\beta$\",\n",
    "    rotation=90,\n",
    "    verticalalignment=\"bottom\",\n",
    "    transform=main_ax.get_xaxis_transform(),\n",
    "    horizontalalignment=\"center\",\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.8, edgecolor=\"none\"),\n",
    ")\n",
    "# plt.axvline(0.6563 * (1 + redshift), color='k', linestyle=':')\n",
    "# plt.text(0.657 * (1 + redshift), 0.80, r'H$\\alpha$', rotation=90, verticalalignment='bottom',\n",
    "#                        transform=main_ax.get_xaxis_transform(), horizontalalignment='center',\n",
    "#                        bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "# Show OIII, OII\n",
    "plt.axvline(0.5007 * (1 + redshift), color=\"k\", linestyle=\":\")\n",
    "plt.text(\n",
    "    0.501 * (1 + redshift),\n",
    "    0.90,\n",
    "    \"[OIII]\",\n",
    "    rotation=90,\n",
    "    verticalalignment=\"bottom\",\n",
    "    transform=main_ax.get_xaxis_transform(),\n",
    "    horizontalalignment=\"center\",\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.8, edgecolor=\"none\"),\n",
    ")\n",
    "plt.axvline(0.3727 * (1 + redshift), color=\"k\", linestyle=\":\")\n",
    "plt.text(\n",
    "    0.373 * (1 + redshift),\n",
    "    0.80,\n",
    "    \"[OII]\",\n",
    "    rotation=90,\n",
    "    verticalalignment=\"bottom\",\n",
    "    transform=main_ax.get_xaxis_transform(),\n",
    "    horizontalalignment=\"center\",\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.8, edgecolor=\"none\"),\n",
    ")\n",
    "\n",
    "# normal_spec\n",
    "ax = plt.gca()\n",
    "ax.set_ylim(ax.get_ylim())\n",
    "ax.set_xlim(ax.get_xlim())\n",
    "orig = -2.5 * np.log10(run_model.raw_observation_grid[:, idx]) + 31.4\n",
    "plt.plot(\n",
    "    run_model.raw_observation_names * (1 + redshift),\n",
    "    orig,\n",
    "    color=\"gray\",\n",
    "    alpha=0.5,\n",
    "    linewidth=0.5,\n",
    "    label=\"Intrinsic\",\n",
    ")\n",
    "plt.xlabel(\"Wavelength [micron]\")\n",
    "plt.ylabel(\"Mag [ABmag]\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim(0.6, 7)\n",
    "# plt.xscale(\"log\")\n",
    "plt.ylim(25, 18)\n",
    "\n",
    "plt.plot(\n",
    "    wavs,\n",
    "    -2.5 * np.log10(10 ** run_model.feature_array[idx]) + 31.4,\n",
    "    label=\"Observed [NIRSpec PRISM]\",\n",
    "    lw=1,\n",
    "    color=\"#EC93D7\",\n",
    ")\n",
    "\"\"\"\n",
    "plt.fill_between(wavs.to('um').value,\n",
    "          -2.5*np.log10((1+redshift)*transformed_16) + 31.4,\n",
    "          -2.5*np.log10((1+redshift)*transformed_84) + 31.4,\n",
    "          color=\"#180652\", alpha=0.3, label='68% credible interval')\n",
    "\"\"\"\n",
    "plt.plot(\n",
    "    sample_wav.to(\"um\").value,\n",
    "    -2.5 * np.log10(recovered_50) + 31.4,\n",
    "    label=\"Recovered median SED\",\n",
    "    lw=1.2,\n",
    "    color=\"#180652\",\n",
    ")\n",
    "\n",
    "\n",
    "plot_params = [\"redshift\", \"log_mass\", \"Av\", \"log10metallicity\"]\n",
    "\n",
    "for i, param in enumerate(plot_params):\n",
    "    ax = fig.add_subplot(gs[1, i])\n",
    "    pidx = list(run_model.fitted_parameter_names).index(param)\n",
    "    ss = samples[:, pidx]\n",
    "\n",
    "    ax.hist(\n",
    "        ss,\n",
    "        bins=20,\n",
    "        density=True,\n",
    "        alpha=0.7,\n",
    "        color=\"#180652\",\n",
    "    )\n",
    "    true = run_model.fitted_parameter_array[idx][pidx]\n",
    "\n",
    "    ax.axvline(\n",
    "        true,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    ax.set_xlabel(param)\n",
    "    ax.set_yticks([])\n",
    "\n",
    "\n",
    "all_true_params = {\n",
    "    name: run_model.fitted_parameter_array[idx][i]\n",
    "    for i, name in enumerate(run_model.fitted_parameter_names)\n",
    "}\n",
    "\n",
    "recreated_true = run_model.simulator(all_true_params)\n",
    "\n",
    "recreated_true_fnu = recreated_true[\"fnu\"]\n",
    "recreated_true_wav = recreated_true[\"fnu_wav\"]\n",
    "\"\"\"\n",
    "main_ax.plot(\n",
    "    recreated_true_wav.to(\"um\").value,\n",
    "    -2.5 * np.log10(recreated_true_fnu) + 31.4,\n",
    "    color=\"green\",\n",
    "    label=\"Recreated true SED\",\n",
    "    lw=1.5,\n",
    ")\n",
    "\"\"\"\n",
    "main_ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Spectral Inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = SBI_Fitter.init_from_hdf5(\n",
    "    \"Spectra_BPASS_Chab_Continuity_SFH_0.01_z_14_logN_4.4_Calzetti_v4_multinode\",\n",
    "    \"/cosma7/data/dp276/dc-harv3/work/sbi_grids/grid_spectra_BPASS_Chab_Continuity_SFH_0.01_z_14_logN_4.4_Calzetti_v4_multinode.hdf5\",  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthesizer.filters import UVJ\n",
    "\n",
    "V = UVJ()[\"V\"]\n",
    "\n",
    "fitter.create_feature_array_from_raw_spectra(\n",
    "    normed_flux_units=\"erg/s/cm^2/Angstrom\",\n",
    "    crop_wavelength_range=(0.6, 5.0),\n",
    "    resample_wavelengths=wavs,\n",
    "    inst_resolution_wavelengths=wavs,\n",
    "    inst_resolution_r=R,\n",
    "    theory_r=np.inf,\n",
    "    flux_norm_method=\"bandpass\",\n",
    "    flux_norm_parameters={\n",
    "        \"filter\": V,\n",
    "        \"rest_frame\": True,\n",
    "    },\n",
    ")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
