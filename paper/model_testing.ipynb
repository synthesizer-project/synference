{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191991de",
   "metadata": {},
   "source": [
    "### Model Testing Figures for Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a67e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] = \"/usr/local/texlive/2025/bin/x86_64-linux:\" + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from synference import SBI_Fitter\n",
    "\n",
    "plt.style.use(\"paper.style\")\n",
    "model_name = \"DenseBasis_v3_final_custom_small\"\n",
    "extra = \"nsf_zfix\"\n",
    "\n",
    "\n",
    "fitter = SBI_Fitter.load_saved_model(\n",
    "    f\"/home/tharvey/work/synference/models/{model_name}/{model_name}_{extra}_posterior.pkl\",\n",
    "    grid_path=\"/home/tharvey/work/synference/grids/grid_BPASS_Chab_DenseBasis_SFH_0.01_z_14_logN_5.0_Calzetti_v3_multinode.hdf5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a64e8",
   "metadata": {},
   "source": [
    "Figure 2: Calibration and recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a453f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.plot_coverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee58dd8",
   "metadata": {},
   "source": [
    "## Calculate TARP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed6e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarp\n",
    "\n",
    "sample_path = (\n",
    "    f\"/home/tharvey/work/synference/models/{model_name}/plots/{extra}/posterior_samples.npy\"\n",
    ")\n",
    "true = fitter._y_test\n",
    "\n",
    "samples = np.load(sample_path)\n",
    "\n",
    "\n",
    "out = tarp.get_tarp_coverage(\n",
    "    samples,\n",
    "    true,\n",
    "    norm=True,\n",
    "    bootstrap=True,\n",
    "    num_bootstrap=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3379f17",
   "metadata": {},
   "source": [
    "\n",
    "## Load metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = f\"/home/tharvey/work/synference/models/{model_name}/{model_name}_{extra}_metrics.json\"\n",
    "\n",
    "import json\n",
    "\n",
    "with open(metrics, \"r\") as f:\n",
    "    met = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82032074",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.fitted_parameter_names\n",
    "\n",
    "\n",
    "param_labels = [\n",
    "    r\"$\\log M_*$\",\n",
    "    r\"$\\log Z/Z_\\odot$\",\n",
    "    r\"$\\rm \\log_{10} \\ A_V$\",\n",
    "    r\"$\\log$ SFR\",\n",
    "    \"$t_{25}$\",\n",
    "    \"$t_{50}$\",\n",
    "    \"$t_{75}$\",\n",
    "    r\"$\\log$ Age$_M$\",\n",
    "    r\"$\\log$ SFR$_{10}$\",\n",
    "    r\"$\\log M_{*,surv}$\",\n",
    "    \"$\\\\beta$\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5deba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9), dpi=150)  # constrained_layout=True)\n",
    "\n",
    "gs = fig.add_gridspec(2, 6, height_ratios=[1, 1.44], hspace=-0.15, wspace=0.65)\n",
    "\n",
    "ax_top_l = fig.add_subplot(gs[0, :2])\n",
    "ax_top_r = fig.add_subplot(gs[0, 2:4])\n",
    "ax_top_c = fig.add_subplot(gs[0, 4:6])\n",
    "ax1 = fig.add_subplot(gs[1, :3])\n",
    "ax2 = fig.add_subplot(gs[1, 3:])\n",
    "axs = [ax_top_l, ax_top_r, ax_top_c]\n",
    "\n",
    "\n",
    "# TARP and Coverage\n",
    "ax1.plot([0, 1], [0, 1], \"k--\", label=\"Ideal\", alpha=0.5)\n",
    "ax1.set_xlabel(\"Predicted Percentile\")\n",
    "ax1.set_ylabel(\"Empirical Percentile\")\n",
    "ax1.text(0.05, 0.90, \"TARP\", transform=ax1.transAxes, fontsize=16)\n",
    "\n",
    "ax2.plot([0, 1], [0, 1], \"k--\", label=\"Ideal\", alpha=0.5)\n",
    "ax2.set_xlabel(\"Credibility Level\")\n",
    "ax2.set_ylabel(\"Expected Coverage\")\n",
    "ax2.text(0.05, 0.90, \"SBC\", transform=ax2.transAxes, fontsize=16)\n",
    "\n",
    "ax_params = [\"log_mass\", \"log10_floor_sfr_10\", \"log10_Av\"]\n",
    "param_latex = [\n",
    "    r\"\\log(\\rm M/M_\\odot)\",\n",
    "    r\"\\log(\\rm SFR_{10 \\rm Myr}/ M_\\odot yr^{-1})\",\n",
    "    r\"\\log(\\rm A_V / \\rm mag)\",\n",
    "]\n",
    "indices = [list(fitter.fitted_parameter_names).index(p) for p in ax_params]\n",
    "\n",
    "# ax_top_r.set_xscale('log')\n",
    "# ax_top_r.set_yscale('log')\n",
    "# ax_top_r.set_xlim(1e-4, 1e3)\n",
    "# ax_top_r.set_ylim(1e-4, 1e3)\n",
    "# TARP\n",
    "\n",
    "ecp, alpha = out[0], out[1]\n",
    "ecp_mean = np.mean(ecp, axis=0)\n",
    "ecp_std = np.std(ecp, axis=0)\n",
    "ax1.plot(alpha, ecp_mean, label=\"TARP\", color=\"b\")\n",
    "ax1.fill_between(alpha, ecp_mean - ecp_std, ecp_mean + ecp_std, alpha=0.5, color=\"b\")\n",
    "ax1.fill_between(alpha, ecp_mean - 2 * ecp_std, ecp_mean + 2 * ecp_std, alpha=0.2, color=\"b\")\n",
    "\n",
    "\n",
    "# SBC\n",
    "trues = fitter._y_test\n",
    "\n",
    "ndata, npars = trues.shape\n",
    "ranks = (samples < trues[None, ...]).sum(axis=0)\n",
    "\n",
    "unicov = [np.sort(np.random.uniform(0, 1, ndata)) for j in range(200)]\n",
    "unip = np.percentile(unicov, [5, 16, 84, 95], axis=0)\n",
    "\n",
    "cdf = np.linspace(0, 1, len(ranks))\n",
    "for i in range(npars):\n",
    "    xr = np.sort(ranks[:, i])\n",
    "    xr = xr / xr[-1]\n",
    "    ax2.plot(cdf, cdf, \"k--\")\n",
    "\n",
    "    ax2.plot(xr, cdf, lw=2, label=param_labels[i])\n",
    "ax2.set(adjustable=\"box\", aspect=\"equal\")\n",
    "ax1.set(adjustable=\"box\", aspect=\"equal\")\n",
    "\n",
    "ax2.set_xlabel(\"Predicted Percentile\")\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.legend(fontsize=8)\n",
    "\n",
    "for i, ax in enumerate([ax_top_l, ax_top_r, ax_top_c]):\n",
    "    param = ax_params[i]\n",
    "    idx = indices[i]\n",
    "    order_index = list(fitter.fitted_parameter_names).index(param)\n",
    "\n",
    "    r2 = met[\"R_squared\"][order_index]\n",
    "    rmse = met[\"RMSE\"][order_index]\n",
    "    # Get 16/50/84 percentiles\n",
    "    # p16 = np.percentile(samples[:, :, idx], 16, axis=0)\n",
    "    # p50 = np.percentile(samples[:, :, idx], 50, axis=0)\n",
    "    # p84 = np.percentile(samples[:, :, idx], 84, axis=0)\n",
    "    # ax.errorbar(true[:, idx], p50, yerr=[p50 - p16, p84 - p50], fmt='o',\n",
    "    #  alpha=0.1, color='C0', markersize=2)\n",
    "    # Instead, plot as hexbin and count all draws\n",
    "    # broadcast true to match samples shape\n",
    "\n",
    "    true_full = np.repeat(true[:, idx][np.newaxis, :], samples.shape[0], axis=0).flatten()\n",
    "    yy = samples[:, :, idx].flatten()\n",
    "    # if i == 1:\n",
    "    #    true_full = np.log10(true_full)\n",
    "    #    yy = np.log10(yy)\n",
    "    #    yy = np.clip(yy, -6, None)\n",
    "    #    true_full = np.clip(true_full, -6, None)\n",
    "    # if i == 2:\n",
    "    #    yy = 10**yy\n",
    "    #    true_full = 10**true_full\n",
    "    ax.hexbin(\n",
    "        true_full,\n",
    "        yy,\n",
    "        gridsize=50,\n",
    "        cmap=\"cmr.sunburst_r\",\n",
    "        mincnt=1,\n",
    "    )  # bins='log')\n",
    "    ax.set(adjustable=\"box\", aspect=\"equal\")\n",
    "\n",
    "    ax.set_xlabel(\"True Value\")\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Inferred Value\")\n",
    "    ax.plot(\n",
    "        [true_full.min(), true_full.max()], [true_full.min(), true_full.max()], \"k--\", alpha=0.5\n",
    "    )\n",
    "    ax.text(0.05, 0.90, f\"${param_latex[i]}$\", transform=ax.transAxes, fontsize=11)\n",
    "    ax.text(0.05, 0.80, \"RMSE = {:.2f}\".format(rmse), transform=ax.transAxes, fontsize=10)\n",
    "    ax.text(0.05, 0.70, f\"$R^2={r2:.2f}$\", transform=ax.transAxes, fontsize=10)\n",
    "\n",
    "fig.savefig(\n",
    "    f\"/home/tharvey/work/synference/models/{model_name}/plots/{model_name}_{extra}_validation.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "fig.savefig(f\"plots/{model_name}_{extra}_validation.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28904a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Make text bigger\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 12, \"axes.labelsize\": 14, \"axes.titlesize\": 14})\n",
    "\n",
    "\n",
    "# CORRECTED FUNCTION\n",
    "def calculate_quantile_error_per_param(\n",
    "    true_params: np.ndarray, posteriors: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Calculates a quantile-based error metric for each parameter of each observation.\n",
    "\n",
    "    This version is corrected to handle posteriors with the shape\n",
    "    (n_samples, n_points, n_dim), as indicated by the traceback.\n",
    "    \"\"\"\n",
    "    # Your shapes:\n",
    "    # true_params: (n_points, n_dim) -> (25000, 11)\n",
    "    # posteriors:  (n_samples, n_points, n_dim) -> (1000, 25000, 11)\n",
    "\n",
    "    # 1. Reshape true_params to (1, n_points, n_dim) to enable broadcasting.\n",
    "    # This aligns the `n_points` and `n_dim` axes correctly.\n",
    "    true_params_reshaped = true_params[np.newaxis, :, :]\n",
    "\n",
    "    # 2. Perform the comparison. Broadcasting now works:\n",
    "    # (1000, 25000, 11) < (1, 25000, 11) -> a boolean array of (1000, 25000, 11)\n",
    "    comparison = posteriors < true_params_reshaped\n",
    "\n",
    "    # 3. Take the mean over the `n_samples` axis (which is now axis=0).\n",
    "    # This collapses the samples dimension, leaving a result of shape (n_points, n_dim).\n",
    "    quantiles = np.mean(comparison, axis=0)\n",
    "\n",
    "    errors = np.abs(quantiles - 0.5)\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "def plot_colored_corner(\n",
    "    data: np.ndarray,\n",
    "    errors: np.ndarray,\n",
    "    param_names: list[str] | None = None,\n",
    "    elabel: str = \"Prediction Error (|quantile - 0.5|)\",\n",
    "    params_to_remove: list[str] = [],\n",
    ") -> None:\n",
    "    \"\"\"Creates a corner plot where scatter points are colored by the error metric.\"\"\"\n",
    "    n_dim = data.shape[1]\n",
    "    # Remove specified parameters\n",
    "    if params_to_remove:\n",
    "        indices_to_keep = [i for i, name in enumerate(param_names) if name not in params_to_remove]\n",
    "        data = data[:, indices_to_keep]\n",
    "        errors = errors\n",
    "        if param_names is not None:\n",
    "            param_names = [param_names[i] for i in indices_to_keep]\n",
    "        n_dim = data.shape[1]\n",
    "    if param_names is None:\n",
    "        param_names = [f\"Param {i}\" for i in range(n_dim)]\n",
    "\n",
    "    fig, axes = plt.subplots(n_dim, n_dim, figsize=(12, 12))\n",
    "\n",
    "    # Adjust subplots to be tight\n",
    "    fig.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1, hspace=0.1, wspace=0.1)\n",
    "\n",
    "    for i in range(n_dim):\n",
    "        for j in range(n_dim):\n",
    "            ax = axes[i, j]\n",
    "\n",
    "            # Diagonal: Plot 1D histograms of the true parameter distribution\n",
    "            if i == j:\n",
    "                sns.histplot(\n",
    "                    data[:, i],\n",
    "                    ax=ax,\n",
    "                    bins=20,\n",
    "                    kde=True,\n",
    "                    element=\"step\",\n",
    "                    color=\"sandybrown\",\n",
    "                    alpha=0.7,\n",
    "                )\n",
    "                ax.set_ylabel(\"\")\n",
    "            # Hide upper triangle\n",
    "            elif i < j:\n",
    "                ax.axis(\"off\")\n",
    "            # Lower triangle: Plot 2D scatter plots\n",
    "            else:\n",
    "                # Color the points by the error metric\n",
    "                \"\"\"sc = ax.scatter(\n",
    "                    data[:, j],\n",
    "                    data[:, i],\n",
    "                    cmap=\"cmr.ember\",\n",
    "                    vmin=np.percentile(errors, 5),\n",
    "                    vmax=np.percentile(errors, 95),\n",
    "                    s=5,\n",
    "                    alpha=0.7,\n",
    "                    c=errors,\n",
    "                )\"\"\"\n",
    "                # do a hexbin - not density just average error in each bin\n",
    "                sc = ax.hexbin(\n",
    "                    data[:, j],\n",
    "                    data[:, i],\n",
    "                    C=errors,\n",
    "                    reduce_C_function=np.mean,\n",
    "                    gridsize=25,\n",
    "                    cmap=\"cmr.ember\",\n",
    "                    vmin=np.percentile(errors, 5),\n",
    "                    vmax=np.percentile(errors, 95),\n",
    "                    mincnt=1,\n",
    "                )\n",
    "            # Labels for the outer plots only\n",
    "            if j == 0 and i > 0:\n",
    "                ax.set_ylabel(param_names[i])\n",
    "            if i == n_dim - 1:\n",
    "                ax.set_xlabel(param_names[j])\n",
    "\n",
    "            # Remove ticks for inner plots to clean up the view\n",
    "            if i < n_dim - 1:\n",
    "                ax.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n",
    "            if j > 0:\n",
    "                ax.tick_params(axis=\"y\", which=\"both\", left=False, right=False, labelleft=False)\n",
    "\n",
    "    # Add a colorbar\n",
    "    cbar_ax = fig.add_axes([0.35, 0.7, 0.55, 0.02])\n",
    "    cbar = fig.colorbar(sc, cax=cbar_ax, orientation=\"horizontal\")\n",
    "    cbar.set_label(elabel)\n",
    "\n",
    "    # plt.suptitle(\"Corner Plot of True Parameters Colored by Prediction Error\", fontsize=16, y=0.95) # noqa E501\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "sample_path = (\n",
    "    f\"/home/tharvey/work/synference/models/{model_name}/plots/{extra}/posterior_samples.npy\"\n",
    ")\n",
    "true = fitter._y_test\n",
    "\n",
    "samples = np.load(sample_path)\n",
    "log_prob_path = f\"/home/tharvey/work/synference/models/{model_name}/plots/{extra}/true_logprobs.npy\"\n",
    "\n",
    "log_probs = np.load(log_prob_path)\n",
    "\n",
    "errors = calculate_quantile_error_per_param(true, samples)\n",
    "errors = np.mean(errors, axis=1)\n",
    "\n",
    "params_to_remove = [\"$\\\\beta$\"]\n",
    "plot_colored_corner(\n",
    "    true,\n",
    "    log_probs,\n",
    "    param_names=param_labels,\n",
    "    elabel=\"$\\\\log P(\\\\theta | x)$\",\n",
    "    params_to_remove=params_to_remove,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d6da58",
   "metadata": {},
   "source": [
    "## Pick a few examples and compare posteriors with nested sampling and the truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30bbeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter._X_test[3435]\n",
    "\n",
    "indexes = 99, 3435, 16, 9985, 7372"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d555d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter._X_test[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aae5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 7372\n",
    "\n",
    "sample = fitter._X_test[index]\n",
    "true_params = fitter._y_test[index]\n",
    "predicted_params = fitter.sample_posterior(sample, num_samples=1000)\n",
    "\n",
    "fitter._prior = fitter.create_priors()\n",
    "\n",
    "sampler = fitter.fit_observation_using_sampler(\n",
    "    observation=sample,\n",
    "    sampler=\"nautilus\",\n",
    "    sampler_kwargs={\"n_live\": 500},\n",
    "    remove_params=[\"log10_mass_weighted_age\", \"log10_floor_sfr_10\"],\n",
    ")\n",
    "points, log_w, log_l = sampler.posterior()\n",
    "\n",
    "# Plot corner of both on same (see through, only contours) and true value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2caf9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "comparison_params = [\n",
    "    \"log_mass\",\n",
    "    \"log10metallicity\",\n",
    "    \"log10_Av\",\n",
    "    \"log_sfr\",\n",
    "    \"sfh_quantile_25\",\n",
    "    \"sfh_quantile_50\",\n",
    "    \"sfh_quantile_75\",\n",
    "]\n",
    "\n",
    "display_names = [\n",
    "    r\"$\\log M_*$\",\n",
    "    r\"$\\log Z/Z_\\odot$\",\n",
    "    \"$A_V$\",\n",
    "    r\"$\\log$ SFR\",\n",
    "    \"$t_{25}$\",\n",
    "    \"$t_{50}$\",\n",
    "    \"$t_{75}$\",\n",
    "]\n",
    "\n",
    "mask_idx = [True if p in comparison_params else False for p in fitter.fitted_parameter_names]\n",
    "mask_idx = np.array(mask_idx, dtype=bool)\n",
    "\n",
    "figure = corner.corner(\n",
    "    points[:, :-2],\n",
    "    weights=np.exp(log_w - log_w.max()),\n",
    "    labels=display_names,\n",
    "    color=\"#03A89E\",\n",
    "    plot_datapoints=False,\n",
    "    fill_contours=False,\n",
    "    contour_kwargs={\"linewidths\": 1.5, \"linestyles\": \"solid\"},\n",
    "    contourf_kwargs={\n",
    "        \"alpha\": 0.3  # Very light fill for contours\n",
    "    },\n",
    "    hist_kwargs={\"alpha\": 0.7, \"histtype\": \"stepfilled\", \"edgecolor\": \"black\", \"linewidth\": 1},\n",
    "    levels=(0.68, 0.95),\n",
    "    plot_density=False,\n",
    "    smooth=1.0,\n",
    "    label_kwargs={\"fontsize\": 22},\n",
    "    title_kwargs={\"fontsize\": 22},\n",
    "    quantiles=[0.16, 0.5, 0.84],\n",
    "    show_titles=False,\n",
    "    # Increase tick label size\n",
    "    tick_label_kwargs={\"fontsize\": 16},\n",
    ")\n",
    "\n",
    "corner.corner(\n",
    "    predicted_params[:, mask_idx],\n",
    "    labels=display_names,\n",
    "    color=\"#CD3700\",\n",
    "    plot_datapoints=False,\n",
    "    fill_contours=False,\n",
    "    contour_kwargs={\"linewidths\": 1.5, \"linestyles\": \"solid\"},\n",
    "    contourf_kwargs={\n",
    "        \"alpha\": 0.3  # Very light fill for contours\n",
    "    },\n",
    "    hist_kwargs={\"alpha\": 0.7, \"histtype\": \"stepfilled\", \"edgecolor\": \"black\", \"linewidth\": 1},\n",
    "    plot_density=False,\n",
    "    smooth=1.0,\n",
    "    fig=figure,\n",
    "    quantiles=[0.16, 0.5, 0.84],\n",
    "    show_titles=False,\n",
    "    tick_label_kwargs={\"fontsize\": 16},\n",
    ")\n",
    "\n",
    "# Add true value lines\n",
    "ndim = len(comparison_params)\n",
    "axes = np.array(figure.axes).reshape((ndim, ndim))\n",
    "for i in range(ndim):\n",
    "    for j in range(ndim):\n",
    "        ax = axes[i, j]\n",
    "        if i == j:\n",
    "            ax.axvline(true_params[i], color=\"k\", linestyle=\"dotted\")\n",
    "            # Add our own titles with quantiles for both\n",
    "            samples_param = predicted_params[:, mask_idx][:, i]\n",
    "            p16, p50, p84 = np.percentile(samples_param, [16, 50, 84])\n",
    "            nested = points[:, :-2][:, i]\n",
    "            # need to get weighted percentiles for nested sampling\n",
    "            sorted_indices = np.argsort(nested)\n",
    "            nested_sorted = nested[sorted_indices]\n",
    "            weights_sorted = np.exp(log_w - log_w.max())[sorted_indices]\n",
    "            cumulative_weights = np.cumsum(weights_sorted)\n",
    "            cumulative_weights /= cumulative_weights[-1]  # Normalize to [0, 1]\n",
    "            p16_ns = np.interp(0.16, cumulative_weights, nested_sorted)\n",
    "            p50_ns = np.interp(0.50, cumulative_weights, nested_sorted)\n",
    "            p84_ns = np.interp(0.84, cumulative_weights, nested_sorted)\n",
    "            title = (\n",
    "                rf\"{comparison_params[i]}\" + \"\\n\"\n",
    "                rf\"SBI: ${p50:.2f}_{{-{p50 - p16:.2f}}}^{{+{p84 - p50:.2f}}}$\" + \"\\n\"\n",
    "                rf\"NS: ${p50_ns:.2f}_{{-{p50_ns - p16_ns:.2f}}}^{{+{p84_ns - p50_ns:.2f}}}$\"\n",
    "            )\n",
    "            # ax.set_title(title, fontsize=14)\n",
    "            ax.set_title(\"\")\n",
    "            # Approximate the title with textbox so we can set the color of SBI vs NS\n",
    "            sbi = rf\"SBI: ${p50:.2f}_{{-{p50 - p16:.2f}}}^{{+{p84 - p50:.2f}}}$\"\n",
    "            ns = rf\"NS: ${p50_ns:.2f}_{{-{p50_ns - p16_ns:.2f}}}^{{+{p84_ns - p50_ns:.2f}}}$\"\n",
    "\n",
    "            ax.text(\n",
    "                0.5,\n",
    "                1.3,\n",
    "                sbi,\n",
    "                color=\"#CD3700\",\n",
    "                fontsize=22,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                transform=ax.transAxes,\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "            ax.text(\n",
    "                0.5,\n",
    "                1.1,\n",
    "                ns,\n",
    "                color=\"#03A89E\",\n",
    "                fontsize=22,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                transform=ax.transAxes,\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "        elif i > j:\n",
    "            ax.axvline(true_params[j], color=\"k\", linestyle=\"dotted\")\n",
    "            ax.axhline(true_params[i], color=\"k\", linestyle=\"dotted\")\n",
    "            ax.plot(true_params[j], true_params[i], \"ks\")\n",
    "\n",
    "        # Increase font size of tick labels if i or j is 0 or ndim-1\n",
    "        if i == ndim - 1 or j == 0:\n",
    "            ax.tick_params(axis=\"x\", which=\"major\", labelsize=16)\n",
    "        if j == 0 or i == ndim - 1:\n",
    "            ax.tick_params(axis=\"y\", which=\"major\", labelsize=16)\n",
    "\n",
    "# figure.suptitle(\"Comparison of Posterior Samples: MDN vs Nested Sampling\", fontsize=16)\n",
    "\n",
    "# Add upper right floating axis for SED plot\n",
    "\n",
    "new_ax = figure.add_axes([0.50, 0.65, 0.45, 0.35])\n",
    "\n",
    "sfh_ax = figure.add_axes([0.75, 0.42, 0.22, 0.18])\n",
    "\n",
    "# Get SEDs given these posterior samples.\n",
    "results = fitter.recover_SED(\n",
    "    sample,\n",
    "    samples=predicted_params,\n",
    "    plot=True,\n",
    "    true_parameters=true_params,\n",
    "    sample_color=\"#CD3700\",\n",
    "    fig=figure,\n",
    "    ax=new_ax,\n",
    "    plot_histograms=False,\n",
    "    plot_sfh=True,\n",
    "    ax_sfh=sfh_ax,\n",
    "    num_samples=50,\n",
    ")\n",
    "\n",
    "# Do the same for nested sampling samples\n",
    "# add two dimensions to fake points to match expected shape\n",
    "\n",
    "points_dict = {name: points[:, i] for i, name in enumerate(comparison_params)}\n",
    "# Not designed to deal with weights, so sample with replacement according to weights\n",
    "weights = np.exp(log_w - log_w.max())\n",
    "weights /= weights.sum()\n",
    "indices = np.random.choice(len(weights), size=len(weights), replace=True, p=weights)\n",
    "points_dict = {name: points_dict[name][indices] for name in points_dict}\n",
    "results_ns = fitter.recover_SED(\n",
    "    sample,\n",
    "    samples=points_dict,\n",
    "    plot=True,\n",
    "    sample_color=\"#03A89E\",\n",
    "    fig=figure,\n",
    "    ax=new_ax,\n",
    "    plot_histograms=False,\n",
    "    plot_sfh=True,\n",
    "    ax_sfh=sfh_ax,\n",
    "    num_samples=50,\n",
    ")\n",
    "\n",
    "new_ax.set_ylim(25, 22)\n",
    "# move legend to lower right\n",
    "\n",
    "# Increase font size of all text in new_ax and sfh_ax\n",
    "for item in (\n",
    "    new_ax.title,\n",
    "    new_ax.xaxis.label,\n",
    "    new_ax.yaxis.label,\n",
    "    new_ax.get_xticklabels(),\n",
    "    new_ax.get_yticklabels(),\n",
    "    new_ax.get_legend().get_texts(),\n",
    "    sfh_ax.title,\n",
    "    sfh_ax.xaxis.label,\n",
    "    sfh_ax.yaxis.label,\n",
    "    sfh_ax.get_xticklabels(),\n",
    "    sfh_ax.get_yticklabels(),\n",
    "):\n",
    "    if hasattr(item, \"__iter__\"):\n",
    "        for subitem in item:\n",
    "            subitem.set_fontsize(16)\n",
    "    else:\n",
    "        item.set_fontsize(16)\n",
    "\n",
    "# Increase marker size for all markers in new_ax\n",
    "for line in new_ax.get_lines():\n",
    "    line.set_markersize(8)\n",
    "\n",
    "# Change line labels in new_ax to \"SBI Posterior\" and \"Nested Sampling\"\n",
    "lines = new_ax.get_lines()\n",
    "for line in lines:\n",
    "    if (\n",
    "        line.get_color() == \"#CD3700\"\n",
    "        and line.get_label() != \"_nolegend_\"\n",
    "        and \"_child\" not in line.get_label()\n",
    "    ):\n",
    "        line.set_label(\"Predicted SBI SED\")\n",
    "    elif (\n",
    "        line.get_color() == \"#03A89E\"\n",
    "        and line.get_label() != \"_nolegend_\"\n",
    "        and \"_child\" not in line.get_label()\n",
    "    ):\n",
    "        print(line.get_label())\n",
    "        line.set_label(\"Predicted NS SED\")\n",
    "\n",
    "\n",
    "# Find labelled markers and rename them\n",
    "for marker in new_ax.collections + new_ax.lines:\n",
    "    if not hasattr(marker, \"get_label\"):\n",
    "        continue\n",
    "    if marker.get_label() == \"Posterior Phot.\" and marker.get_color() == \"#03A89E\":\n",
    "        marker.set_label(\"Predicted NS Phot.\")\n",
    "    elif marker.get_label() == \"Posterior Phot.\" and marker.get_color() == \"#CD3700\":\n",
    "        marker.set_label(\"Predicted SBI Phot.\")\n",
    "\n",
    "new_ax.legend(loc=\"lower right\", fontsize=16)\n",
    "\n",
    "figure.savefig(\n",
    "    f\"plots/posterior_comparison_{index}.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a80d9",
   "metadata": {},
   "source": [
    "### 5 SED recoveries and true SEDs (different redshifts, masses, dust etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da5ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = []\n",
    "for test_sample in test_samples:\n",
    "    fitter.recover_SED(X_test=test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06a2da",
   "metadata": {},
   "source": [
    "### SFH Recovery Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5f11a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(fitter.simulator.unused_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d65661",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.randint(0, len(fitter._X_test), size=100)\n",
    "\n",
    "for idx in random_idx:\n",
    "    sample = fitter._X_test[idx]\n",
    "    true_params = fitter._y_test[idx]\n",
    "    predicted_params = fitter.recover_SED(\n",
    "        sample, num_samples=50, plot=True, true_parameters=true_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21142d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort indexes for high log10_Av and low redshift\n",
    "Av_idx = list(fitter.fitted_parameter_names).index(\"log10_Av\")\n",
    "z_idx = list(fitter.feature_names).index(\"redshift\")\n",
    "mask = (fitter._y_test[:, Av_idx] > 0.5) & (fitter._X_test[:, z_idx] < 0.5)\n",
    "\n",
    "for i in range(len(fitter._X_test[mask])):\n",
    "    s = fitter._X_test[mask][i]\n",
    "    true_params = fitter._y_test[mask][i]\n",
    "    fitter.recover_SED(s, num_samples=50, plot=True, true_parameters=true_params)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
