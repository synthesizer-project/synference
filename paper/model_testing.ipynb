{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191991de",
   "metadata": {},
   "source": [
    "### Model Testing Figures for Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a67e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] = \"/usr/local/texlive/2025/bin/x86_64-linux:\" + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from synference import SBI_Fitter\n",
    "\n",
    "plt.style.use(\"paper.style\")\n",
    "\n",
    "model_name = \"PBP_LogNorm\"\n",
    "extra = \"mdn_noisy_zfix_v2\"\n",
    "\n",
    "\n",
    "fitter = SBI_Fitter.load_saved_model(\n",
    "    f\"/home/tharvey/work/synference/models/{model_name}/{model_name}_{extra}_posterior.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a64e8",
   "metadata": {},
   "source": [
    "Figure 2: Calibration and recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a453f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.plot_coverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee58dd8",
   "metadata": {},
   "source": [
    "## Calculate TARP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed6e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarp\n",
    "\n",
    "sample_path = f\"/home/tharvey/work/synference/models/{model_name}/plots/posterior_samples.npy\"\n",
    "true = fitter._y_test\n",
    "\n",
    "samples = np.load(sample_path)\n",
    "\n",
    "\n",
    "out = tarp.get_tarp_coverage(\n",
    "    samples,\n",
    "    true,\n",
    "    norm=True,\n",
    "    bootstrap=True,\n",
    "    num_bootstrap=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3379f17",
   "metadata": {},
   "source": [
    "\n",
    "## Load metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = f\"/home/tharvey/work/synference/models/{model_name}/{model_name}_{extra}_metrics.json\"\n",
    "\n",
    "import json\n",
    "\n",
    "with open(metrics, \"r\") as f:\n",
    "    met = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5deba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9), dpi=100)  # constrained_layout=True)\n",
    "\n",
    "gs = fig.add_gridspec(2, 6, height_ratios=[1, 1.44], hspace=-0.15, wspace=0.65)\n",
    "\n",
    "ax_top_l = fig.add_subplot(gs[0, :2])\n",
    "ax_top_r = fig.add_subplot(gs[0, 2:4])\n",
    "ax_top_c = fig.add_subplot(gs[0, 4:6])\n",
    "ax1 = fig.add_subplot(gs[1, :3])\n",
    "ax2 = fig.add_subplot(gs[1, 3:])\n",
    "axs = [ax_top_l, ax_top_r, ax_top_c]\n",
    "\n",
    "\n",
    "# TARP and Coverage\n",
    "ax1.plot([0, 1], [0, 1], \"k--\", label=\"Ideal\", alpha=0.5)\n",
    "ax1.set_xlabel(\"Predicted Percentile\")\n",
    "ax1.set_ylabel(\"Empirical Percentile\")\n",
    "ax1.text(0.05, 0.90, \"TARP\", transform=ax1.transAxes, fontsize=16)\n",
    "\n",
    "ax2.plot([0, 1], [0, 1], \"k--\", label=\"Ideal\", alpha=0.5)\n",
    "ax2.set_xlabel(\"Credibility Level\")\n",
    "ax2.set_ylabel(\"Expected Coverage\")\n",
    "ax2.text(0.05, 0.90, \"SBC\", transform=ax2.transAxes, fontsize=16)\n",
    "\n",
    "ax_params = [\"log_mass\", \"sfr_10\", \"log10_Av\"]\n",
    "param_latex = [\n",
    "    r\"\\log(\\rm M/M_\\odot)\",\n",
    "    r\"\\log(\\rm SFR_{10 \\rm Myr}/ M_\\odot yr^{-1})\",\n",
    "    r\"\\log(\\rm A_V)\",\n",
    "]\n",
    "indices = [list(fitter.fitted_parameter_names).index(p) for p in ax_params]\n",
    "\n",
    "# ax_top_r.set_xscale('log')\n",
    "# ax_top_r.set_yscale('log')\n",
    "# ax_top_r.set_xlim(1e-4, 1e3)\n",
    "# ax_top_r.set_ylim(1e-4, 1e3)\n",
    "# TARP\n",
    "\n",
    "ecp, alpha = out[0], out[1]\n",
    "ecp_mean = np.mean(ecp, axis=0)\n",
    "ecp_std = np.std(ecp, axis=0)\n",
    "ax1.plot(alpha, ecp_mean, label=\"TARP\", color=\"b\")\n",
    "ax1.fill_between(alpha, ecp_mean - ecp_std, ecp_mean + ecp_std, alpha=0.5, color=\"b\")\n",
    "ax1.fill_between(alpha, ecp_mean - 2 * ecp_std, ecp_mean + 2 * ecp_std, alpha=0.2, color=\"b\")\n",
    "\n",
    "\n",
    "# SBC\n",
    "trues = fitter._y_test\n",
    "\n",
    "ndata, npars = trues.shape\n",
    "ranks = (samples < trues[None, ...]).sum(axis=0)\n",
    "\n",
    "unicov = [np.sort(np.random.uniform(0, 1, ndata)) for j in range(200)]\n",
    "unip = np.percentile(unicov, [5, 16, 84, 95], axis=0)\n",
    "\n",
    "cdf = np.linspace(0, 1, len(ranks))\n",
    "for i in range(npars):\n",
    "    xr = np.sort(ranks[:, i])\n",
    "    xr = xr / xr[-1]\n",
    "    ax2.plot(cdf, cdf, \"k--\")\n",
    "\n",
    "    ax2.plot(xr, cdf, lw=2, label=fitter.fitted_parameter_names[i])\n",
    "ax2.set(adjustable=\"box\", aspect=\"equal\")\n",
    "ax1.set(adjustable=\"box\", aspect=\"equal\")\n",
    "\n",
    "ax2.set_xlabel(\"Predicted Percentile\")\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.legend()\n",
    "\n",
    "for i, ax in enumerate([ax_top_l, ax_top_r, ax_top_c]):\n",
    "    param = ax_params[i]\n",
    "    idx = indices[i]\n",
    "    # Get 16/50/84 percentiles\n",
    "    # p16 = np.percentile(samples[:, :, idx], 16, axis=0)\n",
    "    # p50 = np.percentile(samples[:, :, idx], 50, axis=0)\n",
    "    # p84 = np.percentile(samples[:, :, idx], 84, axis=0)\n",
    "    # ax.errorbar(true[:, idx], p50, yerr=[p50 - p16, p84 - p50], fmt='o',\n",
    "    #  alpha=0.1, color='C0', markersize=2)\n",
    "    # Instead, plot as hexbin and count all draws\n",
    "    # broadcast true to match samples shape\n",
    "\n",
    "    true_full = np.repeat(true[:, idx][np.newaxis, :], samples.shape[0], axis=0).flatten()\n",
    "    yy = samples[:, :, idx].flatten()\n",
    "    if i == 1:\n",
    "        true_full = np.log10(true_full)\n",
    "        yy = np.log10(yy)\n",
    "        yy = np.clip(yy, -6, None)\n",
    "        true_full = np.clip(true_full, -6, None)\n",
    "    ax.hexbin(\n",
    "        true_full,\n",
    "        yy,\n",
    "        gridsize=50,\n",
    "        cmap=\"cmr.sunburst_r\",\n",
    "        mincnt=1,\n",
    "    )  # bins='log')\n",
    "    ax.set(adjustable=\"box\", aspect=\"equal\")\n",
    "\n",
    "    ax.set_xlabel(\"True Value\")\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Inferred Value\")\n",
    "    ax.plot(\n",
    "        [true_full.min(), true_full.max()], [true_full.min(), true_full.max()], \"k--\", alpha=0.5\n",
    "    )\n",
    "    ax.text(0.05, 0.90, f\"${param_latex[i]}$\", transform=ax.transAxes, fontsize=11)\n",
    "\n",
    "fig.savefig(\n",
    "    f\"/home/tharvey/work/synference/models/{model_name}/plots/{model_name}_{extra}_validation.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "fig.savefig(f\"plots/{model_name}_{extra}_validation.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28904a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# CORRECTED FUNCTION\n",
    "def calculate_quantile_error_per_param(\n",
    "    true_params: np.ndarray, posteriors: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Calculates a quantile-based error metric for each parameter of each observation.\n",
    "\n",
    "    This version is corrected to handle posteriors with the shape\n",
    "    (n_samples, n_points, n_dim), as indicated by the traceback.\n",
    "    \"\"\"\n",
    "    # Your shapes:\n",
    "    # true_params: (n_points, n_dim) -> (25000, 11)\n",
    "    # posteriors:  (n_samples, n_points, n_dim) -> (1000, 25000, 11)\n",
    "\n",
    "    # 1. Reshape true_params to (1, n_points, n_dim) to enable broadcasting.\n",
    "    # This aligns the `n_points` and `n_dim` axes correctly.\n",
    "    true_params_reshaped = true_params[np.newaxis, :, :]\n",
    "\n",
    "    # 2. Perform the comparison. Broadcasting now works:\n",
    "    # (1000, 25000, 11) < (1, 25000, 11) -> a boolean array of (1000, 25000, 11)\n",
    "    comparison = posteriors < true_params_reshaped\n",
    "\n",
    "    # 3. Take the mean over the `n_samples` axis (which is now axis=0).\n",
    "    # This collapses the samples dimension, leaving a result of shape (n_points, n_dim).\n",
    "    quantiles = np.mean(comparison, axis=0)\n",
    "\n",
    "    errors = np.abs(quantiles - 0.5)\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "def plot_colored_corner(\n",
    "    data: np.ndarray, errors: np.ndarray, param_names: list[str] | None = None\n",
    ") -> None:\n",
    "    \"\"\"Creates a corner plot where scatter points are colored by the error metric.\"\"\"\n",
    "    n_dim = data.shape[1]\n",
    "    if param_names is None:\n",
    "        param_names = [f\"Param {i}\" for i in range(n_dim)]\n",
    "\n",
    "    fig, axes = plt.subplots(n_dim, n_dim, figsize=(12, 12))\n",
    "\n",
    "    # Adjust subplots to be tight\n",
    "    fig.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1, hspace=0.1, wspace=0.1)\n",
    "\n",
    "    for i in range(n_dim):\n",
    "        for j in range(n_dim):\n",
    "            ax = axes[i, j]\n",
    "\n",
    "            # Diagonal: Plot 1D histograms of the true parameter distribution\n",
    "            if i == j:\n",
    "                sns.histplot(data[:, i], ax=ax, bins=20, kde=True)\n",
    "            # Hide upper triangle\n",
    "            elif i < j:\n",
    "                ax.axis(\"off\")\n",
    "            # Lower triangle: Plot 2D scatter plots\n",
    "            else:\n",
    "                # Color the points by the error metric\n",
    "                sc = ax.scatter(\n",
    "                    data[:, j],\n",
    "                    data[:, i],\n",
    "                    cmap=\"viridis\",\n",
    "                    s=5,\n",
    "                    alpha=0.7,\n",
    "                    vmin=0,\n",
    "                    vmax=0.5,\n",
    "                    c=errors,\n",
    "                )\n",
    "\n",
    "            # Labels for the outer plots only\n",
    "            if j == 0 and i > 0:\n",
    "                ax.set_ylabel(param_names[i])\n",
    "            if i == n_dim - 1:\n",
    "                ax.set_xlabel(param_names[j])\n",
    "\n",
    "            # Remove ticks for inner plots to clean up the view\n",
    "            if i < n_dim - 1:\n",
    "                ax.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n",
    "            if j > 0:\n",
    "                ax.tick_params(axis=\"y\", which=\"both\", left=False, right=False, labelleft=False)\n",
    "\n",
    "    # Add a colorbar\n",
    "    cbar_ax = fig.add_axes([0.65, 0.7, 0.25, 0.02])\n",
    "    cbar = fig.colorbar(sc, cax=cbar_ax, orientation=\"horizontal\")\n",
    "    cbar.set_label(\"Prediction Error (|quantile - 0.5|)\")\n",
    "\n",
    "    plt.suptitle(\"Corner Plot of True Parameters Colored by Prediction Error\", fontsize=16, y=0.95)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "errors = calculate_quantile_error_per_param(true, samples)\n",
    "errors = np.mean(errors, axis=1)\n",
    "plot_colored_corner(true, errors, param_names=fitter.fitted_parameter_names.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad28ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d6da58",
   "metadata": {},
   "source": [
    "## Pick a few examples and compare posteriors with nested sampling and the truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aae5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = fitter._X_test[99]\n",
    "true_params = fitter._y_test[99]\n",
    "predicted_params = fitter.sample_posterior(sample, num_samples=1000)\n",
    "\n",
    "\n",
    "sampler = fitter.fit_observation_using_sampler(\n",
    "    observation=sample, sampler=\"nautilus\", sampler_kwargs={\"n_live\": 500}\n",
    ")\n",
    "points, log_w, log_l = sampler.posterior()\n",
    "\n",
    "# Plot corner of both on same (see through, only contours) and true value\n",
    "\n",
    "import corner\n",
    "\n",
    "figure = corner.corner(\n",
    "    points,\n",
    "    weights=np.exp(log_w - log_w.max()),\n",
    "    labels=fitter.fitted_parameter_names,\n",
    "    color=\"C1\",\n",
    "    plot_datapoints=False,\n",
    "    fill_contours=True,\n",
    "    levels=(0.68, 0.95),\n",
    "    plot_density=True,\n",
    "    smooth=1.0,\n",
    "    label_kwargs={\"fontsize\": 16},\n",
    "    title_kwargs={\"fontsize\": 14},\n",
    "    quantiles=[0.16, 0.5, 0.84],\n",
    "    show_titles=True,\n",
    ")\n",
    "\n",
    "corner.corner(\n",
    "    predicted_params,\n",
    "    labels=fitter.fitted_parameter_names,\n",
    "    color=\"C0\",\n",
    "    plot_datapoints=False,\n",
    "    fill_contours=False,\n",
    "    plot_density=True,\n",
    "    smooth=1.0,\n",
    "    fig=figure,\n",
    "    quantiles=[0.16, 0.5, 0.84],\n",
    "    show_titles=True,\n",
    ")\n",
    "\n",
    "# Add true value lines\n",
    "ndim = true_params.shape[0]\n",
    "axes = np.array(figure.axes).reshape((ndim, ndim))\n",
    "for i in range(ndim):\n",
    "    for j in range(ndim):\n",
    "        ax = axes[i, j]\n",
    "        if i == j:\n",
    "            ax.axvline(true_params[i], color=\"k\", linestyle=\"--\")\n",
    "        elif i > j:\n",
    "            ax.axvline(true_params[j], color=\"k\", linestyle=\"--\")\n",
    "            ax.axhline(true_params[i], color=\"k\", linestyle=\"--\")\n",
    "            ax.plot(true_params[j], true_params[i], \"ks\")\n",
    "\n",
    "figure.suptitle(\"Comparison of Posterior Samples: MDN vs Nested Sampling\", fontsize=16)\n",
    "figure.savefig(\n",
    "    f\"/home/tharvey/work/synference/models/{model_name}/plots/{model_name}_{extra}_posterior_comparison.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a80d9",
   "metadata": {},
   "source": [
    "### 5 SED recoveries and true SEDs (different redshifts, masses, dust etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06a2da",
   "metadata": {},
   "source": [
    "### SFH Recovery Examples"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
