{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191991de",
   "metadata": {},
   "source": [
    "### Model Testing Figures for Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a67e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import copy\n",
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] = \"/usr/local/texlive/2025/bin/x86_64-linux:\" + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from synference import SBI_Fitter, create_uncertainty_models_from_EPOCHS_cat\n",
    "\n",
    "plt.style.use(\"paper.style\")\n",
    "model_name = \"BPASS_DenseBasis_v4_final\"\n",
    "extra = \"nsf_0\"\n",
    "\n",
    "bands = [\n",
    "    \"F435W\",\n",
    "    \"F606W\",\n",
    "    \"F775W\",\n",
    "    \"F814W\",\n",
    "    \"F850LP\",\n",
    "    \"F090W\",\n",
    "    \"F115W\",\n",
    "    \"F150W\",\n",
    "    \"F200W\",\n",
    "    \"F277W\",\n",
    "    \"F335M\",\n",
    "    \"F356W\",\n",
    "    \"F410M\",\n",
    "    \"F444W\",\n",
    "]\n",
    "hst_bands = [\"F435W\", \"F606W\", \"F775W\", \"F814W\", \"F850LP\"]\n",
    "new_band_names = [\n",
    "    (f\"HST/ACS_WFC.{band.upper()}\" if band in hst_bands else f\"JWST/NIRCam.{band.upper()}\")\n",
    "    for band in bands\n",
    "]\n",
    "data_err_file = \"/home/tharvey/work/JADES-DR3-GS_MASTER_Sel-F277W+F356W+F444W_v13.fits\"\n",
    "\n",
    "\n",
    "fitter = SBI_Fitter.load_saved_model(\n",
    "    f\"/home/tharvey/work/synference/models/{model_name}/{model_name}_{extra}_posterior.pkl\",\n",
    "    grid_path=\"/home/tharvey/work/synference/grids/grid_BPASS_Chab_DenseBasis_SFH_0.01_z_14_logN_6.0_Calzetti_v4_multinode.hdf5\",\n",
    ")\n",
    "\n",
    "\n",
    "empirical_noise_models = create_uncertainty_models_from_EPOCHS_cat(\n",
    "    data_err_file,\n",
    "    bands,\n",
    "    new_band_names,\n",
    "    plot=False,\n",
    "    hdu=\"OBJECTS\",\n",
    "    save=False,\n",
    "    min_flux_error=0,\n",
    "    model_class=\"asinh\",\n",
    ")\n",
    "\n",
    "fitter.feature_array_flags[\"empirical_noise_models\"] = empirical_noise_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a64e8",
   "metadata": {},
   "source": [
    "Figure 2: Calibration and recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a453f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.plot_coverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee58dd8",
   "metadata": {},
   "source": [
    "## Calculate TARP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed6e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarp\n",
    "\n",
    "sample_path = (\n",
    "    f\"/home/tharvey/work/synference/models/{model_name}/plots/{extra}/posterior_samples.npy\"\n",
    ")\n",
    "true = fitter._y_test\n",
    "\n",
    "samples = np.load(sample_path)\n",
    "\n",
    "\n",
    "out = tarp.get_tarp_coverage(\n",
    "    samples,\n",
    "    true,\n",
    "    norm=True,\n",
    "    bootstrap=True,\n",
    "    num_bootstrap=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3379f17",
   "metadata": {},
   "source": [
    "\n",
    "## Load metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = f\"/home/tharvey/work/synference/models/{model_name}/{model_name}_{extra}_metrics.json\"\n",
    "\n",
    "import json\n",
    "\n",
    "with open(metrics, \"r\") as f:\n",
    "    met = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82032074",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.fitted_parameter_names\n",
    "\n",
    "\n",
    "param_labels = [\n",
    "    r\"$\\log M_*$\",\n",
    "    r\"$\\log Z/Z_\\odot$\",\n",
    "    r\"$\\rm \\log_{10} \\ A_V$\",\n",
    "    r\"$\\log$ SFR\",\n",
    "    \"$t_{25}$\",\n",
    "    \"$t_{50}$\",\n",
    "    \"$t_{75}$\",\n",
    "    r\"$\\log$ Age$_M$\",\n",
    "    r\"$\\log$ SFR$_{10}$\",\n",
    "    r\"$\\log M_{*,surv}$\",\n",
    "    \"$\\\\beta$\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744cf453",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.fitted_parameter_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7ae5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.plot_parameter_deviations(snr_bins=[5, 10, np.inf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3596c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_indices = fitter.bin_noisy_testing_data(\n",
    "    X_test=fitter._X_test,\n",
    "    y_test=fitter._y_test,\n",
    "    snr_bins=[5, np.inf],\n",
    "    snr_feature_names=None,\n",
    "    return_indices=True,\n",
    ")[0]\n",
    "\n",
    "snr_indices = np.array(snr_indices).flatten()\n",
    "\n",
    "# Make it a boolean mask\n",
    "snr_indices = np.isin(np.arange(fitter._y_test.shape[0]), snr_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b02ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = fitter._X_test[snr_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5deba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gridspec\n",
    "\n",
    "fig = plt.figure(\n",
    "    figsize=(9, 9),\n",
    "    dpi=150,\n",
    ")\n",
    "\n",
    "gs = fig.add_gridspec(3, 6, height_ratios=[1, 1, 1.44])\n",
    "\n",
    "ax_top_l = fig.add_subplot(gs[0, :2])\n",
    "ax_top_r = fig.add_subplot(gs[0, 2:4])\n",
    "ax_top_c = fig.add_subplot(gs[0, 4:6])\n",
    "ax_middle_l = fig.add_subplot(gs[1, :2])\n",
    "ax_middle_r = fig.add_subplot(gs[1, 2:4])\n",
    "ax_middle_c = fig.add_subplot(gs[1, 4:6])\n",
    "ax1 = fig.add_subplot(gs[2, :3])\n",
    "ax2 = fig.add_subplot(gs[2, 3:])\n",
    "axs = [ax_top_l, ax_top_r, ax_top_c]\n",
    "\n",
    "\n",
    "# TARP and Coverage\n",
    "ax1.plot([0, 1], [0, 1], \"k--\", label=\"Ideal\", alpha=0.5)\n",
    "ax1.set_xlabel(\"Predicted Percentile\")\n",
    "ax1.set_ylabel(\"Empirical Percentile\")\n",
    "ax1.text(0.05, 0.90, \"TARP\", transform=ax1.transAxes, fontsize=16)\n",
    "\n",
    "ax2.plot([0, 1], [0, 1], \"k--\", label=\"Ideal\", alpha=0.5)\n",
    "ax2.set_xlabel(\"Credibility Level\")\n",
    "ax2.set_ylabel(\"Expected Coverage\")\n",
    "ax2.text(0.05, 0.90, \"SBC\", transform=ax2.transAxes, fontsize=16)\n",
    "\n",
    "ax_params = [\n",
    "    \"log_mass\",\n",
    "    \"log10_floor_sfr_10\",\n",
    "    \"log10_Av\",\n",
    "    \"log10_mass_weighted_age\",\n",
    "    \"beta\",\n",
    "    \"log_surviving_mass\",\n",
    "]\n",
    "param_latex = [\n",
    "    r\"\\log(\\rm M_\\star/M_\\odot)\",\n",
    "    r\"\\log(\\rm SFR_{10 \\rm Myr}/ M_\\odot yr^{-1})\",\n",
    "    r\"\\log(\\rm A_V / \\rm mag)\",\n",
    "    r\"\\log(\\rm Age_M / \\rm yr)\",\n",
    "    r\"\\beta\",\n",
    "    r\"\\rm \\log M_{\\star,surv}/M_\\odot)\",\n",
    "]\n",
    "indices = [list(fitter.fitted_parameter_names).index(p) for p in ax_params]\n",
    "\n",
    "# ax_top_r.set_xscale('log')\n",
    "# ax_top_r.set_yscale('log')\n",
    "# ax_top_r.set_xlim(1e-4, 1e3)\n",
    "# ax_top_r.set_ylim(1e-4, 1e3)\n",
    "# TARP\n",
    "\n",
    "ecp, alpha = out[0], out[1]\n",
    "ecp_mean = np.mean(ecp, axis=0)\n",
    "ecp_std = np.std(ecp, axis=0)\n",
    "ax1.plot(alpha, ecp_mean, label=\"TARP\", color=\"b\")\n",
    "ax1.fill_between(alpha, ecp_mean - ecp_std, ecp_mean + ecp_std, alpha=0.5, color=\"b\")\n",
    "ax1.fill_between(alpha, ecp_mean - 2 * ecp_std, ecp_mean + 2 * ecp_std, alpha=0.2, color=\"b\")\n",
    "\n",
    "\n",
    "# SBC\n",
    "trues = fitter._y_test\n",
    "import copy\n",
    "\n",
    "ptrues = copy.deepcopy(trues)[snr_indices]\n",
    "psamples = copy.deepcopy(samples)[:, snr_indices, :]\n",
    "\n",
    "# lower SNR\n",
    "ltrues = copy.deepcopy(trues)[~snr_indices]\n",
    "lsamples = copy.deepcopy(samples)[:, ~snr_indices, :]\n",
    "\n",
    "print(ptrues.shape, trues.shape, psamples.shape, samples.shape)\n",
    "\n",
    "\n",
    "# Apply SNR mask to samples and trues\n",
    "\n",
    "ndata, npars = trues.shape\n",
    "ranks = (samples < trues[None, ...]).sum(axis=0)\n",
    "\n",
    "unicov = [np.sort(np.random.uniform(0, 1, ndata)) for j in range(200)]\n",
    "unip = np.percentile(unicov, [5, 16, 84, 95], axis=0)\n",
    "\n",
    "cdf = np.linspace(0, 1, len(ranks))\n",
    "cmap = plt.get_cmap(\"RdYlBu\")\n",
    "colors = [cmap(i / npars) for i in range(npars)]\n",
    "\n",
    "for i in range(npars):\n",
    "    xr = np.sort(ranks[:, i])\n",
    "    xr = xr / xr[-1]\n",
    "    ax2.plot(cdf, cdf, \"k--\")\n",
    "\n",
    "    ax2.plot(xr, cdf, lw=2, label=param_labels[i], alpha=1, color=colors[i])\n",
    "ax2.set(adjustable=\"box\", aspect=\"equal\")\n",
    "ax1.set(adjustable=\"box\", aspect=\"equal\")\n",
    "\n",
    "ax2.set_xlabel(\"Predicted Percentile\")\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.legend(fontsize=8)\n",
    "\n",
    "for i, ax in enumerate([ax_top_l, ax_top_r, ax_top_c, ax_middle_l, ax_middle_r, ax_middle_c]):\n",
    "    param = ax_params[i]\n",
    "    idx = indices[i]\n",
    "    order_index = list(fitter.fitted_parameter_names).index(param)\n",
    "\n",
    "    # r2 = met[\"R_squared\"][order_index]\n",
    "    # rmse = met[\"RMSE\"][order_index]\n",
    "    # Recalculate RMSE and R2 for just high SNR data\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "    y_true = ptrues[:, idx]\n",
    "    y_pred = np.median(psamples[:, :, idx], axis=0)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    # Get 16/50/84 percentiles\n",
    "    # p16 = np.percentile(samples[:, :, idx], 16, axis=0)\n",
    "    # p50 = np.percentile(samples[:, :, idx], 50, axis=0)\n",
    "    # p84 = np.percentile(samples[:, :, idx], 84, axis=0)\n",
    "    # ax.errorbar(true[:, idx], p50, yerr=[p50 - p16, p84 - p50], fmt='o',\n",
    "    #  alpha=0.1, color='C0', markersize=2)\n",
    "    # Instead, plot as hexbin and count all draws\n",
    "    # broadcast true to match samples shape\n",
    "    # Do Hexbins of LOW SNR data in blues\n",
    "    ltrue_full = np.repeat(ltrues[:, idx][np.newaxis, :], lsamples.shape[0], axis=0).flatten()\n",
    "    lyy = lsamples[:, :, idx].flatten()\n",
    "\n",
    "    true_full = np.repeat(ptrues[:, idx][np.newaxis, :], psamples.shape[0], axis=0).flatten()\n",
    "    yy = psamples[:, :, idx].flatten()\n",
    "    # if i == 1:\n",
    "    #    true_full = np.log10(true_full)\n",
    "    #    yy = np.log10(yy)\n",
    "    #    yy = np.clip(yy, -6, None)\n",
    "    #    true_full = np.clip(true_full, -6, None)\n",
    "    # if i == 2:\n",
    "    #    yy = 10**yy\n",
    "    #    true_full = 10**true_full\n",
    "    pparams = {}\n",
    "    if param == \"beta\":\n",
    "        pparams = dict(extent=(-2.8, 2, -2.8, 2))\n",
    "        ax.set_xlim(-2.8, 0)\n",
    "        ax.set_ylim(-2.8, 0)\n",
    "    if param == \"log10_floor_sfr_10\":\n",
    "        # Remove data below -3\n",
    "        mask = (true_full > -3) & (yy > -3)\n",
    "        true_full = true_full[mask]\n",
    "        yy = yy[mask]\n",
    "        mask = (ltrue_full > -3) & (lyy > -3)\n",
    "        ltrue_full = ltrue_full[mask]\n",
    "        lyy = lyy[mask]\n",
    "    if param == \"log10_Av\":\n",
    "        mask = (true_full > -2) & (yy > -2)\n",
    "        true_full = true_full[mask]\n",
    "        yy = yy[mask]\n",
    "        mask = (ltrue_full > -2) & (lyy > -2)\n",
    "        ltrue_full = ltrue_full[mask]\n",
    "        lyy = lyy[mask]\n",
    "\n",
    "    ax.hexbin(\n",
    "        true_full,\n",
    "        yy,\n",
    "        gridsize=50,\n",
    "        cmap=\"cmr.sunburst_r\",\n",
    "        mincnt=1,\n",
    "        **pparams,\n",
    "    )  # bins='log')\n",
    "    ax.set(adjustable=\"box\", aspect=\"equal\")\n",
    "\n",
    "    \"\"\"ax.hexbin(\n",
    "        ltrue_full,\n",
    "        lyy,\n",
    "        gridsize=50,\n",
    "        cmap=\"Blues\",\n",
    "        mincnt=1,\n",
    "        alpha=0.5,\n",
    "        **pparams,\n",
    "    )  # bins='log')\n",
    "\"\"\"\n",
    "    if i > 2:\n",
    "        ax.set_xlabel(\"True Value\")\n",
    "    if i == 0 or i == 3:\n",
    "        ax.set_ylabel(\"Inferred Value\")\n",
    "    ax.plot(\n",
    "        [true_full.min(), true_full.max()], [true_full.min(), true_full.max()], \"k--\", alpha=0.5\n",
    "    )\n",
    "    ax.text(0.05, 0.90, f\"${param_latex[i]}$\", transform=ax.transAxes, fontsize=11)\n",
    "    ax.text(0.05, 0.80, \"RMSE = {:.2f}\".format(rmse), transform=ax.transAxes, fontsize=10)\n",
    "    ax.text(0.05, 0.70, f\"$R^2={r2:.2f}$\", transform=ax.transAxes, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.2, wspace=-0.25)\n",
    "fig.savefig(\n",
    "    f\"/home/tharvey/work/synference/models/{model_name}/plots/{model_name}_{extra}_validation.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "fig.savefig(f\"plots/{model_name}_{extra}_validation.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28904a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Make text bigger\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 12, \"axes.labelsize\": 14, \"axes.titlesize\": 14})\n",
    "\n",
    "\n",
    "# CORRECTED FUNCTION\n",
    "def calculate_quantile_error_per_param(\n",
    "    true_params: np.ndarray, posteriors: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Calculates a quantile-based error metric for each parameter of each observation.\n",
    "\n",
    "    This version is corrected to handle posteriors with the shape\n",
    "    (n_samples, n_points, n_dim), as indicated by the traceback.\n",
    "    \"\"\"\n",
    "    # Your shapes:\n",
    "    # true_params: (n_points, n_dim) -> (25000, 11)\n",
    "    # posteriors:  (n_samples, n_points, n_dim) -> (1000, 25000, 11)\n",
    "\n",
    "    # 1. Reshape true_params to (1, n_points, n_dim) to enable broadcasting.\n",
    "    # This aligns the `n_points` and `n_dim` axes correctly.\n",
    "    true_params_reshaped = true_params[np.newaxis, :, :]\n",
    "\n",
    "    # 2. Perform the comparison. Broadcasting now works:\n",
    "    # (1000, 25000, 11) < (1, 25000, 11) -> a boolean array of (1000, 25000, 11)\n",
    "    comparison = posteriors < true_params_reshaped\n",
    "\n",
    "    # 3. Take the mean over the `n_samples` axis (which is now axis=0).\n",
    "    # This collapses the samples dimension, leaving a result of shape (n_points, n_dim).\n",
    "    quantiles = np.mean(comparison, axis=0)\n",
    "\n",
    "    errors = np.abs(quantiles - 0.5)\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "def plot_colored_corner(\n",
    "    data: np.ndarray,\n",
    "    errors: np.ndarray,\n",
    "    param_names: list[str] | None = None,\n",
    "    elabel: str = \"Prediction Error (|quantile - 0.5|)\",\n",
    "    params_to_remove: list[str] = [],\n",
    ") -> None:\n",
    "    \"\"\"Creates a corner plot where scatter points are colored by the error metric.\"\"\"\n",
    "    n_dim = data.shape[1]\n",
    "    # Remove specified parameters\n",
    "    if params_to_remove:\n",
    "        indices_to_keep = [i for i, name in enumerate(param_names) if name not in params_to_remove]\n",
    "        data = data[:, indices_to_keep]\n",
    "        errors = errors\n",
    "        if param_names is not None:\n",
    "            param_names = [param_names[i] for i in indices_to_keep]\n",
    "        n_dim = data.shape[1]\n",
    "    if param_names is None:\n",
    "        param_names = [f\"Param {i}\" for i in range(n_dim)]\n",
    "\n",
    "    fig, axes = plt.subplots(n_dim, n_dim, figsize=(12, 12))\n",
    "\n",
    "    # Adjust subplots to be tight\n",
    "    fig.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1, hspace=0.1, wspace=0.1)\n",
    "\n",
    "    for i in range(n_dim):\n",
    "        for j in range(n_dim):\n",
    "            ax = axes[i, j]\n",
    "\n",
    "            # Diagonal: Plot 1D histograms of the true parameter distribution\n",
    "            if i == j:\n",
    "                sns.histplot(\n",
    "                    data[:, i],\n",
    "                    ax=ax,\n",
    "                    bins=20,\n",
    "                    kde=True,\n",
    "                    element=\"step\",\n",
    "                    color=\"sandybrown\",\n",
    "                    alpha=0.7,\n",
    "                )\n",
    "                ax.set_ylabel(\"\")\n",
    "            # Hide upper triangle\n",
    "            elif i < j:\n",
    "                ax.axis(\"off\")\n",
    "            # Lower triangle: Plot 2D scatter plots\n",
    "            else:\n",
    "                # Color the points by the error metric\n",
    "                \"\"\"sc = ax.scatter(\n",
    "                    data[:, j],\n",
    "                    data[:, i],\n",
    "                    cmap=\"cmr.ember\",\n",
    "                    vmin=np.percentile(errors, 5),\n",
    "                    vmax=np.percentile(errors, 95),\n",
    "                    s=5,\n",
    "                    alpha=0.7,\n",
    "                    c=errors,\n",
    "                )\"\"\"\n",
    "                # do a hexbin - not density just average error in each bin\n",
    "                sc = ax.hexbin(\n",
    "                    data[:, j],\n",
    "                    data[:, i],\n",
    "                    C=errors,\n",
    "                    reduce_C_function=np.mean,\n",
    "                    gridsize=25,\n",
    "                    cmap=\"cmr.ember\",\n",
    "                    vmin=np.percentile(errors, 5),\n",
    "                    vmax=np.percentile(errors, 95),\n",
    "                    mincnt=1,\n",
    "                )\n",
    "            # Labels for the outer plots only\n",
    "            if j == 0 and i > 0:\n",
    "                ax.set_ylabel(param_names[i])\n",
    "            if i == n_dim - 1:\n",
    "                ax.set_xlabel(param_names[j])\n",
    "\n",
    "            # Remove ticks for inner plots to clean up the view\n",
    "            if i < n_dim - 1:\n",
    "                ax.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n",
    "            if j > 0:\n",
    "                ax.tick_params(axis=\"y\", which=\"both\", left=False, right=False, labelleft=False)\n",
    "\n",
    "    # Add a colorbar\n",
    "    cbar_ax = fig.add_axes([0.35, 0.7, 0.55, 0.02])\n",
    "    cbar = fig.colorbar(sc, cax=cbar_ax, orientation=\"horizontal\")\n",
    "    cbar.set_label(elabel)\n",
    "\n",
    "    # plt.suptitle(\"Corner Plot of True Parameters Colored by Prediction Error\", fontsize=16, y=0.95) # noqa E501\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "sample_path = (\n",
    "    f\"/home/tharvey/work/synference/models/{model_name}/plots/{extra}/posterior_samples.npy\"\n",
    ")\n",
    "true = fitter._y_test\n",
    "\n",
    "samples = np.load(sample_path)\n",
    "log_prob_path = f\"/home/tharvey/work/synference/models/{model_name}/plots/{extra}/true_logprobs.npy\"\n",
    "\n",
    "log_probs = np.load(log_prob_path)\n",
    "\n",
    "errors = calculate_quantile_error_per_param(true, samples)\n",
    "errors = np.mean(errors, axis=1)\n",
    "\n",
    "params_to_remove = [\"$\\\\beta$\"]\n",
    "plot_colored_corner(\n",
    "    true,\n",
    "    log_probs,\n",
    "    param_names=param_labels,\n",
    "    elabel=\"$\\\\log P(\\\\theta | x)$\",\n",
    "    params_to_remove=params_to_remove,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d6da58",
   "metadata": {},
   "source": [
    "## Pick a few examples and compare posteriors with nested sampling and the truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5fc12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.recreate_simulator_from_grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d50391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator as op\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def search_parameter_array(\n",
    "    array: np.ndarray,\n",
    "    parameter_names: List[str],\n",
    "    constraints: List[Tuple[str, str, Union[int, float]]],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Return indexes in array with columns which meet constraints.\n",
    "\n",
    "    Args:\n",
    "        array (np.ndarray): The data array where rows are entries and columns\n",
    "                            are parameters.\n",
    "        parameter_names (List[str]): A list of string names for each column\n",
    "                                     in the array.\n",
    "        constraints (List[Tuple[str, str, Union[int, float]]]):\n",
    "            A list of tuples, where each tuple defines a constraint in the\n",
    "            format: (parameter_name, operator_string, value).\n",
    "            e.g., ('mass', '>', 100)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A NumPy array of integer indices for the rows in the input\n",
    "                    array that satisfy all of the given constraints.\n",
    "    \"\"\"\n",
    "    # A mapping from string representations of operators to the actual\n",
    "    # functions from the `operator` module.\n",
    "    operator_map = {\">\": op.gt, \"<\": op.lt, \">=\": op.ge, \"<=\": op.le, \"==\": op.eq, \"!=\": op.ne}\n",
    "\n",
    "    # Start with a boolean mask of all True values, the same length as the array.\n",
    "    # We will combine this with the mask from each constraint.\n",
    "    combined_mask = np.ones(array.shape[0], dtype=bool)\n",
    "\n",
    "    # Iterate over each constraint and apply it to the array\n",
    "    for param_name, operator_str, value in constraints:\n",
    "        try:\n",
    "            # Find the column index for the given parameter name\n",
    "            col_idx = parameter_names.index(param_name)\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Parameter '{param_name}' not found. Skipping constraint.\")\n",
    "            continue\n",
    "\n",
    "        # Get the corresponding operator function from our map\n",
    "        op_func = operator_map.get(operator_str)\n",
    "        if not op_func:\n",
    "            raise ValueError(f\"Unsupported operator: {operator_str}\")\n",
    "\n",
    "        # Create a boolean mask for the current constraint\n",
    "        current_mask = op_func(array[:, col_idx], value)\n",
    "\n",
    "        # Update the combined mask using a logical AND.\n",
    "        # This ensures that only rows satisfying *all* constraints are kept.\n",
    "        combined_mask &= current_mask\n",
    "\n",
    "    # np.where returns a tuple of arrays (one for each dimension).\n",
    "    # Since our mask is 1D, we just need the first element.\n",
    "    return np.where(combined_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0d1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.fitted_parameter_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc7fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [38304, 14238, 3448, 87566, 92980, 61720, 98859, 56103]\n",
    "\n",
    "# 86137 - for last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7322db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a gridspec with 2x4 plots\n",
    "\n",
    "arr = copy.deepcopy(fitter._y_test)\n",
    "constraint_names = copy.deepcopy(list(fitter.fitted_parameter_names))\n",
    "\n",
    "redshift = copy.deepcopy(fitter._X_test[:, fitter.feature_names.index(\"redshift\")])\n",
    "arr = np.column_stack((arr, redshift))\n",
    "constraint_names.append(\"redshift\")\n",
    "\n",
    "flexoki_colors = [\n",
    "    \"#D14D41\",\n",
    "    \"#DA702C\",\n",
    "    \"#D0A215\",\n",
    "    \"#879A39\",\n",
    "    \"#3AA99F\",\n",
    "    \"#4385BE\",\n",
    "    \"#8B7EC8\",\n",
    "    \"#CE5D97\",\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(7, 10), dpi=150)\n",
    "ax = fig.subplots(nrows=4, ncols=2, sharex=\"col\")\n",
    "fig.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "ax = ax.flatten()\n",
    "names = [\n",
    "    \"Dusty $z=2$ starburst\",\n",
    "    \"Massive $z=0.1$ quiescent\",\n",
    "    \"Post-Starburst at $z=5$\",\n",
    "    \"Highly Star-forming at $z=7$\",\n",
    "    \"Starforming at $z=13$\",\n",
    "    \"Dusty $z=7$ starburst\",\n",
    "    \"Low-mass $z=2$ starforming\",\n",
    "    \"Low-mass $z=9$ starforming\",\n",
    "]\n",
    "\n",
    "\n",
    "generate_new = [False, False, False, False, False, False, False, True]\n",
    "\n",
    "constraints = [\n",
    "    [\n",
    "        (\"log_mass\", \">\", 9.5),\n",
    "        (\"log10_Av\", \">\", 0.5),\n",
    "        (\"log10_floor_sfr_10\", \">\", 1),\n",
    "        (\"redshift\", \"<\", 2.5),\n",
    "        (\"redshift\", \">\", 1.5),\n",
    "    ],\n",
    "    [\n",
    "        (\"log_mass\", \">\", 10.5),\n",
    "        (\"log10_Av\", \"<\", 0.5),\n",
    "        (\"log10_floor_sfr_10\", \"<\", -1),\n",
    "        (\"redshift\", \"<\", 0.5),\n",
    "        (\"redshift\", \">\", 0.0),\n",
    "    ],\n",
    "    [\n",
    "        (\"log_mass\", \">\", 9.5),\n",
    "        (\"log10_Av\", \"<\", 0.5),\n",
    "        (\"log10_floor_sfr_10\", \"<\", -1),\n",
    "        (\"log10_mass_weighted_age\", \"<\", 2.5),\n",
    "        (\"redshift\", \"<\", 6),\n",
    "        (\"redshift\", \">\", 4),\n",
    "    ],\n",
    "    [\n",
    "        (\"log_mass\", \">\", 8.5),\n",
    "        (\"log10_Av\", \"<\", 0.5),\n",
    "        (\"log10_floor_sfr_10\", \">\", 1),\n",
    "        (\"redshift\", \"<\", 8),\n",
    "        (\"redshift\", \">\", 6),\n",
    "    ],\n",
    "    [\n",
    "        (\"log_mass\", \">\", 8.5),\n",
    "        (\"log10_Av\", \"<\", 0.5),\n",
    "        (\"log10_floor_sfr_10\", \">\", -1),\n",
    "        (\"redshift\", \"<\", 14),\n",
    "        (\"redshift\", \">\", 12),\n",
    "    ],\n",
    "    [\n",
    "        (\"log_mass\", \">\", 9.5),\n",
    "        (\"log10_Av\", \">\", 0.5),\n",
    "        (\"log10_floor_sfr_10\", \">\", 1),\n",
    "        (\"redshift\", \"<\", 8),\n",
    "        (\"redshift\", \">\", 6),\n",
    "    ],\n",
    "    [\n",
    "        (\"log_mass\", \"<\", 8.5),\n",
    "        (\"log10_Av\", \"<\", 0.5),\n",
    "        (\"log10_floor_sfr_10\", \">\", -1),\n",
    "        (\"redshift\", \"<\", 3),\n",
    "        (\"redshift\", \">\", 1),\n",
    "    ],\n",
    "    [\n",
    "        (\"log_mass\", \"<\", 8.5),\n",
    "        (\"log10_Av\", \"<\", 0),\n",
    "        (\"log10_floor_sfr_10\", \">\", -1),\n",
    "        (\"redshift\", \"<\", 9.5),\n",
    "        (\"redshift\", \">\", 8.5),\n",
    "    ],\n",
    "]\n",
    "\n",
    "for i in range(len(names)):\n",
    "    if i == 0:\n",
    "        ax[i].text(\n",
    "            0.98, 0.95, names[i], ha=\"right\", va=\"top\", transform=ax[i].transAxes, fontsize=10\n",
    "        )\n",
    "    else:\n",
    "        ax[i].text(\n",
    "            0.98, 0.02, names[i], ha=\"right\", va=\"bottom\", transform=ax[i].transAxes, fontsize=10\n",
    "        )\n",
    "    if i % 2 == 0:\n",
    "        ax[i].set_ylabel(r\"$\\rm F _\\lambda ~ [arb. units]$\", fontsize=10)\n",
    "\n",
    "    try:\n",
    "        constraint = constraints[i]\n",
    "        indexes = search_parameter_array(arr, constraint_names, constraint)\n",
    "        print(f\"Found {len(indexes)} matches for {names[i]}\")\n",
    "\n",
    "        if len(indexes) == 0:\n",
    "            continue\n",
    "\n",
    "        if generate_new[i]:\n",
    "            rand_index = np.random.choice(indexes, size=1)[0]\n",
    "        else:\n",
    "            rand_index = indices[i]\n",
    "\n",
    "        indices[i] = rand_index\n",
    "        fitter.recover_SED(\n",
    "            plot=True,\n",
    "            ax=ax[i],\n",
    "            X_test=fitter._X_test[rand_index, :],\n",
    "            true_parameters=fitter._y_test[rand_index, :],\n",
    "            num_samples=250,\n",
    "            phot_unit=\"erg/s/cm^2/Angstrom\",\n",
    "            sample_color=flexoki_colors[i],\n",
    "        )\n",
    "    except IndexError:\n",
    "        continue\n",
    "    # remove legend\n",
    "    ax[i].legend_.remove()\n",
    "    ax[i].set_yscale(\"log\")\n",
    "    ax[i].set_ylim(ax[i].get_ylim()[1] * 1e-3, 1.5 * ax[i].get_ylim()[1])\n",
    "    # Deal with limits being linked between rows - only adjust if needed\n",
    "    # if i >= 2:\n",
    "    #    actual_max = max(ax[i].get_ylim()[1], ax[i-2].get_ylim()[1])\n",
    "    #    ax[i].set_ylim(actual_max*1e-4, actual_max)\n",
    "    # Disable ytick labels for all\n",
    "    ax[i].set_yticklabels([])\n",
    "\n",
    "ax[6].set_xlabel(r\"Obs. Wavelength [$\\mu m$]\", fontsize=10)\n",
    "ax[7].set_xlabel(r\"Obs. Wavelength [$\\mu m$]\", fontsize=10)\n",
    "\n",
    "# Change xticklabels on bottom to be in microns\n",
    "xticks = ax[6].get_xticks()\n",
    "ax[6].set_xticklabels([f\"{x / 1e4:.1f}\" for x in xticks])\n",
    "ax[7].set_xticklabels([f\"{x / 1e4:.1f}\" for x in xticks])\n",
    "\n",
    "ax[0].legend(loc=\"lower right\", fontsize=8)\n",
    "\n",
    "fig.savefig(f\"plots/{model_name}_{extra}_example_seds.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e2931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax[2].get_ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax[-1].set_ylim(3e-23, ax[-1].get_ylim()[1])\n",
    "ax[1].set_ylim(7e-20, ax[1].get_ylim()[1])\n",
    "ax[4].set_ylim(1e-21, ax[4].get_ylim()[1])\n",
    "ax[2].set_ylim(3e-21, ax[2].get_ylim()[1])\n",
    "ax[3].set_ylim(3e-21, ax[3].get_ylim()[1])\n",
    "fig.savefig(f\"plots/{model_name}_{extra}_example_seds.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34da8ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "\n",
    "wav = 0.9 * u.micron\n",
    "flux = 28.542376 * u.ABmag\n",
    "\n",
    "flux.to(u.erg / u.s / u.cm**2 / u.AA, equivalencies=u.spectral_density(wav))\n",
    "flux.to(u.ABmag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3043b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unyt import unyt_quantity\n",
    "\n",
    "a = unyt_quantity(1.0, \"nJy\").to_astropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad78a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = [(\"log_mass\", \">\", 10), (\"log10_mass_weighted_age\", \">\", 3), (\"log10_Av\", \">\", 0.5)]\n",
    "indexes = search_parameter_array(fitter._y_test, list(fitter.fitted_parameter_names), constraints)\n",
    "\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30bbeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter._X_test[3435]\n",
    "\n",
    "indexes = 99, 3435, 16, 9985, 7372"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d555d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter._X_test[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aae5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in indices:\n",
    "    sample = fitter._X_test[index]\n",
    "    true_params = fitter._y_test[index]\n",
    "    predicted_params = fitter.sample_posterior(sample, num_samples=1000)\n",
    "\n",
    "    fitter._prior = fitter.create_priors()\n",
    "\n",
    "    result = fitter.fit_observation_using_sampler(\n",
    "        observation=sample,\n",
    "        sampler=\"dynesty\",\n",
    "        sampler_kwargs={\"bound\": \"multi\", \"sample\": \"rwalk\", \"run_kwargs\": {\"n_effective\": 2000}},\n",
    "        remove_params=[\"log10_mass_weighted_age\", \"log10_floor_sfr_10\"],\n",
    "        plot_name=f\"{model_name}_{extra}_example_{index}\",\n",
    "        min_flux_pc_error=0.05,\n",
    "    )\n",
    "    samples = result[\"samples\"]\n",
    "    log_l = result[\"logl\"]\n",
    "    log_w = result[\"logwt\"]\n",
    "\n",
    "    data = {\n",
    "        \"samples\": samples,\n",
    "        \"log_weights\": log_w,\n",
    "        \"log_likelihood\": log_l,\n",
    "    }\n",
    "\n",
    "    np.savez(f\"plots/{model_name}_{extra}_example_{index}_dynesty.npz\", **data)\n",
    "\n",
    "# Plot corner of both on same (see through, only contours) and true value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f7abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "?DynamicNestedSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2caf9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "comparison_params = [\n",
    "    \"log_mass\",\n",
    "    \"log10metallicity\",\n",
    "    \"log10_Av\",\n",
    "    \"log_sfr\",\n",
    "    \"sfh_quantile_25\",\n",
    "    \"sfh_quantile_50\",\n",
    "    \"sfh_quantile_75\",\n",
    "]\n",
    "\n",
    "display_names = [\n",
    "    r\"$\\log M_*$\",\n",
    "    r\"$\\log Z/Z_\\odot$\",\n",
    "    \"$A_V$\",\n",
    "    r\"$\\log$ SFR\",\n",
    "    \"$t_{25}$\",\n",
    "    \"$t_{50}$\",\n",
    "    \"$t_{75}$\",\n",
    "]\n",
    "\n",
    "mask_idx = [True if p in comparison_params else False for p in fitter.fitted_parameter_names]\n",
    "mask_idx = np.array(mask_idx, dtype=bool)\n",
    "\n",
    "figure = corner.corner(\n",
    "    points[:, :-2],\n",
    "    weights=np.exp(log_w - log_w.max()),\n",
    "    labels=display_names,\n",
    "    color=\"#03A89E\",\n",
    "    plot_datapoints=False,\n",
    "    fill_contours=False,\n",
    "    contour_kwargs={\"linewidths\": 1.5, \"linestyles\": \"solid\"},\n",
    "    contourf_kwargs={\n",
    "        \"alpha\": 0.3  # Very light fill for contours\n",
    "    },\n",
    "    hist_kwargs={\"alpha\": 0.7, \"histtype\": \"stepfilled\", \"edgecolor\": \"black\", \"linewidth\": 1},\n",
    "    levels=(0.68, 0.95),\n",
    "    plot_density=False,\n",
    "    smooth=1.0,\n",
    "    label_kwargs={\"fontsize\": 22},\n",
    "    title_kwargs={\"fontsize\": 22},\n",
    "    quantiles=[0.16, 0.5, 0.84],\n",
    "    show_titles=False,\n",
    "    # Increase tick label size\n",
    "    tick_label_kwargs={\"fontsize\": 16},\n",
    ")\n",
    "\n",
    "corner.corner(\n",
    "    predicted_params[:, mask_idx],\n",
    "    labels=display_names,\n",
    "    color=\"#CD3700\",\n",
    "    plot_datapoints=False,\n",
    "    fill_contours=False,\n",
    "    contour_kwargs={\"linewidths\": 1.5, \"linestyles\": \"solid\"},\n",
    "    contourf_kwargs={\n",
    "        \"alpha\": 0.3  # Very light fill for contours\n",
    "    },\n",
    "    hist_kwargs={\"alpha\": 0.7, \"histtype\": \"stepfilled\", \"edgecolor\": \"black\", \"linewidth\": 1},\n",
    "    plot_density=False,\n",
    "    smooth=1.0,\n",
    "    fig=figure,\n",
    "    quantiles=[0.16, 0.5, 0.84],\n",
    "    show_titles=False,\n",
    "    tick_label_kwargs={\"fontsize\": 16},\n",
    ")\n",
    "\n",
    "# Add true value lines\n",
    "ndim = len(comparison_params)\n",
    "axes = np.array(figure.axes).reshape((ndim, ndim))\n",
    "for i in range(ndim):\n",
    "    for j in range(ndim):\n",
    "        ax = axes[i, j]\n",
    "        # Increase axis line weight\n",
    "        for axis in [\"top\", \"bottom\", \"left\", \"right\"]:\n",
    "            ax.spines[axis].set_linewidth(1.5)\n",
    "        if i == j:\n",
    "            ax.axvline(true_params[i], color=\"k\", linestyle=\"dotted\")\n",
    "            # Add our own titles with quantiles for both\n",
    "            samples_param = predicted_params[:, mask_idx][:, i]\n",
    "            p16, p50, p84 = np.percentile(samples_param, [16, 50, 84])\n",
    "            nested = points[:, :-2][:, i]\n",
    "            # need to get weighted percentiles for nested sampling\n",
    "            sorted_indices = np.argsort(nested)\n",
    "            nested_sorted = nested[sorted_indices]\n",
    "            weights_sorted = np.exp(log_w - log_w.max())[sorted_indices]\n",
    "            cumulative_weights = np.cumsum(weights_sorted)\n",
    "            cumulative_weights /= cumulative_weights[-1]  # Normalize to [0, 1]\n",
    "            p16_ns = np.interp(0.16, cumulative_weights, nested_sorted)\n",
    "            p50_ns = np.interp(0.50, cumulative_weights, nested_sorted)\n",
    "            p84_ns = np.interp(0.84, cumulative_weights, nested_sorted)\n",
    "            title = (\n",
    "                rf\"{comparison_params[i]}\" + \"\\n\"\n",
    "                rf\"SBI: ${p50:.2f}_{{-{p50 - p16:.2f}}}^{{+{p84 - p50:.2f}}}$\" + \"\\n\"\n",
    "                rf\"NS: ${p50_ns:.2f}_{{-{p50_ns - p16_ns:.2f}}}^{{+{p84_ns - p50_ns:.2f}}}$\"\n",
    "            )\n",
    "            # ax.set_title(title, fontsize=14)\n",
    "            ax.set_title(\"\")\n",
    "            # Approximate the title with textbox so we can set the color of SBI vs NS\n",
    "            sbi = rf\"SBI: ${p50:.2f}_{{-{p50 - p16:.2f}}}^{{+{p84 - p50:.2f}}}$\"\n",
    "            ns = rf\"NS: ${p50_ns:.2f}_{{-{p50_ns - p16_ns:.2f}}}^{{+{p84_ns - p50_ns:.2f}}}$\"\n",
    "\n",
    "            ax.text(\n",
    "                0.5,\n",
    "                1.3,\n",
    "                sbi,\n",
    "                color=\"#CD3700\",\n",
    "                fontsize=22,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                transform=ax.transAxes,\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "            ax.text(\n",
    "                0.5,\n",
    "                1.1,\n",
    "                ns,\n",
    "                color=\"#03A89E\",\n",
    "                fontsize=22,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                transform=ax.transAxes,\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "        elif i > j:\n",
    "            ax.axvline(true_params[j], color=\"k\", linestyle=\"dotted\")\n",
    "            ax.axhline(true_params[i], color=\"k\", linestyle=\"dotted\")\n",
    "            ax.plot(true_params[j], true_params[i], \"ks\")\n",
    "\n",
    "        # Increase font size of tick labels if i or j is 0 or ndim-1\n",
    "        if i == ndim - 1 or j == 0:\n",
    "            ax.tick_params(axis=\"x\", which=\"major\", labelsize=16)\n",
    "        if j == 0 or i == ndim - 1:\n",
    "            ax.tick_params(axis=\"y\", which=\"major\", labelsize=16)\n",
    "\n",
    "# figure.suptitle(\"Comparison of Posterior Samples: MDN vs Nested Sampling\", fontsize=16)\n",
    "\n",
    "# Add upper right floating axis for SED plot\n",
    "\n",
    "new_ax = figure.add_axes([0.50, 0.65, 0.45, 0.35])\n",
    "\n",
    "sfh_ax = figure.add_axes([0.75, 0.42, 0.22, 0.18])\n",
    "\n",
    "# Get SEDs given these posterior samples.\n",
    "results = fitter.recover_SED(\n",
    "    sample,\n",
    "    samples=predicted_params,\n",
    "    plot=True,\n",
    "    true_parameters=true_params,\n",
    "    sample_color=\"#CD3700\",\n",
    "    fig=figure,\n",
    "    ax=new_ax,\n",
    "    plot_histograms=False,\n",
    "    plot_sfh=True,\n",
    "    ax_sfh=sfh_ax,\n",
    "    num_samples=50,\n",
    ")\n",
    "\n",
    "# Do the same for nested sampling samples\n",
    "# add two dimensions to fake points to match expected shape\n",
    "\n",
    "points_dict = {name: points[:, i] for i, name in enumerate(comparison_params)}\n",
    "# Not designed to deal with weights, so sample with replacement according to weights\n",
    "weights = np.exp(log_w - log_w.max())\n",
    "weights /= weights.sum()\n",
    "indices = np.random.choice(len(weights), size=len(weights), replace=True, p=weights)\n",
    "points_dict = {name: points_dict[name][indices] for name in points_dict}\n",
    "results_ns = fitter.recover_SED(\n",
    "    sample,\n",
    "    samples=points_dict,\n",
    "    plot=True,\n",
    "    sample_color=\"#03A89E\",\n",
    "    fig=figure,\n",
    "    ax=new_ax,\n",
    "    plot_histograms=False,\n",
    "    plot_sfh=True,\n",
    "    ax_sfh=sfh_ax,\n",
    "    num_samples=50,\n",
    ")\n",
    "\n",
    "new_ax.set_ylim(25, 22)\n",
    "# move legend to lower right\n",
    "\n",
    "# Increase font size of all text in new_ax and sfh_ax\n",
    "for item in (\n",
    "    new_ax.title,\n",
    "    new_ax.xaxis.label,\n",
    "    new_ax.yaxis.label,\n",
    "    new_ax.get_xticklabels(),\n",
    "    new_ax.get_yticklabels(),\n",
    "    new_ax.get_legend().get_texts(),\n",
    "    sfh_ax.title,\n",
    "    sfh_ax.xaxis.label,\n",
    "    sfh_ax.yaxis.label,\n",
    "    sfh_ax.get_xticklabels(),\n",
    "    sfh_ax.get_yticklabels(),\n",
    "):\n",
    "    if hasattr(item, \"__iter__\"):\n",
    "        for subitem in item:\n",
    "            subitem.set_fontsize(16)\n",
    "    else:\n",
    "        item.set_fontsize(16)\n",
    "\n",
    "# Increase marker size for all markers in new_ax\n",
    "for line in new_ax.get_lines():\n",
    "    line.set_markersize(8)\n",
    "\n",
    "# Change line labels in new_ax to \"SBI Posterior\" and \"Nested Sampling\"\n",
    "lines = new_ax.get_lines()\n",
    "for line in lines:\n",
    "    if (\n",
    "        line.get_color() == \"#CD3700\"\n",
    "        and line.get_label() != \"_nolegend_\"\n",
    "        and \"_child\" not in line.get_label()\n",
    "    ):\n",
    "        line.set_label(\"Predicted SBI SED\")\n",
    "    elif (\n",
    "        line.get_color() == \"#03A89E\"\n",
    "        and line.get_label() != \"_nolegend_\"\n",
    "        and \"_child\" not in line.get_label()\n",
    "    ):\n",
    "        print(line.get_label())\n",
    "        line.set_label(\"Predicted NS SED\")\n",
    "\n",
    "\n",
    "# Find labelled markers and rename them\n",
    "for marker in new_ax.collections + new_ax.lines:\n",
    "    if not hasattr(marker, \"get_label\"):\n",
    "        continue\n",
    "    if marker.get_label() == \"Posterior Phot.\" and marker.get_color() == \"#03A89E\":\n",
    "        marker.set_label(\"Predicted NS Phot.\")\n",
    "    elif marker.get_label() == \"Posterior Phot.\" and marker.get_color() == \"#CD3700\":\n",
    "        marker.set_label(\"Predicted SBI Phot.\")\n",
    "\n",
    "new_ax.legend(loc=\"lower right\", fontsize=14)\n",
    "\n",
    "figure.savefig(\n",
    "    f\"plots/posterior_comparison_{index}.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a80d9",
   "metadata": {},
   "source": [
    "### 5 SED recoveries and true SEDs (different redshifts, masses, dust etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da5ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = []\n",
    "for test_sample in test_samples:\n",
    "    fitter.recover_SED(X_test=test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06a2da",
   "metadata": {},
   "source": [
    "### SFH Recovery Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5f11a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(fitter.simulator.unused_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d65661",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.randint(0, len(fitter._X_test), size=100)\n",
    "\n",
    "for idx in random_idx:\n",
    "    sample = fitter._X_test[idx]\n",
    "    true_params = fitter._y_test[idx]\n",
    "    predicted_params = fitter.recover_SED(\n",
    "        sample, num_samples=50, plot=True, true_parameters=true_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21142d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort indexes for high log10_Av and low redshift\n",
    "Av_idx = list(fitter.fitted_parameter_names).index(\"log10_Av\")\n",
    "z_idx = list(fitter.feature_names).index(\"redshift\")\n",
    "mask = (fitter._y_test[:, Av_idx] > 0.5) & (fitter._X_test[:, z_idx] < 0.5)\n",
    "\n",
    "for i in range(len(fitter._X_test[mask])):\n",
    "    s = fitter._X_test[mask][i]\n",
    "    true_params = fitter._y_test[mask][i]\n",
    "    fitter.recover_SED(s, num_samples=50, plot=True, true_parameters=true_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810daf0b",
   "metadata": {},
   "source": [
    "# Benchmark Inference Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test speed of normal model.\n",
    "\n",
    "\n",
    "fitter = SBI_Fitter.load_saved_model(\n",
    "    f\"/home/tharvey/work/synference/models/{model_name}/{model_name}_{extra}_posterior.pkl\",\n",
    "    grid_path=\"/home/tharvey/work/synference/grids/grid_BPASS_Chab_DenseBasis_SFH_0.01_z_14_logN_6.0_Calzetti_v4_multinode.hdf5\",\n",
    "    device=\"cuda\",\n",
    ")\n",
    "X_test = fitter._X_test[:1000]\n",
    "\n",
    "out = fitter.sample_posterior(X_test, num_samples=1000, log_times=True)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
