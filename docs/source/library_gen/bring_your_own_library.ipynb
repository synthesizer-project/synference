{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49951ff1",
   "metadata": {},
   "source": [
    "# Bring your Own Grid\n",
    "\n",
    "Whilst Synference by default utilizes Synthesizer to create model libraries, it is also possible to bring your own pre-computed grid of models. This can be useful if you have a custom set of models that you wish to use for inference.\n",
    "\n",
    "We provide a `LibraryCreator` class that allows you to create a grid from your own data and save it in the required HDF5 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a7297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from astropy.table import Table\n",
    "\n",
    "from synference import LibraryCreator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54543f7b",
   "metadata": {},
   "source": [
    "For this example we will build a grid from the SPHINX public data release, which can be found [here](https://github.com/HarleyKatz/SPHINX-20-data), and contains mock observations of 1380 galaxies from 10 different orientations at z=4.6 to 10 from the radiation-hydrodynamic cosmological simulation SPHINX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d9e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"https://raw.githubusercontent.com/HarleyKatz/SPHINX-20-data/refs/heads/main/data/all_basic_data.csv\"\n",
    "\n",
    "\n",
    "if not os.path.exists(\"all_basic_data.csv\"):\n",
    "    os.system(f\"wget {file}\")\n",
    "\n",
    "sphinx = Table.read(\"all_basic_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da4ad1b",
   "metadata": {},
   "source": [
    "For the purposes of simplicity we will only use one direction (0) from the data release, but you could of course use all 10 directions if desired. \n",
    "\n",
    "We will create simple arrays containing the parameter and observation names we wish to use from the data release. In this case we will store redshift, stellar mass, stellar metallicity, mass-weighted age, SFR on 3 different timescales, and the dust E(B-V). For the observations we will use JWST NIRCam photometry.\n",
    "\n",
    "We will also save some units information for the parameters, but this is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eff1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 0  # Choose direction 0 for this example\n",
    "\n",
    "parameter_columns = [\n",
    "    \"redshift\",\n",
    "    \"stellar_mass\",\n",
    "    \"stellar_metallicity\",\n",
    "    \"mean_stellar_age_mass\",\n",
    "    \"sfr_3\",\n",
    "    \"sfr_10\",\n",
    "    \"sfr_100\",\n",
    "    f\"ebmv_dir_{dir}\",\n",
    "]\n",
    "parameter_units = [\n",
    "    \"dimensionless\",\n",
    "    \"log10(Msun)\",\n",
    "    \"dimensionless\",\n",
    "    \"Myr\",\n",
    "    \"Msun/yr\",\n",
    "    \"Msun/yr\",\n",
    "    \"Msun/yr\",\n",
    "    \"dimensionless\",\n",
    "]\n",
    "\n",
    "feature_names = [\n",
    "    f\"F070W_dir_{dir}\",\n",
    "    f\"F090W_dir_{dir}\",\n",
    "    f\"F115W_dir_{dir}\",\n",
    "    f\"F140M_dir_{dir}\",\n",
    "    f\"F150W_dir_{dir}\",\n",
    "    f\"F162M_dir_{dir}\",\n",
    "    f\"F182M_dir_{dir}\",\n",
    "    f\"F200W_dir_{dir}\",\n",
    "    f\"F210M_dir_{dir}\",\n",
    "    f\"F250M_dir_{dir}\",\n",
    "    f\"F277W_dir_{dir}\",\n",
    "    f\"F300M_dir_{dir}\",\n",
    "    f\"F335M_dir_{dir}\",\n",
    "    f\"F356W_dir_{dir}\",\n",
    "    f\"F360M_dir_{dir}\",\n",
    "    f\"F410M_dir_{dir}\",\n",
    "    f\"F430M_dir_{dir}\",\n",
    "    f\"F444W_dir_{dir}\",\n",
    "    f\"F460M_dir_{dir}\",\n",
    "    f\"F480M_dir_{dir}\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c55a3d",
   "metadata": {},
   "source": [
    "We now want to make a numpy array for the parameters and observations from the table. we want to make sure that the shape of these arrays matches the expected input for the `GridCreator` class, which is (n_models, n_parameters) and (n_models, n_observations) respectively. Therefore we need to transpose the arrays after converting them from the pandas dataframe.\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = sphinx[parameter_columns].to_pandas().to_numpy().T\n",
    "features = sphinx[feature_names].to_pandas().to_numpy().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2a242",
   "metadata": {},
   "source": [
    "If we wish we can also store some 'supplementary' parameters, which will not be inferred by default when we use the grid for inference, but can be accessed later if desired. This is useful for derived parameters or other quantities of interest. Here we will store the escape fraction, UV slope, and absolute UV magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af39bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "supplementary_columns = [f\"fesc_dir_{dir}\", f\"beta_dir_{dir}_sn\", f\"MAB_1500_dir_{dir}\"]\n",
    "supplementary_units = [\"dimensionless\", \"dimensionless\", \"AB\"]\n",
    "\n",
    "supplementary_data = sphinx[supplementary_columns].to_pandas().to_numpy().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b2efbb",
   "metadata": {},
   "source": [
    "We will set nicer names for our features, and also define a feature transform function to convert the magnitudes to fluxes. The SPHINX data release provides magnitudes, but we will set input to be in nanoJanskys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cc71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "override_feature_names = [f\"JWST/NIRCam.{filter.split('_dir_')[0]}\" for filter in feature_names]\n",
    "\n",
    "\n",
    "def _feature_transform(features: np.ndarray) -> np.ndarray:\n",
    "    # Convert AB mag to nJy\n",
    "    flux = 10 ** (-0.4 * (features - 31.4))\n",
    "    flux[features == 0] = 0  # Avoid division by zero\n",
    "    flux[~np.isfinite(flux)] = 0  # Handle non-finite values\n",
    "    return flux\n",
    "\n",
    "\n",
    "features = _feature_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0330f1",
   "metadata": {},
   "source": [
    "Now we can create the grid using the `LibraryCreator` class. We will specify an output folder and set `overwrite=True` to overwrite any existing files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc13a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LibraryCreator(\n",
    "    model_name=\"SPHINX_JWST\",\n",
    "    parameter_grid=parameters,\n",
    "    observation_grid=features,\n",
    "    observation_names=override_feature_names,\n",
    "    observation_units=\"nJy\",\n",
    "    parameter_names=parameter_columns,\n",
    "    parameter_units=parameter_units,\n",
    "    supplementary_parameters=supplementary_data,\n",
    "    supplementary_parameter_names=supplementary_columns,\n",
    "    supplementary_parameter_units=supplementary_units,\n",
    "    out_folder=\".\",\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd16408",
   "metadata": {},
   "source": [
    "Now let's quickly check that the grid was saved correctly by loading it back in using the SBI_Fitter class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5afac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synference import SBI_Fitter\n",
    "\n",
    "fitter = SBI_Fitter.init_from_hdf5(model_name=\"SPHINX_JWST\", hdf5_path=\"./library_SPHINX_JWST.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eddb84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fitter.raw_observation_names)\n",
    "print(fitter.parameter_names)\n",
    "print(fitter.parameter_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7ec394",
   "metadata": {},
   "source": [
    "As we can see the grid has been loaded correctly with the expected parameter and observation names and units, and we could now proceed to use this grid for inference as normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cfa9ce",
   "metadata": {},
   "source": [
    "This class provides a flexible way to bring your own model grids into Synference for inference."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
