{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex SBI Model Training\n",
    "\n",
    "In this example we will demonstrate how to customise the training of your SBI model. In the [Basic SBI Training](basic_sbi_model.ipynb) tutorial we trained a default model, but here we will explore some of the cutomisation options available to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synference import SBI_Fitter\n",
    "\n",
    "fitter = SBI_Fitter.init_from_hdf5(model_name=\"test\",\n",
    "                                   hdf5_path=\"../example_libraries/test_model_library.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the default feature array settings for this example, but you can refer to the [Feature Arrays](feature_array.ipynb) tutorial to learn how to create your own custom feature arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-04 14:16:41,306 | synference | INFO     | ---------------------------------------------\n",
      "2025-11-04 14:16:41,306 | synference | INFO     | Features: 8 features over 10000 samples\n",
      "2025-11-04 14:16:41,307 | synference | INFO     | ---------------------------------------------\n",
      "2025-11-04 14:16:41,308 | synference | INFO     | Feature: Min - Max\n",
      "2025-11-04 14:16:41,308 | synference | INFO     | ---------------------------------------------\n",
      "2025-11-04 14:16:41,309 | synference | INFO     | JWST/NIRCam.F070W: 3.642582 - 43.046 AB\n",
      "2025-11-04 14:16:41,309 | synference | INFO     | JWST/NIRCam.F090W: 3.246181 - 40.840 AB\n",
      "2025-11-04 14:16:41,310 | synference | INFO     | JWST/NIRCam.F115W: 2.951415 - 38.513 AB\n",
      "2025-11-04 14:16:41,310 | synference | INFO     | JWST/NIRCam.F150W: 2.685013 - 37.131 AB\n",
      "2025-11-04 14:16:41,311 | synference | INFO     | JWST/NIRCam.F200W: 2.763217 - 35.357 AB\n",
      "2025-11-04 14:16:41,311 | synference | INFO     | JWST/NIRCam.F277W: 3.175404 - 33.451 AB\n",
      "2025-11-04 14:16:41,312 | synference | INFO     | JWST/NIRCam.F356W: 3.535404 - 32.678 AB\n",
      "2025-11-04 14:16:41,313 | synference | INFO     | JWST/NIRCam.F444W: 3.874129 - 32.164 AB\n",
      "2025-11-04 14:16:41,313 | synference | INFO     | ---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "fitter.create_feature_array();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the options available in the `run_single_sbi` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mfitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_sbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrain_test_fraction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_seed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbackend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sbi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'NPE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrain_indices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtest_indices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_nets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodel_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mdn'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mhidden_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_components\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_transforms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtraining_batch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_fraction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstop_after_epochs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mclip_max_norm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0madditional_model_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msave_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprior_method\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ili'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mout_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/user/Documents/PhD/synference/models/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mplot\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mname_append\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfeature_scalar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'sklearn.preprocessing._data.StandardScaler'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtarget_scalar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'sklearn.preprocessing._data.StandardScaler'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mset_self\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlearning_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'offline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msimulator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_simulations\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_online_rounds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minitial_training_from_library\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moverride_prior_ranges\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0monline_training_xobs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mload_existing_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muse_existing_indices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mevaluate_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msave_method\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'joblib'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_posterior_draws_per_sample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0membedding_net\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIdentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcustom_config_yaml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msql_db_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Run a single SBI training instance.\n",
      "\n",
      "Args:\n",
      "    train_test_fraction (float, optional): Fraction of the dataset to be\n",
      "        used for training. Defaults to 0.8.\n",
      "    random_seed (int, optional): Random seed for reproducibility.\n",
      "        Defaults to None.\n",
      "    backend (str, optional): Backend to use for training ('sbi', 'lampe',\n",
      "        or 'pydelfi'). Pydelfi cannot be installed in the same\n",
      "        environment. Defaults to \"sbi\".\n",
      "    engine (Union[str, List[str]], optional): Engine to use ('NPE',\n",
      "        'NLE', 'NRE' or sequential variants). Defaults to \"NPE\".\n",
      "    train_indices (np.ndarray, optional): Indices of the training set.\n",
      "        Defaults to None.\n",
      "    test_indices (np.ndarray, optional): Indices of the test set. If None,\n",
      "        no test set is used. Defaults to None.\n",
      "    n_nets (int, optional): Number of networks to use in the ensemble.\n",
      "        Defaults to 1.\n",
      "    model_type (Union[str, List[str]], optional): Type of model (e.g.,\n",
      "        'mdn', 'maf', 'nsf'). If a list, an ensemble is used.\n",
      "        Defaults to \"mdn\".\n",
      "    hidden_features (Union[int, List[int]], optional): Number of hidden\n",
      "        features in the neural network. Defaults to 50.\n",
      "    num_components (Union[int, List[int]], optional): Number of components\n",
      "        in the mixture density network. Defaults to 4.\n",
      "    num_transforms (Union[int, List[int]], optional): Number of transforms\n",
      "        in the masked autoregressive flow. Defaults to 4.\n",
      "    training_batch_size (int, optional): Batch size for training.\n",
      "        Defaults to 64.\n",
      "    learning_rate (float, optional): Learning rate for the optimizer.\n",
      "        Defaults to 1e-4.\n",
      "    validation_fraction (float, optional): Fraction of training set for\n",
      "        validation to prevent over-fitting. Training stops if\n",
      "        validation loss doesn't improve for `stop_after_epochs`.\n",
      "        Defaults to 0.2.\n",
      "    stop_after_epochs (int, optional): Epochs without improvement\n",
      "        before stopping. Defaults to 15.\n",
      "    clip_max_norm (float, optional): Maximum norm for gradient clipping.\n",
      "        Defaults to 5.0.\n",
      "    additional_model_args (dict, optional): Additional arguments for\n",
      "        the model (e.g., num_layers, use_batch_norm). Defaults to {}.\n",
      "    save_model (bool, optional): Whether to save the trained model.\n",
      "        Defaults to True.\n",
      "    verbose (bool, optional): Whether to print verbose output.\n",
      "        Defaults to True.\n",
      "    prior_method (str, optional): Method to create the prior\n",
      "        ('manual' or 'ili'). Defaults to \"ili\".\n",
      "    feature_scalar (Callable, optional): Scaler class for the features.\n",
      "        Defaults to StandardScaler.\n",
      "    target_scalar (Callable, optional): Scaler class for the targets.\n",
      "        Defaults to StandardScaler.\n",
      "    out_dir (str, optional): Directory to save the model. Defaults to\n",
      "        f\"{code_path}/models/\".\n",
      "    plot (bool, optional): Whether to plot the diagnostics.\n",
      "        Defaults to True.\n",
      "    name_append (str, optional): String to append to the model name.\n",
      "        Defaults to \"timestamp\".\n",
      "    set_self (bool, optional): Whether to set instance attributes with\n",
      "        the trained model. Defaults to True.\n",
      "    learning_type (str, optional): Type of learning ('offline' or\n",
      "        'online'). If 'online', a simulator must be provided.\n",
      "        Defaults to \"offline\".\n",
      "    simulator (Callable, optional): Function to simulate data for\n",
      "        'online' learning. Defaults to None.\n",
      "    num_simulations (int, optional): Number of simulations to run in\n",
      "        each call during 'online' learning. Defaults to 1000.\n",
      "    num_online_rounds (int, optional): Number of rounds for 'online'\n",
      "        learning. Defaults to 5.\n",
      "    initial_training_from_library (bool, optional): Whether to use the\n",
      "        initial training from the grid in 'online' learning.\n",
      "        WARNING: This is broken. Defaults to False.\n",
      "    override_prior_ranges (dict, optional): Dictionary of prior ranges\n",
      "        to override the defaults. Defaults to {}.\n",
      "    online_training_xobs (np.ndarray, optional): A single input\n",
      "        observation to condition on for 'online' training.\n",
      "        Defaults to None.\n",
      "    load_existing_model (bool, optional): Whether to load an existing\n",
      "        model if it exists. Defaults to True.\n",
      "    use_existing_indices (bool, optional): Whether to use existing\n",
      "        train/test indices if they exist. Defaults to True.\n",
      "    evaluate_model (bool, optional): Whether to evaluate the model\n",
      "        after training (computes log prob, PIT). Defaults to True.\n",
      "    save_method (str, optional): Method to save the model ('torch',\n",
      "        'pickle', 'joblib', or 'h5py'). Defaults to \"joblib\".\n",
      "    num_posterior_draws_per_sample (int, optional): Number of posterior\n",
      "        draws for metrics and plots. Defaults to 1000.\n",
      "    embedding_net (Optional[torch.nn.Module], optional): Optional\n",
      "        embedding network for the simulator.\n",
      "        Defaults to torch.nn.Identity().\n",
      "    custom_config_yaml (Optional[str], optional): Path to a custom YAML\n",
      "        config file to override settings. Defaults to None.\n",
      "    sql_db_path (Optional[str], optional): Path to an SQL database for\n",
      "        logging or results. Defaults to None.\n",
      "\n",
      "Returns:\n",
      "    tuple: A tuple containing the trained posterior distribution\n",
      "    and a dictionary of training statistics.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Documents/PhD/synference/src/synference/sbi_runner.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "?fitter.run_single_sbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will break down the options into a few categories:\n",
    "1. **Model Architecture Options**: These options allow you to customize the architecture of the neural network used in the SBI model.\n",
    "- _backend_: This lets you choose between the SBI backends supported by LtU-ILI. The default is `sbi`, but you can also choose `lampe` if you prefer that framework.\n",
    "- _engine_: This option allows you to select the inference engine used for training. The default is `NPE`, but you can also choose `NLE` or `NRE` depending on your needs. Sequentual methods are also supported (SNPE, SNLE, SNRE). \n",
    "- _model_type_: This option lets you specify the type of model to use. The default is `mdn` (Mixture Density Network), but you can also choose `maf` (Masked Autoregressive Flow) or `nsf` (Neural Spline Flow) for more complex distributions. See the documentation for sbi or lampe for the full list of supported model types.\n",
    "- _hidden_features_: This option allows you to set the number of hidden features (neurons) in each layer of the neural network. The default is 50, but you can increase this for more complex models.\n",
    "- _num_components_: This option lets you specify the number of mixture components in the Mixture Density Network. The default is 4, but you can increase this for more complex distributions. \n",
    "- _num_transforms_: This option allows you to set the number of transforms in normalizing flow models (like MAF or NSF). The default is 4, but you can increase this for more complex distributions.\n",
    "- _embedding_net_: This option lets you provide a custom embedding network for processing the observations. By default no embedding network is used, but you can create your own using PyTorch and pass it here.\n",
    "- _n_nets_: This option allows you to specify the number of networks to use in an ensemble. The default is 1, but you can increase this to train an ensemble of models which may improve performance. Model parameters such as _num_components_ and _hidden_features_ can be specified as lists to vary them across the ensemble members.\n",
    "\n",
    "2. **Training Options**: These options allow you to customize the training process of the SBI model.\n",
    "- _train_test_fraction_: This option lets you specify the fraction of data to use for training versus testing. The default is 0.8 (80% training, 20% testing), but you can adjust this based on your dataset size.\n",
    "- _training_batch_size_: This option allows you to set the batch size for training. The default is 64, but you can vary this based on your hardware capabilities.\n",
    "- _learning_rate_: This option lets you specify the learning rate for the optimizer. The default is 1e-4, but you can adjust this based on your training dynamics.\n",
    "- _override_prior_ranges_: This option allows you to override the prior ranges defined in the model grid. You can provide a dictionary with parameter names as keys and tuples of (min, max) as values to set new prior ranges. The default parameter ranges are the minimum and maximum values defined in the model grid.\n",
    "- _use_existing_indices_: This option lets you choose whether to use existing training and testing indices if they are already saved on the object. The default is `True`, which will reuse the existing indices to ensure consistency across runs.\n",
    "- _validation_fraction_: This option allows you to specify the fraction of training data to use for validation during training. The default is 0.1 (10% of training data), but you can adjust this based on your needs.\n",
    "- _stop_after_epochs_: The number of epochs without improvement on the validation set after which training will stop early. The default is 15, but you can adjust this based on your training dynamics.\n",
    "- _train_indices_/_test_indices_: These options allow you to provide custom indices for training and testing data. By default, random indices are generated based on the _train_test_fraction_.\n",
    "\n",
    "3. **Miscellaneous Options**: These options provide additional customization for the SBI model training.\n",
    "- _load_existing_model_: This option allows you to load an existing trained model instead of training a new one if the named model file is found. The default is `True`.\n",
    "- _evaluate_model_: This option lets you choose whether to evaluate the model after training. The default is `True`, which will compute metrics on the test set.\n",
    "- _save_model_: This option allows you to save the trained model to disk. The default is `True`.\n",
    "- _name_append_: This option lets you append a custom string to the model name for easier identification. The default is a timestamp.\n",
    "- _set_self_: This option will set the trained model and various attributes to the current SBI object. The default is `True`.\n",
    "- _plot_: This option allows you to generate plots of the training results. The default is `True`.\n",
    "- _verbose_: This option lets you control the verbosity of the training output. The default is `True`, which will print detailed information during training.\n",
    "- _save_method_: This option allows you to specify the method for saving the model. The default is `joblib`, but you can choose other methods supported by the backend.\n",
    "- _num_posterior_draws_per_sample_: This option lets you specify the number of posterior draws to make per sample during evaluation. The default is 1000.\n",
    "- _random_seed_: This option allows you to set a random seed for reproducibility. The default is `None`, which means no specific seed is set.\n",
    "- _out_dir_: This option lets you specify the output directory where models and results will be saved. The default is the models/ folder.\n",
    "4. **Online Training Options**: These options allow you to customize the online training process of the SBI model.\n",
    "- _learning_type_: This option lets you specify the type of learning to perform. For online training, set this to `online`. The default is `amortized`.\n",
    "- _num_online_rounds_: This option lets you specify the number of online training rounds to perform. The default is 5, but you can adjust this based on your needs.\n",
    "- _num_simulations_: The number of simulations to run in each online training round. The default is 1000, but you can adjust this based on your computational resources.\n",
    "- _online_training_xobs_: As online training is not amortized, you need to provide the specific observation(s) for which you want to perform inference during online training. This option allows you to specify those observations.\n",
    "- _initial_training_from_library_: This option lets you specify whether to perform an initial training phase using a grid of simulations. The default is `False`.\n",
    "-simulator_: This option allows you to provide a custom simulator function for generating simulations during online training. By default, the simulator is attempted to be retrieved from the model grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example where we use the lampe backend to train an ensemble of 2 models using different architectures (NSF and MAF) with varying hidden features and number of transforms. We also adjust the training parameters such as train-test split, batch size, and learning rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "fitter.run_single_sbi(\n",
    "    backend=\"lampe\",\n",
    "    engine=\"NPE\",\n",
    "    model_type=[\"nsf\", \"maf\"],\n",
    "    hidden_features=[12, 20],\n",
    "    num_transforms=[9, 18],\n",
    "    n_nets=2,\n",
    "    train_test_fraction=0.9,\n",
    "    training_batch_size=32,\n",
    "    learning_rate=5e-2,\n",
    "    override_prior_ranges={\"log_mass\": [7.75, 12.25]},\n",
    ");\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
