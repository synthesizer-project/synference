{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c89da6",
   "metadata": {},
   "source": [
    "# Sampling Validation using MC\n",
    "\n",
    "We can also validate our SBI model by drawing samples from the posterior using MCMC methods. This allows us to assess how well our model captures the underlying distribution of parameters given the observed data.\n",
    "\n",
    "We can do this using the ```SBI_Fitter.fit_observation_using_sampler``` method, which lets us choose from a few nested sampling or MCMC samplers. Here, we'll use the `dynesty` sampler to draw samples from the posterior.\n",
    "\n",
    "First we'll load a trained model and choose a mock observation to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "289654ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model file /Users/user/Library/Application Support/Synthesizer/data/synference does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msynference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SBI_Fitter, load_unc_model_from_hdf5, test_data_dir\n\u001b[1;32m      3\u001b[0m library_path \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_data_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/grid_BPASS_Chab_DenseBasis_SFH_0.01_z_14_logN_2.7_Calzetti_v3_multinode.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m fitter \u001b[38;5;241m=\u001b[39m \u001b[43mSBI_Fitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_saved_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtest_data_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlibrary_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m nm_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_data_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/BPASS_DenseBasis_v4_final_nsf_0_params_empirical_noise_models.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m noise_models \u001b[38;5;241m=\u001b[39m load_unc_model_from_hdf5(nm_path)\n",
      "File \u001b[0;32m~/Documents/PhD/synference/src/synference/sbi_runner.py:442\u001b[0m, in \u001b[0;36mSBI_Fitter.load_saved_model\u001b[0;34m(cls, model_file, library_path, model_name, load_arrays, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m         model_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m library_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m model_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     level: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m logger\u001b[38;5;241m.\u001b[39mgetEffectiveLevel()\n",
      "\u001b[0;31mValueError\u001b[0m: Model file /Users/user/Library/Application Support/Synthesizer/data/synference does not exist."
     ]
    }
   ],
   "source": [
    "from synference import SBI_Fitter, load_unc_model_from_hdf5, test_data_dir\n",
    "\n",
    "library_path = (\n",
    "    f\"{test_data_dir}/grid_BPASS_Chab_DenseBasis_SFH_0.01_z_14_logN_2.7_Calzetti_v3_multinode.hdf5\"  # noqa: E501\n",
    ")\n",
    "\n",
    "fitter = SBI_Fitter.load_saved_model(\n",
    "    model_file=f\"{test_data_dir}\", library_path=library_path, device=\"cpu\"\n",
    ")\n",
    "\n",
    "nm_path = f\"{test_data_dir}/BPASS_DenseBasis_v4_final_nsf_0_params_empirical_noise_models.h5\"\n",
    "noise_models = load_unc_model_from_hdf5(nm_path)\n",
    "\n",
    "fitter.feature_array_flags[\"empirical_noise_models\"] = noise_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d685bb3",
   "metadata": {},
   "source": [
    "First we can recreate the simulator from the information stored in the library. We will use the simulator in the log-likelihood calculation during sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.recreate_simulator_from_library(\n",
    "    override_library_path=library_path, override_grid_path=\"test_grid.hdf5\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cfee03",
   "metadata": {},
   "source": [
    "Then we can proceed to fit the observation using the sampler.\n",
    "\n",
    "The code will attempt to remove parameters which don't affect the fit (e.g. supplemental parameters) before fitting, but you can also specify to remove specific parameters using the `remove_params` argument.\n",
    "\n",
    "Let's choose an observation from the validation set and fit it using the dynesty sampler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d70c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2\n",
    "\n",
    "data = f\"{test_data_dir}/sbi_test_data_BPASS_DenseBasis_v4_final.npz\"\n",
    "import numpy as np\n",
    "\n",
    "loaded = np.load(data)\n",
    "X_test = loaded[\"X\"][:, index]\n",
    "y_test = loaded[\"y\"][:, index]\n",
    "\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b265a20d",
   "metadata": {},
   "source": [
    "We'll just recreate our prior for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9d5b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.create_priors(set_self=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbdd482",
   "metadata": {},
   "source": [
    "No we can run the sampler to fit the observation. This is too computationally expensive to run here, so we'll just show the code you would use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a49323",
   "metadata": {},
   "source": [
    "```python\n",
    "result = fitter.fit_observation_using_sampler(\n",
    "    observation=X_test,\n",
    "    sampler=\"dynesty\",\n",
    "    sampler_kwargs={\"bound\": \"multi\", \"sample\": \"rwalk\", \"run_kwargs\": {\"n_effective\": 2000}},\n",
    "    plot_name=f\"example_{index}\",\n",
    "    min_flux_pc_error=0.05,\n",
    ")\n",
    "samples = result[\"samples\"]\n",
    "log_l = result[\"logl\"]\n",
    "log_w = result[\"logwt\"]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecfb94b",
   "metadata": {},
   "source": [
    "We can sample using our trained SBI model as well for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a854df",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_params = fitter.sample_posterior(X_test, num_samples=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
