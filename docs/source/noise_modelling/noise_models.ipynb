{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed5bf9cd",
   "metadata": {},
   "source": [
    "# Noise Modelling\n",
    "\n",
    "Here we will look at the noise modelling - how to generate a noise model, and how to use it in training.\n",
    "\n",
    "All noise models have certain basic characteristics:\n",
    "\n",
    "- They take in a set of fluxes (or other features) and return noisy fluxes. If ```return_noise=True```, they also return the standard deviation of the noise applied to each flux **or an estimate thereof given the scattered flux itself**.\n",
    "- They can be serialized to HDF5 files for later use, and restored from such files. This uses the ```serialize_to_hdf5``` method and the ```load_unc_model_from_hdf5``` factory function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf524078",
   "metadata": {},
   "source": [
    "### Depth Noise Model\n",
    "\n",
    "The simplest noise model is the Depth Noise Model, which adds Gaussian noise with a standard deviation determined by the depth of the observation. This takes a depth (in AB mag), and optionally a depth sigma (default 5.0), which sets the SNR at the given depth. The flux is this noise model is distributed in flux space *not* magnitude space.\n",
    "\n",
    "If you're using this model there are a few things to keep in mind:\n",
    "- If you are training in magnitude space and conditioning the model on the magnitude errors, they are not well-behaved near the detection limit, as the flux errors become non-Gaussian in magnitude space. The code uses the approximation sigma_mag = 2.5 / ln(10) * (sigma_flux / flux) to estimate the magnitude errors, but this breaks down near the detection limit, and can lead to very large or undefined magnitude errors. Negative fluxes will lead to NaN magnitude errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3afa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from unyt import nJy\n",
    "\n",
    "from synference import DepthUncertaintyModel\n",
    "\n",
    "noise_model = DepthUncertaintyModel(depth_ab=28, return_noise=True)\n",
    "\n",
    "\n",
    "fluxes = np.random.uniform(0.1, 100, size=10_000) * nJy\n",
    "\n",
    "noisy_fluxes, sigmas = noise_model.apply_noise(fluxes, out_units=nJy)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.xlabel(\"Flux [nJy]\")\n",
    "plt.hist(\n",
    "    (noisy_fluxes),\n",
    "    bins=50,\n",
    "    density=False,\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "plt.hist(\n",
    "    (fluxes.to_value(nJy)),\n",
    "    bins=50,\n",
    "    density=False,\n",
    "    alpha=0.7,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82082248",
   "metadata": {},
   "source": [
    "We can set the output units as well - here we choose AB magnitudes, and plot the noisy fluxes against the true fluxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e19b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_fluxes, sigmas = noise_model.apply_noise(fluxes, out_units=\"AB\")\n",
    "\n",
    "\n",
    "plt.scatter(-2.5 * np.log10(fluxes) + 31.4, noisy_fluxes, s=1, alpha=0.5)\n",
    "# plot 1:1 line\n",
    "plt.plot([26, 35], [26, 35], color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"True Magnitude [AB]\")\n",
    "plt.ylabel(\"Noisy Magnitude [AB]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891af48d",
   "metadata": {},
   "source": [
    "### General Noise Model\n",
    "\n",
    "This noise model is designed to match the noise distribution of a given dataset. It fits a model to the relationship between flux and flux uncertainty in the data, and uses this to generate noisy fluxes. There are a few different ways to use this model, depending on your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca012846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synference import GeneralEmpiricalUncertaintyModel\n",
    "\n",
    "# Generate some fake random data with noise\n",
    "\n",
    "# model error as a function of flux in bins\n",
    "errors = 0.1 * fluxes + 1.0 * nJy + 5.0 * nJy * np.random.rand(len(fluxes))\n",
    "\n",
    "\n",
    "noise_model = GeneralEmpiricalUncertaintyModel(\n",
    "    observed_fluxes=fluxes, observed_errors=errors, flux_unit=nJy\n",
    ")\n",
    "\n",
    "noise_model.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766bdafd",
   "metadata": {},
   "source": [
    "### Asinh Noise Model\n",
    "\n",
    "This noise model can also match the noise distribution of a given dataset, but uses an asinh transformation to better handle low SNR data. This is particularly useful when working with data that includes many non-detections or upper limits. The asinh transformation helps to stabilize the variance and make the noise distribution more Gaussian-like, which can improve the performance of models trained on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synference.utils import f_jy_err_to_asinh, f_jy_to_asinh\n",
    "\n",
    "mags = np.arange(28, 35, 0.1)\n",
    "fluxes = 10 ** ((mags - 31.4) / -2.5) * nJy\n",
    "asinh_fluxes = f_jy_to_asinh(fluxes.to(\"Jy\"), f_b=1 * nJy)\n",
    "\n",
    "plt.plot(mags, asinh_fluxes)\n",
    "plt.axhline(31.4, color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"Magnitude [AB]\")\n",
    "plt.ylabel(\"Magnitude [asinh]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f109a2",
   "metadata": {},
   "source": [
    "This noise model is implemented in the ```AsinhEmpiricalUncertaintyModel``` class. It works similarly to the ```GeneralEmpiricalUncertaintyModel```, but applies the asinh transformation to the fluxes before fitting the noise model. It only excepts input fluxes in Jy units, and whilst the ```apply_noise``` method will accept the ```out_flux_unit``` argument for consistency with other noise models, the output fluxes will always be in asinh magnitudes.\n",
    "\n",
    "For this model, the asinh softening parameter is not set directly, but in multiples of the median standard deviation of the flux uncertainties in the training data. This is set using the ```f_b_factor``` argument when initializing the model. For example, setting ```f_b_factor=1.0``` will set the softening parameter to the median flux uncertainty, while ```f_b_factor=2.0``` will set it to twice the median flux uncertainty. By default, ```f_b_factor=5.0```, so the softening parameter is set to five times the median flux uncertainty (aka the $5\\sigma$ detection limit).\n",
    "\n",
    "For this example we setup a more realstic scenario, with a catalogue of 50,000 fake sources with a fixed background level, a fractioanl error and an overall lognormal flux distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synference import AsinhEmpiricalUncertaintyModel\n",
    "from synference.utils import f_jy_to_asinh\n",
    "\n",
    "# --- 1. Define Realistic Survey Parameters ---\n",
    "N_SOURCES: int = 50_000\n",
    "\n",
    "# Background noise limit (e.g., 100 uJy).\n",
    "# This dominates the error for faint sources.\n",
    "BACKGROUND_NOISE_JY: float = 0.0001\n",
    "\n",
    "# Fractional/calibration error (e.g., 2%).\n",
    "# This dominates the error for bright sources.\n",
    "FRACTIONAL_ERROR: float = 0.02\n",
    "\n",
    "# Log-normal distribution parameters for \"true\" fluxes.\n",
    "# We set the median flux to be near the noise floor.\n",
    "FLUX_MEDIAN_JY: float = 0.00015\n",
    "FLUX_LOG_SIGMA: float = 1.5  # Width of the log-normal distribution\n",
    "\n",
    "# --- 2. Generate \"True\" Fluxes ---\n",
    "# Use a log-normal distribution: many faint sources, few bright ones\n",
    "true_flux_jy = np.random.lognormal(\n",
    "    mean=np.log(FLUX_MEDIAN_JY), sigma=FLUX_LOG_SIGMA, size=N_SOURCES\n",
    ")\n",
    "\n",
    "# --- 3. Calculate \"Ideal\" Error for Each True Flux ---\n",
    "# This is the characteristic error model: sqrt(bg_noise^2 + (frac_err * flux)^2)\n",
    "ideal_error_jy = np.sqrt(BACKGROUND_NOISE_JY**2 + (FRACTIONAL_ERROR * true_flux_jy) ** 2)\n",
    "\n",
    "# --- 4. Simulate \"Observed\" Fluxes by Scattering by the Error ---\n",
    "# The observed flux is the true flux plus Gaussian noise\n",
    "observed_flux_jy = true_flux_jy + np.random.normal(loc=0.0, scale=ideal_error_jy, size=N_SOURCES)\n",
    "\n",
    "# The \"observed error\" is the error the pipeline *reports*.\n",
    "# We assume the pipeline correctly estimates the ideal error.\n",
    "observed_error_jy = ideal_error_jy\n",
    "\n",
    "# Plot a flux histogram\n",
    "plt.hist(true_flux_jy, label=\"Fluxes\", bins=100)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Flux [Jy]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc934bb",
   "metadata": {},
   "source": [
    "From this realistic dataset we can generate our `AsinhEmpiricalUncertaintyModel`. Note that some datapoints fall below the softening parameter - these are originally negative fluxes which can be represented by asinh magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db14a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_model = AsinhEmpiricalUncertaintyModel(\n",
    "    observed_phot_jy=observed_flux_jy,\n",
    "    observed_phot_errors_jy=observed_error_jy,\n",
    ")\n",
    "\n",
    "print(noise_model.b)\n",
    "\n",
    "# plot noise_model.b\n",
    "fig, ax = plt.subplots()\n",
    "noise_model.plot(ax=ax)\n",
    "\n",
    "\n",
    "plt.axvline(f_jy_to_asinh(noise_model.b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b18c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "?truncnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610fcb87",
   "metadata": {},
   "source": [
    "## Example Noise Models for Real Data\n",
    "\n",
    "Let's try making noise models for some real data. We will use the UNCOVER DR3 catalog (0.32\" apertures) for this example. First, we need to download the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8767e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_link = r\"https://drive.google.com/uc?export=download&id=1dDo2RhiP_OCjO5hEc90T8HnnC0lYxqfl\"\n",
    "file_name = r\"UNCOVER_DR3_LW_D140_catalog.fits\"\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    subprocess.run(\n",
    "        [\"wget\", direct_link, \"-O\", file_name], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "\n",
    "catalog = Table.read(\"UNCOVER_DR3_LW_D140_catalog.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5574ec",
   "metadata": {},
   "source": [
    "Here for the F444W band is the flux error as a function of flux, for the full catalog. (Note fluxes are in 10xnJy units in the catalog.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf87db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "flux = list(catalog[\"f_f444w\"].value) * 10 * nJy\n",
    "flux_err = list(catalog[\"e_f444w\"].value) * 10 * nJy\n",
    "\n",
    "mask = (flux > 0) & (flux_err > 0)\n",
    "flux = flux[mask]\n",
    "flux_err = flux_err[mask]\n",
    "\n",
    "plt.hexbin(\n",
    "    flux, flux_err, gridsize=50, cmap=\"Blues\", mincnt=1, yscale=\"log\", xscale=\"log\", norm=\"log\"\n",
    ")\n",
    "plt.xlabel(\"Flux [nJy]\")\n",
    "plt.ylabel(\"Flux Error [nJy]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f44cacf",
   "metadata": {},
   "source": [
    "In magnitude space, this looks like the following. It's worth noting that the magnitude errors become asymmetric and non-Gaussian near the detection limit, which can cause issues if you're training in magnitude space and conditioning on the magnitude errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = -2.5 * np.log10(flux / 3631e9)\n",
    "mag_err = (2.5 / np.log(10)) * (flux_err / flux)\n",
    "\n",
    "plt.hexbin(mag, mag_err, gridsize=50, cmap=\"Blues\", mincnt=1, norm=\"log\", extent=(21, 35, 0, 1))\n",
    "plt.xlabel(\"Magnitude [AB]\")\n",
    "plt.ylabel(\"Magnitude Error [AB]\")\n",
    "plt.ylim(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1671ccd",
   "metadata": {},
   "source": [
    "Now we can plot the asinh uncertainty model fit for the F444W band, on top of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767cc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = AsinhEmpiricalUncertaintyModel(\n",
    "    observed_phot_jy=flux,\n",
    "    observed_phot_errors_jy=flux_err,\n",
    ")\n",
    "print(f\"The derived softening parameter is b = {nm.b:.3e}\")\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "true_f_asinh = f_jy_to_asinh(flux, f_b=nm.b)\n",
    "\n",
    "true_f_err_asinh = f_jy_err_to_asinh(flux, flux_err, f_b=nm.b)\n",
    "\n",
    "ax.hexbin(\n",
    "    true_f_asinh,\n",
    "    true_f_err_asinh,\n",
    "    gridsize=50,\n",
    "    cmap=\"Blues\",\n",
    "    mincnt=1,\n",
    "    norm=\"log\",\n",
    "    extent=(21, 30, 0, 0.2),\n",
    ")\n",
    "\n",
    "nm.plot(ax=ax)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
