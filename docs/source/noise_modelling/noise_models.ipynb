{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed5bf9cd",
   "metadata": {},
   "source": [
    "# Noise Modelling\n",
    "\n",
    "Here we will look at the noise modelling - how to generate a noise model, and how to use it in training.\n",
    "\n",
    "All noise models have certain basic characteristics:\n",
    "\n",
    "- They take in a set of fluxes (or other features) and return noisy fluxes. If ```return_noise=True```, they also return the standard deviation of the noise applied to each flux **or an estimate thereof given the scattered flux itself**.\n",
    "- They can be serialized to HDF5 files for later use, and restored from such files. This uses the ```serialize_to_hdf5``` method and the ```load_unc_model_from_hdf5``` factory function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf524078",
   "metadata": {},
   "source": [
    "### Depth Noise Model\n",
    "\n",
    "The simplest noise model is the Depth Noise Model, which adds Gaussian noise with a standard deviation determined by the depth of the observation. This takes a depth (in AB mag), and optionally a depth sigma (default 5.0), which sets the SNR at the given depth. The flux is this noise model is distributed in flux space *not* magnitude space.\n",
    "\n",
    "If you're using this model there are a few things to keep in mind:\n",
    "- If you are training in magnitude space and conditioning the model on the magnitude errors, they are not well-behaved near the detection limit, as the flux errors become non-Gaussian in magnitude space. The code uses the approximation sigma_mag = 2.5 / ln(10) * (sigma_flux / flux) to estimate the magnitude errors, but this breaks down near the detection limit, and can lead to very large or undefined magnitude errors. Negative fluxes will lead to NaN magnitude errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3afa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from unyt import nJy\n",
    "\n",
    "from synference import DepthUncertaintyModel\n",
    "\n",
    "noise_model = DepthUncertaintyModel(depth_ab=28, return_noise=True)\n",
    "\n",
    "\n",
    "fluxes = np.random.uniform(0.1, 100, size=10_000) * nJy\n",
    "\n",
    "noisy_fluxes, sigmas = noise_model.apply_noise(fluxes, out_units=nJy)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.xlabel(\"Flux [nJy]\")\n",
    "plt.hist(\n",
    "    (noisy_fluxes),\n",
    "    bins=50,\n",
    "    density=False,\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "plt.hist(\n",
    "    (fluxes),\n",
    "    bins=50,\n",
    "    density=False,\n",
    "    alpha=0.7,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82082248",
   "metadata": {},
   "source": [
    "We can set the output units as well - here we choose AB magnitudes, and plot the noisy fluxes against the true fluxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e19b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_fluxes, sigmas = noise_model.apply_noise(fluxes, out_units=\"AB\")\n",
    "\n",
    "\n",
    "plt.scatter(-2.5 * np.log10(fluxes) + 31.4, noisy_fluxes, s=1, alpha=0.5)\n",
    "# plot 1:1 line\n",
    "plt.plot([26, 35], [26, 35], color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"True Magnitude [AB]\")\n",
    "plt.ylabel(\"Noisy Magnitude [AB]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891af48d",
   "metadata": {},
   "source": [
    "### General Noise Model\n",
    "\n",
    "This noise model is designed to match the noise distribution of a given dataset. It fits a model to the relationship between flux and flux uncertainty in the data, and uses this to generate noisy fluxes. There are a few different ways to use this model, depending on your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca012846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synference import GeneralEmpiricalUncertaintyModel\n",
    "\n",
    "noise_model = GeneralEmpiricalUncertaintyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766bdafd",
   "metadata": {},
   "source": [
    "### Asinh Noise Model\n",
    "\n",
    "This noise model can also match the noise distribution of a given dataset, but uses an asinh transformation to better handle low SNR data. This is particularly useful when working with data that includes many non-detections or upper limits. The asinh transformation helps to stabilize the variance and make the noise distribution more Gaussian-like, which can improve the performance of models trained on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synference.utils import f_jy_to_asinh\n",
    "\n",
    "mags = np.arange(28, 35, 0.1)\n",
    "fluxes = 10 ** ((mags - 31.4) / -2.5) * nJy\n",
    "asinh_fluxes = f_jy_to_asinh(fluxes.to(\"Jy\"), f_b=1 * nJy)\n",
    "\n",
    "plt.plot(mags, asinh_fluxes)\n",
    "plt.axhline(31.4, color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"Magnitude [AB]\")\n",
    "plt.ylabel(\"Magnitude [asinh]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f109a2",
   "metadata": {},
   "source": [
    "This noise model is implemented in the ```AsinhEmpiricalUncertaintyModel``` class. It works similarly to the ```GeneralEmpiricalUncertaintyModel```, but applies the asinh transformation to the fluxes before fitting the noise model. It only excepts input fluxes in Jy units, and whilst the ```apply_noise``` method will accept the ```out_flux_unit``` argument for consistency with other noise models, the output fluxes will always be in asinh magnitudes.\n",
    "\n",
    "For this model, the asinh softening parameter is not set directly, but in multiples of the median standard deviation of the flux uncertainties in the training data. This is set using the ```f_b_factor``` argument when initializing the model. For example, setting ```f_b_factor=1.0``` will set the softening parameter to the median flux uncertainty, while ```f_b_factor=2.0``` will set it to twice the median flux uncertainty. By default, ```f_b_factor=5.0```, so the softening parameter is set to five times the median flux uncertainty (aka the $5\\sigma$ detection limit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synference import AsinhEmpiricalUncertaintyModel\n",
    "\n",
    "noise_model = AsinhEmpiricalUncertaintyModel()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
